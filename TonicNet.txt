Improving Polyphonic Music Models with Feature-Rich Encoding
14 Sep 2020 ·  Omar Peracha
Paper: https://paperswithcode.com/paper/improving-polyphonic-music-models-with
Code: https://github.com/omarperacha/TonicNet
TonicNet, a GRU-based model trained to initially predict the chord at a given time-step before then predicting the notes of each voice at that time-step, in contrast with the typical approach of predicting only the notes. We then evaluate TonicNet on the canonical JSB Chorales dataset and obtain state-of-the-art results.
Someone else's version https://github.com/AI-Guru/tonicnet
He also conducted experiments on a Transformer encoder with input masking. Trained to first predict the chord, and then to predict the notes of each voice seemed to improve the performance. Results improve when more musical information is contained in the sequence being predicted. TonicNet is an order of magnitude smaller than Music Transformer, with lower validation set loss on the JSB chorales than reported by Huang. 
Smaller, faster, better: I like that.
Refers to C. Huang, A. Vaswani, J. Uszkoreit, N. Shazeer, I. Simon, C. Hawthorne, A. Dai, M. Hoffman, M. Dinculescu and D. Eck, “Music Transformer”, arXiv:1809.04281 [cs], 2018
"The Transformer and its derived architectures have been popular choices for more recent polyphonic music models, and are emerging as strong alternatives to RNNs more broadly due to the self-attention mechanism demonstrating great effectiveness at capturing long-term dependencies in training data [7]. Music Transformer adds a novel relative attention mechanism to the vanilla Transformer and is evaluated on the JSB chorales dataset. LakhNES [4] uses the Transformer-XL architecture [16] and is pretrained on a large corpus of four-part music before being fine-tuned on the NES Music Database [17]"
"In the method proposed in this paper, chords are in fact must be predicted along with the other four voices, rather than being used as a secondary conditioning input."
I wonder if he limited his source files to the 32 1/16th note time steps. Nope.
Both coconet and DeepBach "require the length of the sample in time-steps to be preset in order to facilitate the orderless Gibbs-like sampling methods used." I would like to get rid of that restriction, and allow longer sections to be generated, not just concatenated together.
"We include chords in our encoding. We first derive the chords for each 16th-note time-step by analysing the pitches of the four voices at said time-steps, using the music21 chord module. We then create a single ordered sequence for each sample in the form C0, S0, B0, A0, T0, C1, S1, B1, A1, T1..." Chord, Soprano, Bass, Alto, Tenor at each time step. N is number of time steps in the sample. "The longest sequence observed in the dataset is 2,881 tokens in length."
MIDI # 37 - C# - was never observed. That's interesting. 
Set of 98 possible tokens: 
      MIDI values 36 through 81 represent 46 note classes, plus rest and end = 48 note classes. 
      50 chord classes: 12 major, 12 minor, 12 dimished, 12 augmented, other, chord rest.
He also tracks the number of repetitions of a note, which to me is basically how long it is held. He calls those Z-inputs. 
Data Augmentation:
      - transpose all pieces as many times as possible while keeping pitches within the 36 - 81 range, plus not outside the natural vocal range of the voice-type in which it appears. Total training samples to 1,968
      - Crude conversion of all major pieces to minor and visa versa, only touching the 3rd, 6th, and 7th. This had negligible impact on model performance, hurt training time, harmed sample quality.
Input: concatenation of: chord, 4 MIDI numbers, Z-input. Converted to one-hot encoding. 
Model: Training on the transposed dataset took roughly 3.25hrs on a T4 Tensor Core GPU. So I can expect 30 hours or so on the HP800.
--------------------------------------------
Ran the training code for about 30 hours, and it ended at around 59 epochs. It saved the result after 57 epochs as 
      eval/TonicNet_epoch-57_loss-0.325_acc-90.756.pt. 
      I had the change the source code of main.py as shown:
      elif sys.argv[1] in ['--sample', '-s']:
            #   x = sample_TonicNet_random(load_path='eval/TonicNet_epoch-56_loss-0.328_acc-90.750.pt', temperature=1.0)
            x = sample_TonicNet_random(load_path='eval/TonicNet_epoch-57_loss-0.325_acc-90.756.pt', temperature=1.0)
            # 
            indices_to_stream(x)
            smooth_rhythm()

      elif sys.argv[1] in ['--eval_nn', '-e']:
            eval_on_test_set(
                  # 'eval/TonicNet_epoch-58_loss-0.317_acc-90.928.pt',
                  'eval/TonicNet_epoch-57_loss-0.325_acc-90.756.pt',
                  TonicNet(nb_tags=98, z_dim=32, nb_layers=3, nb_rnn_units=256, dropout=0.0),
                  CrossEntropyTimeDistributedLoss(), set='test', notes_only=True)
      I ran  the evaluation code:
            python main.py --eval_nn
      loaded params from eval/TonicNet_epoch-57_loss-0.325_acc-90.756.pt

      TonicNet(
      (embedding): Embedding(98, 256)
      (pos_emb): Embedding(64, 0)
      (z_embedding): Embedding(80, 32)
      (dropout_i): VariationalDropout()
      (rnn): GRU(288, 256, num_layers=3, batch_first=True)
      (dropout_o): VariationalDropout()
      (hidden_to_tag): Linear(in_features=288, out_features=98, bias=False)
      )
                  [1] loss: 0.209, acc: 93.969
                  [2] loss: 0.276, acc: 91.837
                  [3] loss: 0.187, acc: 94.770                 
                  ...
                  [72] loss: 0.159, acc: 94.817
                  [73] loss: 0.159, acc: 95.417
                  [74] loss: 0.277, acc: 91.582
                  [75] loss: 0.230, acc: 94.231
                  [76] loss: 0.243, acc: 93.648
                  [77] loss: 0.151, acc: 95.330

      Then ran the sample:
            python main.py --sample
      ...
      239
      ending
      SAVED sample to ./eval/sample.mid
      SAVED rhythmically 'smoothed' sample to ./eval/sample_smoothed.mid
      That one was barely 4 measuers. Ran it again and it went up to 1264, 16 measures
      sample_smoothed.mid was pretty good.
      The sample.mid was all 1/16 notes repeated. Interesting.
      Another one ended after 199, only three measures.
I'm wondering if I could insist that the generated chorale be over a certain length? 
      find /var/home/prent/Dropbox/Tutorials/TonicNet -name "*.py" -exec grep -Hni "sample_TonicNet_random" {} \;
I found it here: eval/sample.py
I wonder what the temperature does? Read the paper.  It doesn't say. I think it has something to do with the degree of randomness. 

-----------------------------------------------------------
JS Fake Chorales: a Synthetic Dataset of Polyphonic Music with Human Annotation
Paper: https://arxiv.org/pdf/2107.10388v4.pdf
Code: https://github.com/omarperacha/TonicNet
More code: https://github.com/omarperacha/js-fakes
Web page: https://omarperacha.github.io/make-js-fake/ - generates a fake ch00orale while you wait.
3/31/2022 
Omar A. Peracha Humtap, Inc. London, U.K. omar@humtap.com
Synthetic Bach Chorales JS Fake Chorales. Uses an algorithm called KS_Chorus.
They discuss TonicNet, which can create chorales from original Bach input chorales. They feed their Synthetic Chorales into TonicNet, and it creates new synthetic chorales not significantly different from ones that were created from actual Bach chorale input. Mentions MusicBERT
He also created the TonicNet paper, which is used in JS Fake Chorales.
Video lecture: https://program.ismir2020.net/poster_2-01.html (click on the video button)
I'm trying to read the saved file from the  https://github.com/omarperacha/js-fakes git hub. I cloned it into the Tuturials as js-fakes but I'm struggling. js-fakes-16thSeparated.npz is a pickle file. I read it in, and found that it's a dictionary with 'pitches' and 'chords' as keys. Then if I iterate over pitches, I get sequences of from 112 to 520 notes. But how do I translate those into SATB? 
He says: "If a voice is silent at a given time step, its pitch is -1." But I'm not finding any -1. I searched every sequence and there are no -1's . Maybe zero? Lots of zeros. That's because you were looking at 'chords' not 'pitches'. Don't get stuck on stupid.

If I compare the pickle dictionary 'chords' file #5, the shortest chorale at 112 notes, with the midi file called 5.mid, I see no relationship between the pickle file #5 and 5.mid. 5.mid is 7 measures. If we count each measure as 4 quarter notes, 16 1/16th notes, 16*7 = 112 time steps. Is there another place where the other 3 voices are represented? And what do the numbers represent.  3,  3,  3,  3,  3,  3,  3,  3,  starts and ends it. If I switch to looking at jsf['pitches'][5] then I see the four voices across 112 time steps. The pitches look right. 

------------------------------------
7/5/22 To do today:
      Now that I've found the chorale arrays inside the jsb['pitches'][chorale_num], how can I send them through the python codes to evaluate them. Start there.
      Interesting results. The longest is number 176.mid, which has a very long held note. It looks to be an anomoly. 
      The other longer pieces are all very good. 
      I also used music21 to find the key it's in. 
      I chose (cherry pick, you might say) only those chorales of last time step of 50,000 (over half are that long) amd class entropy of more than 3.0. I get 106 files, out of the 500 in the set. After all, I only need a few. 
      The plan is to read in a MIDI file and use that as the basis for my modifications.
------------------
7/14/22 Tried the training again starting yesterday. 
      Last saved model:
      SAVED MODEL TO: eval/TonicNet_epoch-42_loss-0.329_acc-90.598.pt
      Beginning EPOCH 46
      Last time it made it to 59 before failing. Who knows if it makes a difference.
      What is amazing is that the model is only 4.9MB, compared to the coconet model at 1.6 GB, 99.69% smaller. 0.31% the size of coconet model. Amazing. Much smaller, and we could argue better results. 
      But it doesn't support sending "seed" chorales into the model. From the Feb 2020 paper by Peracha: 
      "Both DeepBach and COCONET [6] are trained with the primary goal of completing partially-filled musical scores, for example harmonising a given melody, though both areable to generate entire four-voice samples from an empty or  randomly-initialised score."
      "Theoretically one could fix the chords or the notes of a given voice when sampling from TonicNet by ignoring predicted output for the relevant part, instead using the token from the corresponding time-step of the fixed sequence as input to the model at the next time-step. However, this kind of forced sampling has not been tested empirically and so sample quality under these conditions can-not be attested."
      On the remaining problem with time_step data modeling: "A partial workaround to lack of repeated note boundaries during sampling is to simply tie together consecutive occurrences of the same pitch in a voice, which we refer to as rhythmic ’smoothing’, however this inevitably sacrifices some rhythmic integrity of the original chorales."
      Plus, your smoothing algorithm doesn't work. 
----------------------
7/15/22 To do today:
      finished train phase [60] loss: 0.284, acc: 91.338

                  PHASE: val
                        [50] loss: 0.316, acc: 91.019
                  finished val phase [60] loss: 0.322, acc: 90.762

                  time: 31m 40s 

                  LOSS DID NOT IMPROVE FROM 0.322 

            Beginning EPOCH 61

                  PHASE: train
            Traceback (most recent call last):
            File "/home/prent/Dropbox/Tutorials/TonicNet/main.py", line 12, in <module>
            train_TonicNet(3000, shuffle_batches=1, train_emb_freq=1, load_path='')
            File "/home/prent/Dropbox/Tutorials/TonicNet/train/train_nn.py", line 161, in train_TonicNet
            scheduler.step()
            File "/home/prent/miniconda3/envs/gym/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 152, in step
            values = self.get_lr()
            File "/home/prent/Dropbox/Tutorials/TonicNet/train/external.py", line 360, in get_lr
            raise ValueError("Tried to step {} times. The specified number of total steps is {}"
            ValueError: Tried to step 113522 times. The specified number of total steps is 113520
            ​      
      Last saved model step: eval/TonicNet_epoch-58_loss-0.322_acc-90.745.pt
-----------------------
7/26/22 Notes. I had a jupyter notebook that generated 500 chorales, and the associated numpy chorale structures. What happened to it? I must have deleted those cells sometime between 7/15 and 7/24. I need to go back to Dropbox and download versions from that time. What is the date of the TonicNet/eval/midi_samples directory? 7/15/22. So if I grab the notebook from 7/15 I should be good.
------------------------------
12/17/22 Notes. I came back to this 5 months later.

I found it here: /home/prent/Dropbox/Tutorials/TonicNet/TonicNet_Synthetic_Chorale_Manufacture.ipynb
Notes on this project are here: Many_Chorales_on_HP800.txt
---------------------------------
3/5/23 To do today

1.    Work on the generated chorales with a focus on masking for interesting rhythms. 
      a.    Find the evaluation routine.
      and run those through a model that lingers on the chords that are not in the original key.

2.    Had a hard time starting up jupyter inside code-server serve on the T15:
            python3.11 -m venv virtual_python3.11
            source virtual_python3.11/bin/activate
            python3.11 -m pip install --upgrade pip
            pip install jupyter
            pip install numpy matplotlib scipy 
            pip install mido fluidsynth music21 muspy pandas
            pip3 install torch
            cd Dropbox/Tutorials/TonicNet
      Advice for jupyter on vscode here: # https://github.com/microsoft/vscode-jupyter/wiki/Connecting-to-a-remote-Jupyter-server-from-vscode.dev

            jupyter notebook --no-browser --NotebookApp.allow_origin='*' 
      or:
            jupyter notebook --no-browser --NotebookApp.allow_origin_pat=https://.*vscode-cdn\.net

      Now I have access to the jupyter notebook inside code-server serve without Anaconda.
            
--------------------------
3/7/23 To do today:

1.    Get the evaluation notebook working again: TonicNet_Synthetic_Chorale_refactored.ipynb. 

2.    Fix the TonicNet_Synthetic_Chorale_Manufacture.ipynb so that it places the new midi files here:
      /home/prent/Dropbox/Tutorials/TonicNet/eval/midi_samples
      It was saving the midi files to TonicNet/eval 
      Make sure the numpy chorales are saved to here:
      /home/prent/Dropbox/Tutorials/TonicNet/eval/numpy_chorales

3.    I will need access to some functions that are in a different directory. 
      This function call sys.path.insert will let me load a python library in other directories:
      sys.path.insert(0, '/home/prent/Dropbox/Tutorials/coconet-pytorch/coconet-pytorch-csound')

4.    Do you suppose I could change the temperature setting on the tonicnet model. 
      Would I get more wigged out results? In general, a temperature of 1.0 is normal. Higher temperatures produce more greedy, with results that might not be correct. But it will it will have higher interestingness.

5.    So I have several ways to control the scoring of the manufactured tonicnet chorales:
      a.    Limit the duration and require the higher entropy:
                  if 50_000 < metric[10] < 250_000 and metric[8] > 3.2:
            But I get the feeling that the longer they are, the more entropy I can expect. Perhaps I should demand a lower entropy for the shorter ones, but require higher entropy for the longer ones.

------------------------
3/8/23 To do today:

1.    Get a look at the results of the temperature setting to 1.2 for sample4100 through sample4499. 
      See if you can limit the evaluation to just those midi files. The entropy was larger, I found a peak collection with 3.45 through 3.56, which is more than the previous temperature. Now trying 4500-4899 with temperature 0.8. See what that does. Now the peaks are 3.0 through 3.24. Try 1.5. I think those are too off. Deleting 4900 to 5200.
      So now I have a wide assortment from 0000 to 4899.

2.    I'm very slowly working on sending a chorale through a transformation into a csound file. 
      The v in noguev for velocity. Make sure to keep those in order every place where they are used.

-------------------------
3/9/23 To do today:

1.    List the complete step-by-step for moving from a numpy version of the midi chorale to csound wav file
      Source code in: TonicNet_play_Chorale_on_Csound.ipynb
      Choral Manufacture in: TonicNet_Synthetic_Chorale_refactored.ipynb
      
      Key requirements:
      a.    The number of voices in the instrument array stored as variable horn_line must be equal the number of instrument in the chorale, or some multiple of that number.
      b.    The volume array must have the same number of notes as the second dimension of chorale, the number of notes in a voice
      c.    The dimension of notes_features coming out of build_notes_features_from_chorale can be several different configurations depending on the axis of the np.stack command. 
            With axis = 0 it is (features, voices, notes) (6, 4, 602)
      d.    The number of notes is dependent on the length of the synthetic chorale
      e.    The number of features is initially set to 6 in noguev
      
      Here is the order of the transformation:
      a.    Some values can be preset for the whole piece:
                  tpq = 0.25
                  horn_line =  np.array(["ob1","cl1","fr1","bs1","ob2","cl2","fr2","bs2"])
                  horn_line.shape = (8,)
                  voice_time = # dictionary structure in the notebook.
      b.    Some are set for each synthetic chorale when you know the number of notes in the chorale:
                  chorale.shape = (4, 602)
                  volume_array = np.full(chorale.shape[1], 5)
                  # the chorale is voices, notes
      c.    Use a function to convert (voices, notes) to (features, voices, notes)
                  notes_features = build_notes_features_from_chorale(chorale, guev = np.array(0, 0, 1, 74)):
            I can change the dimension structure by changing the axis of the stack call in build_notes_features_from_chorale:
                  np.stack((note, octave, gliss, upsample, envelope, velocity), axis = 0) # notes_features.shape = (6, 4, 602) 
                  features, voices, notes
                  np.stack((note, octave, gliss, upsample, envelope, velocity), axis = 1) # notes_features.shape = (4, 6, 602) 
                  voices, features, notes
                  np.stack((note, octave, gliss, upsample, envelope, velocity), axis = 2) # notes_features.shape = (4, 602, 6) 
                  voices, notes, features
                  np.stack((note, octave, gliss, upsample, envelope, velocity)) # notes_features.shape = (6, 4, 821)
                  features, voices, notes
            piano_roll_to_notes_features expects: (features, voices, notes)
                  features must be 6: noguev
                  voices must be equal to horn_line.shape[0]
                  notes can be any number
            Here is that transformation in code:
                  notes_features = dmu.piano_roll_to_notes_features(notes_features, volume_array, horn_line, tpq, voice_time)
                        notes_features.shape = (635, 15) 
            The number of notes returned by dmu.piano_roll_to_notes_features will not match the chorale.shape[0] or any other value. It is dependent on how many repeated notes there are in the chorale.
      d.    Transform the duration value for each note in each voice into a start time:
                  notes_features, voice_time = dmu.fix_start_times(notes_features, voice_time)
      e.    Print the total duration for all the voices in the instrument collection:
                  print("horn: ", *[(inst, dmu.format_seconds_to_minutes(voice_time[inst]["start"])) for inst in horn_line if voice_time[inst]["start"] > 0],sep='\t')
                  horn:  ('ob1', '00:02:30.500') ('cl1', '00:02:30.500') ('fr1', '00:02:30.500') ('bs1', '00:02:30.500')
      f.    Send the notes to csound to the format the csd file expects.
                  notes_features = dmu.send_to_csound_file(notes_features, voice_time, CSD_FILE, tempos = 't0 ' + str(tempo), tempo = tempo, print_only = 10) 
      g.    Process the csd file with csound
                  result = os.system(f'csound new_output.csd -Ocsound_{CS_LOGNAME}') # give it a log file to write csound messages to.
      h.    Look for error messages in the csound log file.
                  result = os.system(f"egrep 'invalid|replacing|range|error|cannot|rtevent|overall' csound_{CS_LOGNAME}") 
      i.    Play the file in a gui like audacity

2.    What was the temperature of the files:
      1.0 for sample0 through sample4099
      1.2 for sample4100 through sample4499
      0.8 for sample4500 through sample4899 

--------------------------------
3/13/23 To do today:

1.    Convert the midi representation to the 256-tone scale and use the corresponding f3 ftable in the ball4.csd file.
      The purpose of this is the allow glissandi and trills with the synthetic chorales. And also to choose scales that make sense for all the keys. I'll need a different conversion for each of the 12 keys. That implies a method to evaluate the possible chosen conversions. Which opens up an evaluation of the work I did a few years ago on searching for interesting diatonic keys in the tonality diamond to the 31 limit. The method I used was to do the following:
      a.    The key needs to have a perfect 5th
      b.    If major, it needs either a 5:4 or close to a 5:4, a certain maximum number of cents from 5:4
      c.    If minor, it can be almost any ratio from 8:7 to 6:5. 
      I can't find a version of the microtonal spreadsheet that has all the alternatives. I found it from 8/13/18

2.    See if the midi generated files and the numpy representations line up correctly. 
      They do. Now, at least. Misplaced i += 1 

3.    This conversion from midi numbers to notes in the TD31L (Tonality Diamond to the 31-limit) form is a bit more challenging that I considered. 
      Take f minor for example. It could be easy-peasy 
            Utonal on C
      128   96    64    32    0     224   192   160   
      4/3   16/11 8/5   16/9  1/1   16/15 8/7   16/13 
      F     G-    Ab    Bb    C     Db    D+    Eb    
      0     1     2     3     4     5     6     7     

      mode = 'uton'
      ratio = '1/1'
      rank = 'A'
      f_minor = dmu.build_scales(mode, ratio, rank)
      f_minor = array([128,  96,  64,  32,   0, 224, 192, 160])

      The problem is that the chorale array has numbers from 0 to 11, and the scale returned by build_scales has 0 through 7. 12 can't fit in 8.
      And that's the problem for tomorrow. Go for a walk now.

-------------------------------------------------
3/14/23 To do today:

1.    Tuning Idea: For every note, search for the right notes for a chorale from the 214 available in the TD31L:
      a.    optimize choices across all the notes within a chorale - no good if all 12 are used frequently
      b.    within a chord
      b.    within a certain number of time_steps
      What is the goal?
      a.    Minimize the wolf notes, beating 
      b.    If one chord requires one note and the next requires it to be a different note, slide from one to the other. 
      
      Some data from a highly entropic synthetic chorale:
      chosen = 24, file_num = 4321
      midi source entropy length key [array(['sample4321.mid', '3.456', '52480', 'f minor'], dtype='<U32')]
      chorale.shape = (4, 205)
      notes.shape = (4, 205)
      count_of_note_names = array([124,  50,  49,   71,   50,  115,   40,   70,   72,   77,   88,   14])
                                 ['C♮', 'D♭', 'D♮', 'E♭', 'E♮', 'F♮', 'G♭', 'G♮', 'A♭', 'A♮', 'B♭', 'B♮']
                                 ['C♮', 'C♮', 'D♮', 'D♮', 'E♮', 'F♮', 'F♮', 'G♮', 'G♮', 'A♮', 'A♮', 'B♮']
      plt.hist(unique_note_names, weights=count_of_note_names, bins = 12)
      plt.show()
      This is important information. We can expect all of the highly entropic synthetic chorales to have a similar histogram, where all 12 notes are used. We will need to look 

2.    What is the process going to be:
      a.    Start with the first chord, and make it pure just, either otonal or utonal.
            key is f minor but the first chord is Eb major. Maybe that's the key? ♭, ♮, ♯
            chord: 
            1a    E♭   G♮   B♭
            1b    E♭   G♭   A♮
            2a    B♭   F♮   
            2b    B♭   F♮   D♮
            3a    E♭   G♮   B♭
      b. William A. Sethares has studied this problem here: https://sethares.engr.wisc.edu/papers/adaptun.html
      His original code was translated into python here: https://gist.github.com/endolith/3066664
      I was able to get it to work in a notebook. I'm not fond of his dissonance curve, though. It ignores the appeal of the 7/4, for example. Might that small dip between 5/3 (A natural perhaps), and 2/1 be the 7/4? I'm not eager to duplicate his work. I'm instead just going to choose 12 notes out of the 16 in a utonal or otonal scale and be done with it. Assign the 12 to the most attractive 16. 
      Mode = 'uton' root = 1/1,  Ranks "A" and "C" concatenated
      Before sorting
      scale =  128,     96,      64,    32,     0,      224,   192,   160,     208,     176,     144,     112,      80,      48,     16,      240 
      convert to ratios
      ratios = '4/3', '16/11', '8/5', '16/9', '1/1', '16/15', '8/7', '16/13', '32/29', '32/27', '32/25', '32/23', '32/21', '32/19', '32/17', '32/31'
      convert to floating point and then to cents
      
      After sorting and rolling
                 F         G♭         G♮       A♭       A♮       B♭     B♮      C♮             D♭              D♮             E♭          E♮         F♮
                500       600        700      800      900      1000   1100     0             100             200            300         400        500
      cents     498. , 571.7,  648.7,  729.2,  813.7,  902.5,  996.1, 1095. ,   0. ,   55. ,    111.7,   170.4,   231.2,    294.1,  359.5,   427.4  498
      
      Which ones shall I choose? I think it's time I looked at notes outside the utonal ranks. When did I come up with that huge spreadsheet of different modes in the 216 note scale?
-----------------------------------------
3/15/23 To do today:

1.    Keep working on using the TD31L to make 12TET scales. 
      I found a spreadsheet from 8/13/18 that has what I think are the scales I teased out of the TD31L. Look at the tab for "Transpositions" for the 21 modes available. 
      It has the mode (O or U), the starting note and the order of the 16 notes, which 3rd is used, the starting note in 24ET, the ratio of the first note and the 3rd. The utonal notes are relative to the F, since it's in F minor. The otonal are relative to C. I don't know how they skip around so much. Look at the first Dn row: 2,3,4,5,E,F,1,9,A,B,C,D,6,7,8,G. Wierd. I see what I did there. There are two ranks already. A & B. 1 through 8, then 9,A,B,C,D,E,F,G as the second rank
      Consider Dn: 
       0    1     2     3     4     5     6     7     0     1     2     3     4     5     6     7
       9/8   5/4  11/8   3/2  27/16 29/16  1/1  17/16 19/16 21/16 23/16 25/16 13/8   7/4  15/8  31/16
       pull these from the 1/1 oton 16:
        2   3   4   5   E   F   1   9   A   B   C   D   6   7   8   G 
        9/8 5/4   11/8  3/2   27/16 29/16 1/1   17/16 19/16 21/16 23/16 25/16 13/8  7/4   15/8  31/16

      Also has information in the tab "triads". This has 22 modes, unlike the 21 in the Transpositions version. The Triad skips #18 for some reason.
      Triads has more information that would be useful for the python realization.

      mode4 = np.array()
      Has a nice list of all the thirds. from 1.167 7/6 to 1.292 31/24. from here: https://en.xen.wiki/w/Gallery_of_just_intervals
            septimal     1.167   7/6 
            otonal minor    1.188  19/16
            minor      1.200   6/5 
            supraminor     1.214  17/14
            undecimal neutral    1.222  11/9 
            rastmic neutral     1.227  27/22
            submajor     1.235  21/17 septendecimal submajor third
            major      1.250   5/4 
            smaller undevicesimal major  1.263  24/19 Boethius' major third
            BP3rd septimal major    1.286   9/7 
            sensi supermajor    1.292  31/24
      There are more...

What I did when I first created new ranks in the python dictionary:
                  'E': {'oton': np.array([ 2,  4,  6,  8, 11, 13, 15,  0]), # 3rd: 11:9 neutral
                      'uton': np.array([ 8,  6,  4,  2,  0, 15, 13, 11])}, # 3rd: 6:5 minor
                  'F': {'oton': np.array([ 8, 10, 12, 14,  0,  2,  4,  6]), # 3rd: 7:6 subminor
                      'uton': np.array([ 0, 14, 12, 10,  8,  6,  4,  2])}, # 3rd: 8:7 subminor
                  'G': {'oton': np.array([ 4,  6,  8, 10, 14, 15,  0,  2]), # 3rd: 6:5 minor
                      'uton': np.array([14, 10,  8,  6,  4,  2,  0, 15])}, # 3rd: 5:4 major
                  'H': {'oton': np.array([12, 14,  0,  2,  5,  7,  9, 11]), # 3rd: 8:7 sub-subminor
                      'uton': np.array([5,  3,   1, 15, 12, 10,  8,  6])} # 3rd: 21/17 neutral
Where do those fit in compared to the ones from 8/13/18?

--------------------------
3/16/23 To do today:

1.    Take a look at the Sethares adaptive tuning again, this time in 72EDO. 72√2, or 16.667 cents per step. 
      If I can get it working there, I could always expand it to larger equal divisions of the octave. 
      
      October 01 2018 Playing Music in Just Intonation: A Dynamically Adaptive Tuning Scheme Karolin Stange, Christoph Wick, Haye Hinrichsen
      The paper: https://arxiv.org/pdf/1706.04338.pdf
      Talks about the 23.5 cent pythagorian comma, found by stacking 5ths. Also the 5/4 compared to CGDAE stacking 4 5ths is 21.5 cents.
      Review of the literature on dynamical tuning: GrovenMax [22] was three sets of pipes a syntonic (21.5 cents) apart. Sort of like 56 EDO.
      Others: Justonic Pitch Palette TM [23], Mutabor [24], 
      Hermode Tuning TM [25]: the algorithm tunes intervals between adjacent tones of a given chord instantly to just ratios. At the same time the global pitch is adjusted in such a way that the difference to the usual ET is minimized. 
      TransFormSynth [26]: This is William Sethares tool. His algorithm modifies the frequencies of the higher partials in such a way that they match across a chord. I can't do that with samples. 

      Fundamental concept: The ratio between notes is m/n. The impression of consonance is particularly pronounced if m and n are small. The smaller the better, but no smaller than necessary.
      Their table of a just scale:
            0 Unison 1 1 0 0 0
            1 Semitone 1.0595 16/15 111.73 100 +11.73
            2 Major Second 1.1225 9/8 203.91 200 +3.91
            3 Minor Third 1.1892 6/5 315.64 300 +15.64
            4 Major Third 1.2599 5/4 386.31 400 -13.69
            5 Fourth 1.3348 4/3 498.04 500 -1.96
            6 Tritone 1.4142 45/32 590.22 600 -9.78
            7 Fifth 1.4983 3/2 701.96 700 +1.96
            8 Minor Sixth 1.5874 8/5 813.69 800 +13.69
            9 Major Sixth 1.6818 5/3 884.36 900 -15.64
            10 Minor Seventh 1.7818 9/5 1017.60 1000 +17.60
            11 Major Seventh 1.8878 15/8 1088.27 1100 -11.73
            12 Octave 2 2 1200 1200 0
      Note that the Tritone is 45/32 and a 11/8 uses smaller numbers (11 * 8 = 88 vs 1,440) and the minor 7th uses 9/5, but 7/4 is nicer. (9*5 = 45. 7 * 4 = 28). I think using multiplication of ratios is a nice way to think of consonance. The smaller the product of ratios the better. 
      They track two key values: 
            The absolute pitch: the difference between the pitch called for and the 12TET pitch, in cents.
            The microtonal absolute interval size: the cent difference of an interval
      Two measures:
            Vertical Tuning: all notes played at the time. Choose pitches such that the interval sizes equal values in their table above, which I would suggest is not ideal.
                  For a chord consisting of N tones there are N(N − 1)/2 possible intervals which have to be tuned as just as possible. 4 * (4 - 1) / 2 = 6 possible intervals to examine:
                        C E G A# 
                        C-E, C-G, C-A#, E-G, E-A#, G-A#
                        C E G# Can't be tuned, since C-G# is not equal to 8/5 in the table. 
                  Their solution is table driven, and I'd prefer one that uses optimizations. 
                        C-E = 5/4 
                        C-G# = 25/16, or 13/8? 25/16 is in the otonal scale of 16, so I would keep it. In the paper they erroneously refer to that ratio as 20/16, which it is not.
                        E-G = 5/4 
                  Keep it 5/4 and 5/4. No problem.
                  "This means that this chord cannot be tuned consistently in just intonation" - wrong answer!
            Horizontal Intonation – Adaptive Tuning in the Harmonic Progression - within three seconds, according to the authors.
                  They track a virtual intensity, which means that the delay between notes is a factor to how important the ratio affect is between two notes horizontally. 
                  How fast new notes are introduced reduces the effect of notes in the past. For example, it 10 fast notes are played, we loose track of the notes several notes previously played. If there are fewer notes played over time, then each is more important. They compromize on 1 second for all, which I would say it bogus. Strike 2 in their algorithm. (strike one was the limited table of legitimate ratios)
      And then you need to worry about pitch drift. When do you reset, and how do you move back to the center?
      They consider the problem of determining how to move from one note to another and give the example of a melody of two successive 9/8 ratios. C, D, E. E should be 5/4, but 9/8 * 9/8 = 81/64, too high for 5/4. It would be better to have the second ratio of D to E be a 10/9. How can we determine that choice algorithmically?
      They have a table of alternatives to the table of just scale shown above. But the alternatives are very limited:
      
            1 Semitone 16/15 (+11.73) 25/24 (-29.32) - 2 choices
            2 Major Second 9/8 (+3.91) 10/9 (-17.60) - 2 choices
            10 Minor Seventh 16/9 (-3.91) 9/5 (+17.60) 7/4 (-31.17) - 3 choices including the 7/4
      
      There should be many more choices! And in my experience with retuning hymns in 72EDO, a slide of around 20 cents is indiscernible.
      
      They say their code is available here: www.just-intonation.org Except that web page is gone. Perhaps this one: http://doxygen.just-intonation.org/. 
      Code itself is here: https://gitlab.com/tp3/JustIntonation
      Algorithm is here: https://gitlab.com/tp3/JustIntonation/-/tree/master/application/modules/tuner

2.    This looks like more than I could safely start now. And the end results would be in doubt, especially compared to a carefully chosen well temperament. 
      There are some demo examples, but they are just midi files and I can't see what tuning they have done. I suspect they are just examples to be used to show how the application can retune them. https://gitlab.com/tp3/JustIntonation/-/tree/master/application/resources/media/audio

3.    I was able to install the sagittal font and use it in the Libre Office spreadsheet application. How did I do it?
      ~/Downloads/Sagittal2.0d11.ttf 
      How to set up Sagital to use with spreadsheets.
            https://forum.sagittal.org/viewtopic.php?f=4&t=554
            https://sagittal.org/


      And here is the character map for the Sagittal symbols in Bravura:
            https://sagittal.org/Sagittal-SMuFL-Map.pdf
            https://sagittal.org/Sagittal-SMuFL-Map.xlsx
            https://sagittal.org/Sagittal-SMuFL-Map.ods

      There is currently no index mapping from the old Sagittal codepoints to the new Bravura codepoints. But I have put the following old files back onto the Sagittal web server for you. They are not linked from anywhere but this post. When cross-referenced with the Bravura map above, using the pure long ASCII representation, they allow you to create such an index.

      But if you tell me whether your existing symbols use the version 1 or version 2 mapping, and tell me what spreadsheet format you would like it in, and whether you want the codepoints in decimal or hex, I can create such an index for you. [Edit: Done, below]

            The character map for the version 1 Sagittal fonts:
            https://sagittal.org/v1map/#mid

            The character map for the version 2 Sagittal fonts:
            https://sagittal.org/Sagittal2_character_map.xls
            https://sagittal.org/Sagittal2_character_map.ods

      The last version 2 Sagittal font:
            https://sagittal.org/Sagittal2.0d11.ttf
            The latter is what I downloaded and it started working eventually. 

4.    For now, lets just pick a 12 tone scale out of the 256 for f minor and see what it sounds like using ball4.csd. Terrible. Really, really bad. 
      What if I choose from all 256 notes and get the ones that are closest to the 12ET cent counts.
      I just found VRWT in Ab and it sounds wonderful. Lots or tonal variety and wolf notes for contrast. The piece ends in Ab major, starts in Eb major, yet muspy labels it as F minor. 

-----------------------------------------------
3/18/26 To do today:

1.    Find a way to spread out the octaves. My first effort was hindered by forgetting that I need to affect each octave value on octave_array differently.
      I started out with this:
            octave_array += (rng.choice(6, p = [.1, .2, .2, .2, .2, .1]) - 3) # just one number would affect them all the same way. Wrong!
      Then I made an array of values to affect each one differently:
            print(f'prior to spread: {[np.average(voice) for voice in octave_array]}')
            octave_array += (rng.choice(6, size = octave_array.shape, p = [.1, .2, .2, .2, .2, .1]) - 3) # spread out the octaves add 0,1,2,3,4,5 - 2 = -2,-1,0,1,2,3
            print(f'after spread: {[np.average(voice) for voice in octave_array]}')
      That was nice, and accomplished what I wanted, but it sounded random. I need to do what I did previously, which is to affect them in large chunks of 10-20 notes before changeing to another value. There was a function that did that. It was in coconet-csound

--------------------
3/19/23 To do Today:

1.    Try this before you use the old smelly way:
      def build_octave_alteration_mask(repeats, voices, chorale):
            octave_alteration_mask = np.empty(0, dtype = int)
            done = False
            while not done:
                  some_octave_change = rng.choice(6, p = [.1, .2, .2, .2, .2, .1]) - 2 # returns a single number 0,1,2,3,4,5 - 2 = -2,-1,0,1,2,3 rarely hitting the largest and smallest values
                  some_repeat_value = (1 + rng.choice(5, p = [.1, .3, .2, .2, .2])) * repeats
                  repeated_octave_change = np.repeat(some_octave_change, some_repeat_value, axis = 0)
                  octave_alteration_mask = np.concatenate((octave_alteration_mask, repeated_octave_change), axis = 0)
                  done = octave_alteration_mask.shape[0] > chorale.shape[1] 
            octave_alteration_mask = octave_alteration_mask[:chorale.shape[1]] # cut off the excess array elements
            return np.array([np.roll(octave_alteration_mask, iteration * repeats, axis = 0) for iteration in np.arange(voices)])
      Seems to work.

2.    Add the woodwinds slowly changing. This worked out very well. That's two successes in one day.       

3.    I'd like to add some flute with slides but I don't have a way to slide between note numbers in a well tempered scale. 

4.    Try another chorale. See what breaks. Not much. Sounds pretty good.

5.    Fix the ending. Fade out at least. It sounds all wrong. I suppose most have turned it off already...

6.    Maybe balloon drums in a tight repetitive loop. like 7 & 8 alternating? to total 15.

7.    Envelope feature mod Transferred to 3/21/23

8.    Make the function table f3 setable for each chorale based on the key:
            f3 0 16 -2  0 0.0091260  0.0185738  0.0292217  0.0387788  0.0486861  0.0590156  0.0684491  0.0792180  0.0886842  0.0989189  0.1089010  0.1184236       
      Keep track of the ratios and use those to set up glissandi and trills.
      I show the initial key of a ratios for the key of C as:  
      1/1 19/18 83/74 19/16 64/51  4/3 24/17  3/2  19/12 57/34 16/9  32/17  2/1 
      Key of A
      1/1   18/17   9/8   19/16 323/256 171/128  24/17    3/2    27/17  27/16  57/32 513/272   2/1  
      Where did I get those?

------------------------------
3/20/23 To do today:

1.    Start with #8 from yesterday.
     
      George Secor's Victorian rational well-temperament (based on Ellis #2) 
      Check for the origin of VRWT in the scala archive:
            cat secor_vrwt.scl
            ! secor_vrwt.scl
            ! 
            George Secor's Victorian rational well-temperament (based on Ellis #2) Best in C, ok in F, G, Bb, Eb
            12
            !
            545/516
            6071/5418
            707447/595980
            755/602
            30118/22575
            30535/21672
            451/301
            34315/21672
            1514/903
            2755/1548
            20365/10836
            2/1
      
      Those are some very high ratios!
      In python:
      vrwt = np.array(['1/1', '545/516', '6071/5418', '707447/595980', '755/602', '30118/22575', '30535/21672', '451/301', '34315/21672', '1514/903', '2755/1548', '20365/10836', '2/1'])
      How will I use this.
      a.    Need to be able to transpose to other keys. Convert to decimal ratios, then multiply by the ratio of the destination key. Then what? The spreadsheet is kind of a hack. To create the D major, it starts with 9/16 times the Bb to make the C, then 9/16 times the B to make Db, the 9/16 times the C to make D and so on. But in the end it doesn't create a 1/1 or 2/1. Gets damn close. 1.8 cents off. Close enough for my use. How could I improve on that? Change 16/9 to 1548/2755.
      I'm thinking I need to use excel what-if goal seeking method to do this work. I'm sure there is some mathematical calculation that I could do, but let's just get it done and move on. The Office 365 web version of excel did not have goal seek, nor did the LibreOffice implementation. But the version inside Windows 11 had it. 

      So now I have two keys finished C major and D major, and a file called scala_ratios_from_excel.txt that has a few others. Next, I need to figure out how to assemble the f3 function table and insert it into the csd file, replacing the one that's there. I could just add it later, and csound will pick up the last one I think.

----------------------------------
3/21/23 To do today:

1.    Pick something small from the enhancements you have been writing about lately. Try #7, feature mod.
      Make the choice of envelope changeable outside of the build_notes_features_from_chorale function.
      take the upsample, envelope, gliss, and velocity and make them rng.choice(values, p = probability) and allow the caller to change values and probability during the call.
      build_notes_features_from_chorale now has guev = np.array([0, 0, 1, 74]), which sets the values once and keeps them for the whole piece. That's way too restrictive, since it has one value for the whole chorale.
      We need three numbers: the index, the values, and their probabilties, for each of those four features.
      
      Make a set of feature collections with probabilities that extends over the whole chorale.
      Then for each feature, have that collection affect the individual choice in some way.
      For example: create an envelope_curve with dimension that will be maybe 10 items. Build a list of envelopes, indexed by current_envelope_index. Like this, maybe:
            envelopes = np.array([[1, 16, 8], [2, 8, 8], [1, 16, 17]])
            envelope_prob = np.array([[.5, .3, .2], [.4, .3, .3], [.2, .4, .4]])
            envelope_index = rng.integers(3, size = envelopes.shape[0], dtype = int)
            Then at various points: 0     #            2                     1 = 1
                                    1     #            2                     2 = 2
                                    2     #            2                     3 = 2
                  envelope_index = np.min((envelopes.shape[0] - 1, envelope_index + 1))
            This way it can't get too big. 
            When you need an envelope:
                  env = rng.choice(envelopes[envelope_index], p = envelope_prob[envelope_index])

2.    Make a very short chorale that you can test ideas on. Found a nice on in D major
            print(f'{[metric for metric in metrics[-500:] if (metric[11] == "D major") and (metric[4] > "3")] = }')
      
3.    While doing that, I picked one of the shortest and least entropic chorale, with only 4 distinct notes and dimension (4,61) which after repeat by 15 is (4, 915). Then double voices and it's (8,915). But the density_function.shape = (8, 900). How is that calculated in the finger_piano_part:
            density_function = rng.choice(2, size = (voices, (repeats * 2) - 1), p = [.3, .7])
      The reason for this is important. It makes sure that there is a repeating pattern across 29 notes. We don't want it across all the notes, we want it to repeat. The key is to make it larger than what you think you need, then clip it to the desired length at the end.
            density_function = np.tile(density_function, chorale.shape[1] // density_function.shape[1] + 1) # add one so that you get a longer density function than you need.
            ... 
                  octave_array.shape = (8, 1095), density_function.shape = (8, 1110) # too long, that's ok.
            ...
            notes_features_6[1] = octave_array * density_function[:, :octave_array.shape[1]]

4.    Well, I accomplished what I set out to do with the features mod enhancement in #1 above. 
      The problem is that since the features change from one note to the next, piano_roll_to_notes_features assumes they are different notes. So everything is a 1/16th note. Oops. I only want to change the features if the note changes. So I have to look at every note to see if I want to assign a new feature, and if not, assign the one previously assigned. This wasn't a problem before because all the features, other than note and octave, never changed. 
      How hard would it be to check if the note changes before assigning a feature, and saving the previous feature to assign that if it doesn't change. Not hard at all. Done. Almost. After the first held note was perfect, all subsequent notes reverted to 1/16th notes. I must reset prev_note at the end of the loop.

5.    But I need different envelopes for each instrument, not the same ones for all instruments. 
      That's a bit more complicated. The problem is I am prematurely assigning features in the build_notes_features_from_chorale, since I'm reusing the notes, octaves and the other feautures in multiple downstream functions. 

      I can't assign the features until I know what instrument group I'm working on, and I won't know that until I'm in the finger_piano_part and the woodwind_part. I'l have to remove the assignment of features from the build_notes_features_from_chorale and move that to the finger_piano_part and woodwind_part. That's the soonest I'll know what instrument group I'm in. 

      Time for a walk in the sunshine.

---------------------------
3/22/23 To do today

1.    Remove the feature selection from build_notes_features_from_chorale.
      Limit it to just (voices, notes, octaves) or some combination thereof. The first dimension should be samples, and the following dimensions apply to that sample. So is the sample the notes, the voices, or the octave? I'm going to go with voices, notes, octaves for now.
      So I finished, but all the envelopes are 16. I think it mistakes different notes for the previous note. Fixed that, but now all the notes in the 1/3 size sections have the same envelope. Something is wrong with the rng.choice operation:
            (array([-1,  0,  1,  2]), array([  2,   3, 286,   1]))
            (array([ 1,  8, 16, 17]), array([284,   1,   4,   3]))
            (array([70, 72, 74]), array([  5, 282,   5])) 
      The problem is that the indexes quickly go to 2 prematurely. This is getting me angry...
      I see new notes in the first third, then no more after that. That's sounds wrong to me.
            first note in voice: voice = 0 notes[voice, 0] = 4
            new note: voice = 0, note = 8, notes[voice, note] = 6, gls_i = 0, ups_i = 0, env_i = 0, vel_i = 0
            new note: voice = 0, note = 16, notes[voice, note] = 4, gls_i = 0, ups_i = 0, env_i = 0, vel_i = 0
            new note: voice = 0, note = 20, notes[voice, note] = 2, gls_i = 0, ups_i = 0, env_i = 0, vel_i = 0
            note = 24, note % break_point = 0, ups_i = 0, env_i = 0, vel_i = 0
            note = 48, note % break_point = 0, ups_i = 1, env_i = 1, vel_i = 1
      I'm working with a very short file sample4788.mid, two measures long 28 notes in each voice. Yet when I read in the numpy file, it's (4,73)
      It was because of this: 
            chorale = np.concatenate((chorale, np.repeat(chorale[:,-1], repeats * 3, axis = 0).reshape(4, repeats * 3)), axis = 1)
      It takes the last note and repeats it 15 * 3 times. Leaving 28 * 45 = 74. That explains why we didn't change notes, because there were no note changes. Duh!
      So now it works. What else can I vary?
            a.    density_function = rng.choice(2, size = (voices, (repeats * 2) - 1), p = [.3, .7]) # <-- this is the same loop for the whole piece
                  It would be nice if I could vary the p factor at various point. p = [.01, .99] makes a very sparce collection of held notes.

--------------------------------
3/23/23 To do today

1.    Make sure the split in thirds is actually doing a split in thirds. 
      Both the finger piano and woodwinds have three alternatives for features.
            guev_array.shape = (8, 3, 2) (features, sections, alternatives) where features has two arrays, one for choices, the other for probabilities.
      I checked and it is working as designed. 

2.    Make sure the following is working properly:
            probs = [[.2, .8],[.3, .7],[.4,.6],[.01,.99]]
            density_function = np.array([rng.choice(2, size = (voices, (repeats // 2) - 1), p = prob) for prob in probs]).reshape(8,-1) 
      
------------------------------
3/24/23 To do today:

1.    I'm not comfortable with the VRWT realizations. Some of the chords have prominent beating. 
      I could draw attention to them, and highlight how they delighfully showcase the good keys and the bad keys. Kind of like asking the listener to admire the different lipsticks on a pig. That may be too harsh. Or I could explore ways to fix it:
      a.    Try a different transposition of the VRWT. For example, change from D to A, or G and see how that sounds. Quick, but may miss the gem.
      b.    Systematically evaluate all the chords, their durations, frequencies, and consonance with each of the potential VRWT transpositions. This would require determining the ratios or cents of all the transpositions, loading them into a set of arrays, and calculating the cents from just from those ratios or cents for all the chords in the piece. The one that has the lowest cent errors would be the one I choose. Result: the best VRWT possible. 
      c.    Switch to 72 EDO, and use a reinforcement learning approach to finding the best path through the chorale that minimizes the distance from ideal. After completing this, then calculate how to get from one pitch variety to another using glissandi. Or do the same with the 256 in TD31L. 

      The "c" alternative is a real stretch for me. I haven't really done much with reinforcement learning in a while. I could start small with just a three chord MIDI file that contains an example from one of my hymn pieces of a challenging chord progression involving a note that would need alteration from one chord to another. I went looking for it a while ago and found it, but didn't write down where it was.
      
      I did a great deal of work with Herzliebster Jesu here: http://ripnread.com/herzliebster-jesu-original-4-part-harmonization-in-72-edo/ from 11/17/2015
      Also found a spreadsheet microtonal 11-15-15.xlsx in csound/Archive that had each chord and note listed, with 72 EDO note number, sagittal name (wrong font), ratio, and move from the previous note in 72-EDO steps. I did all this by hand. Amazing. And no-one cared. And I did not save the pdf that had all the note numbers.

      So I'm starting the conversion to 72 EDO from a midi number. Should I start with the default value for all the notes? After all, 72 EDO translates from 12 EDO 1:1. 

      Somehow the octaves are getting as high as 900. Not right. I fixed that, but the number being calculated in the ball5.csd is wrong for iMIDInumber.
      I'm loading the right values from the midi file, but the calculation in the ball5.csd is whack:
            chorale.shape = (4, 192), [79, 74, 66, 62]
            max octave in build_note_octave: [6, 6, 5, 5]
            instr 1:  p5 = 3.000  ipitch = 3.000  p6 = 5.000  ioct = 5.000
            instr 1:  iMIDInumber = 360.000
            instr 1:  p5 = 11.000  ipitch = 11.000  p6 = 3.000  ioct = 3.000
            instr 1:  iMIDInumber = 1136.000
      in the csd file:
            ioct = p6 
            print p5, ipitch, p6, ioct
            iMIDInumber = int(12 * ipitch / .12) + 12 * ioct
            print iMIDInumber
      My goal is to use 72 EDO, so I need a new value for the imidi calculation.

-------------------------
3/25/23 To do today:

1.    Get the ball5.csd working correctly. 
      I made one small change and everything works in 72 EDO now. In build_note_octave:
            note = np.array([(midi_number % 12) * 6 for midi_number in chorale]) # 72 EDO default values
      Just multiplied what used to be a number in midi_number % 12 by 6, and now we have each of the 12 ET values represented in 72 EDO. This makes a good starting point. Now to tweak them to make it sound better.
      midi % 12:    0     1     2     3     4     5     6     7     8     9     10    11
      keys_sharps: 'C♮', 'C♯', 'D♮', 'D♯', 'E♮', 'F♮', 'F♯', 'G♮', 'G♯', 'A♮', 'A♯', 'B♮'
2.    First method: 
      a.    Determine what the purpose of the chord is: major, minor, suspended, etc.
            you must include all inversions.
            major = {0,4,7}
      b.    lookup in a table for the ideal notes to use instead of the defaults

3.    How to use music21 to simplify the process:
      the display doesn't work. I found someone who fixed it on Windows, and I was able to use it on linux with a modification:
            from music21 import * # I changed this to avoid name collisions
            import music21 as m21
            m21.environment.set('musescoreDirectPNGPath', '/usr/bin/musescore') # required for finding mscore
            s = corpus.parse('bwv244.3') # Herzliebster chorale from St. Mattew's Passion.
      https://web.mit.edu/music21/doc/usersGuide/usersGuide_24_environment.html describes all the environment issues.
      The Music21 corpus has it in a different key. Mine is in Ab, theirs is in A. 
      But is can provide a terrific analysis:
            0 b minor
            1 b minor
            2 b minor
            3 F# major
            4 D major
            5 D major
            6 D major
            7 D major
            8 D major
            9 e minor
            10 b minor
            11 B major
      So in this way I can build some prearranged alterations to deal with all these chords.
      How can I convert from the Music21 to MIDI, or other form I could use. Muspy has 
            music = muspy.from_music21(stream: music21.stream.base.Stream, ...
      That worked. So I now have the music21 corpus version of Herzliebster in a numpy file performed by csound in 72 EDO, but only the 12 ET subset. Next, modify the notes to make the above list of chords sound better in real 72 EDO. Then do just. 
      But will this method work with the TonicNet midi files? Yes, because muspy can take a muspy music object (from MIDI) and convert it into a music21 object.
            music21 = muspy.to_music21(music)

4.    Use the Herzliebster music21 analysis to create a 72EDO version with tuned intervals. What are the 72 EDO intervals for major and minor chords?

----------------------------------------
3/26/23 To do today:

1.    Keep working on the ways to tune the Herzliebster hymn to near-just in 72 EDO. Notice that the step counts in the work I did yesterday are wrong. Fixed it. I had the order of the parameters to the function closest_step_to_just backwards. Fixed it. Notice that the array close_72EDO is an array of strings. It will need to be converted to integer upon use. The good thing about that is it will match the ratios expected by the diamond_music_utils.py library. That will help with glides and trills.

-------------------------
3/27/23 To do today:

1.    Go back to ball4, the two 25 minute pieces. See TonicNet_Csound_Arpeggios.ipynb. 
      See if there isn't some way to vary the rhythm. 15/16 gets old after a while. They key is to vary it in both instruments. That means replacing:
            voices = voice_names.shape[0] # if you want it to last twice as long, make twice as many voices: voice_names.shape[0] * 2
            chorale = np.repeat(chorale, repeats, axis = 1) # make each note repeats times as long
            print(f'after repeating each note {repeats = }: {chorale.shape = }')
            chorale = np.repeat(chorale, voices // 4, axis = 0)
      Which is in both finger_piano_part and woodwind_part with something more interesting. It will need to yield the same dimensions in both voices.
      While you are at it, see if the following is being processed correctly. The last probability is designed to make the finger piano much less dense, since it has far fewer zeros, and therefore the notes should mostly last as long as the repeats.
            probs = [[.2, .8],[.3, .7],[.4,.6],[.01,.99]] # from mostly ones, to half and half Note: p = [.01, .99] makes a very sparce collection of held notes.
            density_function = np.array([rng.choice(2, size = (voices, (repeats // 2) - 1), p = prob) for prob in probs]).reshape(8,-1) 
      How long is the density function? (8,24) then (8,25). I was planning for it to be across the whole piece, and since I tile it, it exceeds the length of the piece after this:
                                          (8,25)          6480             //  25 = 259 + 1 = 260           260 * 25 = 6500
            density_function = np.tile(density_function, chorale.shape[1] // density_function.shape[1] + 1)
            print(f'{octave_array.shape = }, {density_function.shape = }') # octave_array.shape = (8, 6480), density_function.shape = (8, 6500)
      So it appears to be doing what I planned. I think I need to mix up the alternatives. I did that. It's working as designed. It's just hard to create much variety out of different envelopes in the finger piano.

2.    Finish up the conversion to predesignated conversion of 12 EDO to just 72 EDO approximations. 
      Question: Do I want to look just a the notes in chorale, or should I also look at the chords as determined by music21. I suggest the best course would be to find the chord on my own in the notes in chorale, then check them against the ones that music21 finds.
            
------------------------------------
3/28/23 To do today:

1.    Fix the tuning. I need more traces to see what is happening.
      The first few traces told me nothing, but I soon noticed that i was getting 11/8 ratios in the first chord. Not right. Sounded terrible:
            found_steps = [65, 33, 12, 65], ['15/8' '11/8' '9/8' '15/8'], [1088.3  551.3  203.9 1088.3]
      I was screwing up the conversion from edo_12 to edo_72. The hand crafted arrays assumed it would start at B and end at A#, but the numbers coming in had B as 11, so I should have B in the #11 spot, not the starting spot. That was wrong, and when I fixed it:
            edo_12_nums = np.array([  0,    1,     2,   3,    4,    5,   6,    7,   8,    9,   10,  11])
            edo_12_names = np.array(['C',  'C#',  'D', 'D#', 'E',  'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'])
            edo_12_ratios = np.array([16/15, 9/8, 6/5,  5/4,  4/3, 11/8, 3/2,  8/5, 5/3,  9/5, 15/8, 1/1 ])

            edo_12 = array([71, 66, 62, 59]), [11, 6, 2, 11]
            found_steps = [0, 42, 19, 0], ['1' '3/2' '6/5' '1'], [  0.  702.  315.6   0. ]
      It's a shame that Fraction changes 1/1 into just 1. But I guess it's expecting a fraction, and it is delivered an integer. It sounds much better now. Let's try a more complext chorale. Actually, this one uses 11 of 12 pitches (not the F natural 11/8), and pitch class entropy of 3.05, which is midway from the most simple to the most complex.

2.    Now do the extended routine from  TonicNet_Csound_Arpeggios.ipynb. I was able to integrate all the codes from the music21 into that and created TonicNet_Csound_Arpeggios Herlz.ipynb.
      Unfortunately, there are long sections of silence and very low bass finger pianos in that version. I think there might be an octave issue.
            print(*[np.unique(octave, return_counts=True) for octave in octave_array], sep = '\n')
            (array([-2, -1,  0,  1,  3,  4,  5,  6,  7]), array([360, 384, 312, 108,  72, 588, 612, 264, 432]))
      These are the values for octave_array. Something is causing it to include some very high and very low values
      But the octave_alteration_mask is quite modest:
            octave_alteration_mask buckets
            (array([-2, -1,  0,  1]), array([672, 792, 960, 852]))
            octave_array prior to spread:
            (array([0, 5, 6]), array([1452,  864, 1104]))
      Why are the only octaves 0, 5 * 6? I guess that's conceivable. But why the large chunk of zeros? This is prior to the primary masking. But the primary problem is the spreading out of the octaves in octave array. What is causing that? The zeros in octave_array. Those are one problem. 0 - 2 is -2. And that is a problem. 
      I can only guess that a zero value in a note is to indicate that the voice is not playing during that time_step. So zero is valid for the octave as well. But it screws up the octave spread routine. 

-----------------
3/29/23 To do today      

1.    Try Herzliebster with actual just ratios instead of 72 EDO. Do the same with a D minor tonicnet synthetic chorale.
      a.    Convert the ratios in edo_12_ratios to fractions of an octave.
      b.    Modify ball5.csd to include those values
      c.    Modify TonicNet_Csound_Arpeggios Herlz.ipynb to use midi % 12 as the note instead of the complicated conversion to 72 EDO.

      I'm having trouble with the notes being way out of tune:
            
            These are for C minor just
                          C      C#        D          D#         E          F          F#        G         G#         A        A#         B          C   
                          1/1   16/15      9/8        6/5        5/4       4/3       11/8       3/2,       8/5       5/3       9/5       15/8       2/1 
            f3   0 16 -2  0    0.01117    0.02039    0.03156    0.0386     0.0498   0.05513    0.0702    0.08137    0.088439  0.10176    0.10883    0.12
      
      I can easily get to B minor by removing the first 0, but how can I do other keys?
                            C           C#          D         D#         E         F       F#      G        G#        A        A#          B
                            16/15       9/8        6/5        5/4       4/3       11/8     3/2,   8/5       5/3      9/5      15/8        2/1 
            f3   0 16 -2    0.01117    0.02039    0.03156    0.0386     0.0498   0.05513  0.0702  0.08137  0.088439  0.10176  0.10883    0.12
            In each of these cases the ratio reflects the relationship of the note to the root key of B as 1/1.
      This took several hours to figure out how to fix, but I got it done.
      
-------------------------
3/30/23 To do today

1.    Figure out a way to take the C minor above and transpose it into D minor. The way I did B minor won't work. 
      a.    The spreadsheet starts on the target root in the new array, in this case D is a copy of the 0th element in the C minor just scale times a constant, which will be determined later. If the result is less than one then multiply by 2 to keep it in range.
      b.    continue that arithmetic as you move down the scale:
            D =  C ratio * constant 
            D# = C# ratio * c
            E = D * c 
            F = D# * c
            F# = E * c
            G = F * c 
            G# = F# * c 
            A = G * c 
            A# = G# * c 
            B = A * c 
            C = A# * c 
            C# = B * c
            Here are the csound numbers for D minor from Libre Office using their goal seek function:  
            ;          C     C#         D         D#        E         F           F#         G           G#          A          A#         B           C
            f3 - 16 -2 0  0.0070673  0.0182404  0.0294135  0.0386314  0.0498045  0.0568718  0.0680449  0.0733722  0.0884359  0.0996090  0.1066763  0.1200000 

---------------------------------
3/31/23 To do today:

1.    I have it working in d minor up from the c minor just scale. 
      I made one change, to remove 11/8 and replace it with 45/32, a 4/3 below the B at 15/8. That wipes out the wolf. It wasn't present in the b minor because f natural was never used in the b minor chorale herzliebster. 
      I'm not sure about this synthetic chorale I first chose. 
            midi source entropy length key [array(['sample4102.mid', '3.233', '153600', 'd minor'], dtype='<U32')]
      It starts in F major, wanders about a lot, and ends in A major. I'm going to try another one. 809 sounds better.

2.    I'm listening to some of these results and finding some things I'd like to try to avoid too much predictability in the output.
      Of course, it only sounds predictable to me because I've heard so many of them. But still, I am my primary audience anyway, so why not? 
      a.    Do a shuffle on the guev_array = np.stack((gls, gls_p, ups, ups_p, env, env_p, vel, vel_p), axis = 0)
            Its in the finger_piano_part and the woodwind_part. This will have to be carefully done so that I don't screw up the associations. I only want to shuffle the last dimension, I think. Its an inplace shuffle so I don't assign it like other functions:
                  rng.shuffle(guev_array, axis=2) # 2 is what I want for the dimension
      b.    I'd really like to spend more time in the sections of the chorale that have higest pitch class entropy.
            If I could evaluate them, and do some tiling of them. Perhaps before I send it through the instrument functions.
      c.    Maybe some balloon drums? or bass flutes? strings?
      d.    slides

-------------------------------------
4/1/23 To do today: Saturday

1.    Make changes to the base csd files so they can run in both wsl and linux.
      change this:
            /home/prent/Dropbox/csound/McGill/Partition I/FingerP/c1.aif
      to this 
            ../../csound/McGill ...
      Is there a way to do this across all .csd files? Here's an example: https://askubuntu.com/questions/655496/how-to-edit-multiple-text-files-with-a-single-command#:~:text=You%20can%20use%20sed%20%3A%20sed%20-i.bak%20%271s%2F%5E.%2A%24%2Fnew,just%20use%20%3A%20sed%20-i%20%271s%2F%5E.%2A%24%2Fnew%20line%2F%27%20%2A.txt
            sed -i.bak '1s/^.*$/new line/' *.txt
      or if you have rpl
            rpl "myFlag=True" "myFlag=False" *.cfg
      I was able to make the change incredibly easily:
            mkdir temp
            cd temp
            cp ../*.csd .
            rpl "/home/prent/Dropbox/csound/McGill" "../../csound/McGill" *.csd
            cp temp/*.csd .
            rm -rf temp
      Neat.

2.    At 0:56 in the latest d minor chorale, the wolves are out in force. It returns to the sweet just by 1:40. 
      I think I need to go back to the pursuit of adaptive just using 72 EDO. If it works, scale it to cents, 1200 EDO.

3.    Still trying to get code-server running a jupyter notebook. This time with 
            code-server serve      
      open on: 
            https://insiders.vscode.dev/+ms-vscode.remote-server/ThinkCentre/mnt/c/Users/prent/Dropbox/Tutorials/TonicNet
      Get it to use the jupyter kernel here:
            http://localhost:8888/?token=0005bf37ecfcb8ceed08f3f64a32f26431e7d2bd89e66b79 
      
      Still fails in first cell with 
            ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
                        ImportError: 
      I'm thinking it might be something to do with PYTHONPATH
            export PYTHONPATH=/home/prent/virtual_python3.11/bin # on fedora linux 
            export PYTHONPATH=/home/prent/virtual_python3/bin # on fedora linux in wsl
      After I issued that command in a terminal session, and then reconnected to the jupyter environment, selected the python path that pointed to 
            ~/virtual_python3.11/bin/python
      Which points to 
            ls -lth virtual_python3.11/bin/python
                  lrwxrwxrwx 1 prent prent 10 Mar 30 12:54 virtual_python3.11/bin/python -> python3.11pyt
             python --version
                  Python 3.11.0rc1
      It seems to work now.
      Until it didn't
            Original error was: No module named 'numpy.core._multiarray_umath'
      Then I killed the jupyter server and the code-server and started a new one up and I'm getting the same error.
      I even selected the python environment explicitly:
            ~/virtual_python3.11/bin/python
      I had to go back and reselect the very same kernel, and then it worked. Not a lot of fun.

4.    Posted the latest synthetic chorale in D minor with all the wolfs on ripnread.com, twitter, and facebook.

5.    I'd like to go back to my 72EDO and see if I can't use that to create a near accurate dynamic tuning.
      What I see is creating a matrix like the ones I used back when I originally put together the Herzliebster in 2015. Here is one for c minor just.
            C     1/1
            D#    6/5   5/6   
            G     3/2   2/3   4/5
            C     1/2   1/1   6/5   3/2 

      It's a matrix, and the first column is the ratio of that note, the next is the distance between 1st and the 2nd, 3rd, 4th, the next column is the distance from the 2nd to the 3rd, 4th, and the last from the 3rd to the 4th. All combinations of the four are covered. That may not make sense, but the goal is to assemble a matrix of all the notes sounding at that time, and come up with a metric for that combination. 
      For example, multiply 5 * 6 + 2 * 3 + 1 * 1 + 4 * 5 + 6 * 5 + 3 * 2 = 93 
                              30  +   6   +   1   +  20   +  30   +   6   = 93
      If another combination of ratios produces a lower number using this method, it's assumed to be a more consonant chord, and should replace the one you were going to use.
      
      They make changes to one note by +-5 72_EDO steps and see if it improves. Do that for all four notes and pick the best mix. Or something like that.

      Next step is to take the ratio distances and find a way to evaluate them in terms of the size of the numerator and denominator. Once you get the distance in a ratio, you can obtain the numerator and denominator using this:
            n, d = ratio.split('/')
      There may be a way that doesn't require so many steps. Maybe Fraction without the str
      I figured it out.
      The next step is to make modifictions to the 72 EDO steps seeking a lower score from the sum of the products of the numerators & denominators.

      change the first number to all the different choices for the first number
            for alt in np.arange(-1, 2, 1): # -1, 0, 1
                  change the 0th element and run the compare 
                  if the score is lower:
                        save it. 
                        save the numbers that gave that score.
                  
      Example:
            chord1  = array([60, 64, 67, 69]) # major 7th in the c minor just scale
            scale degrees: chord1 % 12 = array([0, 4, 7, 9])
            in 72 EDO: chord_72_edo = array([ 0, 23, 42, 53])
            So I've figured out how to test every alternative without duplication. It took about 3 hours to do so. It takes almost no time to run the test with -2, -1, 0, 1, 2 steps from each of the four notes in the chord. 
            %%timeit -n 10 says: 44.5 ms ± 1.3 ms per loop 
            This could scale to larger numbers of smaller steps quite easily, except that I need to systematize the process.
            For every note in the chord, I'll need something that duplicates this:
                  alt0 = chord_72_edo[0] # isolate one of the elements in the chord
                  alt0 = np.array([(alt0 - 2) % 72, (alt0 - 1) % 72, alt0, (alt0 + 1) % 72, (alt0 + 2) % 72])
                  # then spread them out, making sure you stay in the 72 EDO limit. 
                  # you need to do this for all the notes in the chord being examined. 
            
---------------------------
4/3/23 To do today:

1.    Try the score function with some chords that are not expected in the d minor just scale.
      Problem: The chord returned by the score function is the same as the one passed to it, even if another chord was "better". Not so. I was reading the output text incorrectly, mixing up the tested_chords count with the min_score value. It's working as designed.

2.    Problem. I have some ratios in my d minor.scl that aren't in the list of 72 EDO ratios. 
      I'm thinking I need a more advanced way to associate ratios in the 12 note scale and the 72 note scale.
      For example, G in the D minor is 40/27 which is not in the 72 ratio list. I have 46/31, 3/2, 44/29, but no 40/27, which is 680.4 cents. A poor 3/2. I replaced 40/27 with 3/2 and tried it again. It worked. But I need to make sure I don't choose 12 tone ratios not in edo_72_ratios.
      Now the improved chord is not getting returned correctly:
      What was sent for evaluation:
            '1', '5/4', '3/2', '16/9'
            step_in_12_edo = array([ 0,  4,  7, 10])
            test_chord_72_edo = array([ 0, 23, 42, 60])
      What was found:                      
            new_chord = array([ 0, 23, 42, 58]), score = 161, tested_chords = 311, min_score = 161,
      What was returned:
            improved_chord = array([ 0, 23, 42, 53])
      It was because I had removed the assignment to improved_chord, so it was just using the old value over and over. Oops. 
      
      What if I just ignore the initial just scale and stop worrying about it. Let's see what 12 EDO looks like. It seems like it requires fewer changes from the D minor just scale. 
      Here's a b minor chord using as close to 12 EDO as I can get in 72 EDO ratios.
            ['17/9', '9/8', '17/12', '17/9']
            test_chord_72_edo = array([66, 12, 36, 66])
            new_chord = array([64, 11, 34, 64]), score = 75, tested_chords = 26, min_score = 75,
            new_chord = array([66, 13, 36, 66]), score = 75, tested_chords = 338, min_score = 75,
            improved_chord = array([66, 13, 36, 66])
            ['17/9', '17/15', '17/12', '17/9']
            Limited movement produced a great score. 75 is the lowest I've seen. Notice that I have two choices here that had the same score. What to make of that? Could I use one more than the other? 

3.    How will I use this new-found capability? Should I revise all the notes from 12 MIDI to 72 octave note?
      Then mass change all. No way. It has to be situationally handled. Every chord gets their own chance to be the perfect tuning. Go for a walk and think about it.

-----------------------------
4/4/23 To do today:

1.    Systematize check_different_steps (and find a better name). def tune_step_choices
      a.    Make it so it is extendable with fewer changes.
      b.    Reduce the use of literals. Change from this:
                  alt0 = chord_72_edo[0] 
                  alt0 = np.array([(alt0 - 2) % 72, (alt0 - 1) % 72, alt0, (alt0 + 1) % 72, (alt0 + 2) % 72])
            to this:
                  mod_values = np.arange([-3, 4, 1]) # -3, -2, -1, 0, 1, 2, 3
                  alter_array = np.array([[(note + inx) % edo_value for inx in mod_values] for note in chord_72_edo])
            This makes it so I just need one line to accomodate all EDO's and all range alterations. Just change mod_values to widen the range, and edo_value from 72 to 1200 for cents. But I'll need a table of ratio values for all the 1200 cents to replace edo_72_ratios in the score function.
                  
      c.    Return all the best choices in an array with scores and list of notes.
                  results = array([[63, 10, 33, 63],
                        [64, 11, 34, 64],
                        [66, 13, 36, 66]])
                  [['11/6', '11/10', '11/8', '11/6'], ['50/27', '10/9', '25/18', '50/27'], ['17/9', '17/15', '17/12', '17/9']] 
            Looks good. I think this is wrongly influenced by the ratios chosen in edo_72_ratios. But that can be fixed if I shift to 1200 cent resolution. Later.

2.    Here is the current information provided by the tune_step_choices:
            These are the scale degrees, note names and ratios used to match the 72 EDO scale:
            0 1 2 3 4 5 6 7 8 9 10 11
            C C# D D# E F F# G G# A A# B
            1 18/17 9/8 19/16 24/19 4/3 17/12 3/2 27/17 32/19 16/9 17/9 2
            finding best 72 EDO steps for the following chord
            original 72 EDO notes: starting_72_edo_chord = array([66, 12, 36, 66]) 
            B D F# B
            these are the preferred 72 EDO steps to use to make this chord most consonant
            [63 10 33 63]
            [64 11 34 64]
            [66 13 36 66]
            these are the ratios of the chosen 72 EDO chords:
            ['11/6', '11/10', '11/8', '11/6']
            ['50/27', '10/9', '25/18', '50/27']
            ['17/9', '17/15', '17/12', '17/9']
      Notice that all three are the same number of steps from one note to the next. This leads to the question, why wasn't 65 12 35 65 chosen? Big red flag time. The answer is that those notes scored 10951, compared to the 75 for the others. Why? Because the ratios in the edo_72_ratios table for those steps were different from the others. And those ratios are the ones used in the calculations. What would happen if I just did a brute force assignment of ratios to the edo_72_ratios array. 
            edo_72_ratios = np.array([np.power(2, step/72) for step in np.arange(72)])
      
2.    We now have a way to check every chord and provide alternatives. 
      The next step is to select one of the alternatives. There are a few different ways to accomplish this:
      a.    Keep a record for every note in the orginal 12 tone scale, and the corresponding last selected 72 EDO step.
            For example, suppose you have a MIDI chord: 

----------------------------------
4/5/23 To do today:

1.    Consider a different way to handle tune_step_choices. 
      Instead of returning all the choices, which will just be transpositions to a different starting note, return the base note and the distances between the other notes. That makes up for the differences between the 72 EDO ratio choices. As it stands now, all the ratios are very high. Try lower limit_denominator values. That didn't help. I'm going to go back to the carefully chosen 72 EDO ratios, and make sure the unequal_12_ratios are in that list. I did that, but I can't find any ratios with a score below 8236. Pretty bad. I'm thinking I need to go back to choosing the unequal_12_ratios they way I did earlier, when I got scores of 173 and the like. 
      Here are the unequal_12_ratios chosen from edo_72_ratios:
      1 107/101 55/49 44/37 63/50 4/3 140/99 3/2 127/80 37/22 98/55 185/98
      Notice that many have ratios much larger than the 105 cutoff that I thought I was imposing. 
      Here are the first and last 8 ratios from edo_72_ratios:
       1 104/103 105/103 35/34 53/51 85/81 107/101 46/43 50/27 43/23 185/98 162/85 102/53 171/88 206/105 103/52
      The last three include 171 and 206 in the numbers. Is limit_denominator not working, or is it a matter of problems in data conversion?
      Here are all the edo_72_ratio_strings that are longer than 6 characters:
      Created with this:
      edo_72_ratio_strings = np.array([str(Fraction(ratio).limit_denominator(105)) for ratio in edo_72_ratios])
      ['104/103', '105/103', '107/101', '119/103', '131/105', '131/103', '131/102', '162/103', '180/103', '187/104', '206/105']
      Lots of them use numbers larger than 105. It doesn't matter. If all of the ratios have an average numerator or denominator that is very high, then none will produce good scores. So what I need is a list of ratios for the 72 EDO scale that are carefully chosen to have low ratios, even if they are off by 4 cents high or low from the calculated ratio. 
      I revised the ratios to go back to what I had previously. I'm getting reasonable scores now. What I need to do now is convert those 72 EDO step numbers to delta steps. I can then transpose them to any 72 EDO that makes sense in context.
            delta_results = np.array([[result[inx + 1] - result[inx] for inx in np.arange(result.shape[0] - 1)] for result in results])
            print(f'{delta_results = }')
            delta_results = array([[-53,  23,  30],
                        [-53,  23,  30],
                        [-53,  23,  30]])
      Notice that all of the different step distances are the same. So I can transpose to any starting note and have the low ratio that I want. It turns out I have no use for delta_results. I can just transpose a chord to any other starting note just by adding or subtracting a value from all the notes in the chord. Easy-peasy:
            transposed_chord = results[best_result] + 6

--------------------------------------
4/6/23 To do today:
                  
1.    Figure out why I'm getting two results from one chord. I did that intentionally. It's up to the caller to pick the best score and use it. I always wanted to get to use np.argmax(). It's got such a gnarly name. But in fact I'm looking for np.argmin(). Oh well, maybe next time.

2.    Try to get some music out of the work I've done over the past few days.

3.    Increase the range of choices in tune_step_choices. Set max_mod to 7 and see if that has any impact on performance or quality of choices.
      What are the consequences of a bigger range of choices to search:
      max_mod = 3: 113 ms ± 2.88 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)
      max_mod = 5: 669 ms ± 50.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
      max_mod = 7: 2.11 s ± 25.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

4.    Is this a bug in score_chord? How could I get a score of 75 when the ratios involved are so high?
      It's because what is being evaluated is the difference between ratios, not the ratios themselves.
            score_chord(best_chord) = 75
            best_chord = array([70, 17, 40, 70])
            np.array([str(Fraction(ratio).limit_denominator(100)) for ratio in ratios]) = array(['51/26', '20/17', '25/17', '51/26'], dtype='<U5')
      A bigger problem is that it turned a major chord into minor:
                  +--- approx 400 cents, just like a 12 ET major third!
            ['1' '24/19' '3/2' '1']
            unequal_12_names[chord1 % 12] = array(['C', 'E', 'G', 'C'], dtype='<U2')
            improved_chord = array([70, 17, 40, 70])
            np.array([str(Fraction(ratio).limit_denominator(100)) for ratio in ratios]) = array(['51/26', '20/17', '25/17', '51/26'], dtype='<U5')
            chord_72_edo[0]= 0, improved_chord[0] = 70
            offset = 2
            best_chord = array([ 0, 19, 42,  0])
                  +-- turned into a minor third thanks to going 7 steps either side of the original 72 edo steps
            ['1' '6/5' '3/2' '1'] 
      Lesson learned: 
            a.    Limit the range of steps you travel to less than the difference between major and minor.
            5 takes longer, but it doesn't switch major to minor.
            b.    You could save time if two chords in a row are the same, but that might be complicated. Basically you would test for equivalence with a prior chord, and if so, keep the prior improved chord.
            c.    The fact that in the first few notes of b minor force a change from 72 edo step 66 to 63 in order to optimize the score should give you pause to consider if your choice of 72 edo ratios is suspect.
            d.    I had to increase the step range from 3 to 4 so that it could find an acceptable set of notes for 'E' 'B' 'C#' 'G'
            e.    Unfortunately that caused a merge between to chords that were supposed to be different:
                        midi_chord = array([74, 71, 66, 49])
                        note names in 12 tone: ['D' 'B' 'F#' 'C#'] C# is changed to D
                        chord_72_edo[0]= 12, improved_chord[0] = 9
                        best_chord = array([12, 65, 42, 12])
                        best chord ratios:  9/8 15/8 3/2 9/8

                        midi_chord = array([74, 71, 66, 50])
                        note names in 12 tone: ['D' 'B' 'F#' 'D']
                        chord_72_edo = array([12, 66, 36, 12])
                        best_chord = array([12, 65, 42, 12])
                        best chord ratios:  9/8 15/8 3/2 9/8
                  I bumped up the min_score = 5000 and it made a choice. Check it out. I could get away with 1001.
                        note names in 12 tone: ['E' 'B' 'C#' 'G']
                        chord_72_edo = array([24, 66,  6, 42])
                        ratios in 72 edo:  ['24/19' '17/9' '18/17' '3/2']
                        3811 1969 1031 1001

5.    The chorale shape is (4, 385) for (voices, notes). 
      I'll have to split up the octave collection, which is done by voice, from the assignment of 72 edo steps, which are done by chord. I can assign octaves with a one line python comprehension. I have to do that first, since I need the midi numbers in order to determine the octave. But after I do that, I can convert the midi numbers to 72 edo steps in a function by chord. 

      Problem statement before I go for a walk. I need to move the voices_notes_features = build_voices_notes_features(chorale) to before any repeating of notes or voices. I expect 4 note chords, and something is going whack when 8 notes arrive. This happens in both the woodwinds and the finger piano parts. Fix that and you should get some music. 

---------------------
4-7-23 To do today:

1.    Get it making music. Done.

2.    Optimize. Work on this on 4/9
      31 s per loop (mean ± std. dev. of 7 runs, 1 loop each)
      to go through one chorale with 385 time steps. Many of those are repetitive. It may be time to bypass the call to 
            note = np.array([improve_chord(chords) for chords in chorale.T]) # convert it from (voices, notes) to (chords, time_steps)
            It's still taking a long time: user 41 s, sys: 681 ms, total: 41.7 s
                  Wall time: 41.5 s
            
-------------------------
4/8/23 To do today:

1.    Control the drift. Take a look at the log file and see what's going on with chords suddenly shifting. 
      And make sure they don't shift keys on you, or change major to minor. It's charming the way it works now, but I'd like more control.

2.    Remember that a midi note of zero is not a real note, it means there is no note there. 
      Before you start processing, you need to do something with those notes that aren't real. What to replace them with so that they are never processed? What about sparse matrix in numpy? Take a look and see. Also, check to see if there are any zeros in the first place.
                  values, counts = np.unique(chorale, return_counts=True)
                  print(f'{values[0] = }, {counts[0] = }')
                  values[0] = 0, counts[0] = 216
      So there are quite a few zeros. I'll have to confront this. They evalutate to step 0 in the 12 unequal_12_ratios array. 
            a.    I could investigate the sparse array functions in numpy. numpy.ma is when you work with data that is invalid. The zeros have meaning in MIDI files. They are not invalid.
            b.    I could subtract 1 from all the zeros, then put in logic to have a separate path for those that are -1.
            c.    I could put in logic prior to or during the conversion from 12 to 72 that examines the note values and when it finds a zero, sets the comparable value in the octave array to zero. I will need to exclude the zero while scoring the chord.

                  1.    Modify the function midi_to_notes_octaves. It currently does this:
                              octave = np.array([midi_number // 12 for midi_number in chorale])
                        This sets any midi number between 0 and 11 to zero. That's fine at this point, since the only notes that are that low are zeros anyway. So the octave is set to zero for any midi note that is zero. No change is required to that function. It's critical to set the octave array before converting the notes to 72 edo.
                  2.    For any midi note that is zero. What does it currently do:
                              note = np.array([improve_chord(chords) for chords in chorale.T])
                        It calls improve_chord function, which in turn calls note_12_to_72_edo
                              chord_72_edo = np.array(note_12_to_72_edo(unequal_12_ratios, chord1)) 
                        which in turn:
                              step_in_12_edo = np.array([step % 12 for step in midi_numbers]) 
                        All midi notes that were evenly divisible by 12 return zero in the 72 EDO scale. This includes midi note with a zero value, which has special meaning. I've lost that by converting all midi numbers to scale steps here. I have to capture those prior to this point in the logic. 
                        All midi number zero notes will be elminated because the conversion of the midi number to octave will convert a midi number zero to an octave zero, and octave zeros are eliminated later on. 
                        I just have to not allow actual midi zeros be converted to zero 72 EDO. They must be excluded from the scoring. In other words, I should not send them to the evaluation function. 
                        I was able to convert the step in 12 to 72 by combining a lambda function called in a list comprehension:
                              ifzero = lambda num: -1 if num == 0 else num % 12 
                              step_in_12_edo = np.array([ifzero(note) for note in midi_numbers])
                        Now I have the steps in an array that are from 0 to 12, plus the -1 which later in the function allows me to discard it.
                        That's all very clever, but it's really not needed. Just discard it in the list comprehension. Or not. There are other reasons to keep it the way it is. I don't want to make a mistake and mod it with 12 then discard, because that would discard valid notes. I have to first test to see if it's zero, and if it is, don't include it in the list comprehension results. That's the advantage of the lambda inside a list comprehension.
3.    Something interesting is happening with the scoring.
      It starts on 66, the best chord starts at 63, and then it's transposed back to 66.
            before scoring: chord_72_edo = array([66, 36, 12, 24])
            2023-04-08 14:45:42,387scores = array([215])
            2023-04-08 14:45:42,389before transposing: best_chord = array([63, 33, 10, 21])
            2023-04-08 14:45:42,391ratios in best_chord: np.array([str(Fraction(ratio).limit_denominator(100)) for ratio in ratios]) = array(['11/6', '11/8', '11/10', '11/9'], dtype='<U5')
            2023-04-08 14:45:42,393after transposing: best_chord = array([66, 36, 13, 24])
            2023-04-08 14:45:42,395ratios after transposing: np.array([str(Fraction(ratio).limit_denominator(100)) for ratio in ratios]) = array(['17/9', '17/12', '17/15', '24/19'], dtype='<U5')
      Working as designed. It finds the best chord then transposes back to where it started. But the notes are different
            [66, 36, 12, 24]
            [63, 33, 10, 21]
            [66, 36, 13, 24] I swap 12 out and put 13 in it's place. The ratios look bad, but it's the ratio from one to another that matters. Or rather these six relationships: 0-1, 0-2, 0-3, 1-2, 1-3, 2-3 
            The winning combo:
            0-1 11/6 to 11/8 is 2/1
            0-2 11/6 to 11/10 is 5/3
            0-3 11/6 to 11/9 is 3/2
            1-2 11/8 to 11/10 is 5/4
            1-3 11/8 to 11/9 is 9/8
      2-3 11/10 to 11/9 is 9/10
      So the key is to make sure that the 72 edo ratios include all the 11 limit or ideally 15 limit ratios. 

4     Bug: note = np.array([improve_chord(chords) for chords in chorale.T])
      Before it goes belly up:
            note = -1. That means do not score it. Discarding.
            before scoring: chord_72_edo = array([66, 12, 42])
      That's the first time I discard a note. I think the problem has to do with fewer notes in a chord causing dimensionality trouble. It's actually trouble when I try to find the winning combo. There is no [3] if one of the notes is discarded. I suppose I could duplicate one of the notes to make four. That's what I did.
            while chord_72_edo.shape[0] < 4:
                  chord_72_edo = np.append(chord_72_edo, chord_72_edo[0], axis = None)
      That should handle the case of only 1 or two notes in the chord as well.
      But not with no notes: 
            before scoring: chord_72_edo = array([])
      There's your trouble:
            chorale = np.concatenate((chorale, np.zeros((4,1),dtype=int)),axis = 1) # add a bit at the end so you don't loose the ending
      My old code used to need an extra bit at the end to avoid getting cut off, but my current code doesn't need that. Loose the np.concatenate with np.zeros.

---------------------------------------
4/9/23 To do today:

1.    You have a reasonably solid vertical adaptive tuning, now take a look at the horizontal perspective. 
      Jumps are bad.      

2.    Different ways to optimize performance:
      a.    Look at the current call and compare it to the previous call and if it's the same chord, return the same value as the previous chord
      b.    Sort them first, so they will be processed more efficiently by the option a. Must store all the chords and their actual location in the 384 time_steps, then after processing them, resort by time_step.
      c.    Cache all previous retuned results in an array, with an index of the chord that drove those results:
                  initial_chord = array([71, 66, 62, 52]) # save this input
                  before scoring: chord_72_edo = array([66, 36, 12, 24])
                  before transposing: best_chord = array([63, 33, 10, 21])
                  after transposing: best_chord = array([66, 36, 13, 24])  # save this output 
            Then look up the initial_chord in the array and return after transposing best_chord.
      Clearly the last is the best, most efficient, and most extensible. Most efficient means it has the fewest trips through the selection routines. Most extensible means it can be altered later to include horizontal adaptive tuning.


3.    The order of calls:
      a.    chorale_in_72_edo = midi_to_notes_octaves(chorale) # assign note step and octave
      b.    midi_to_notes_octaves # one chord at a time, feed chords into the improvement function, after first checking to see if you have already 
            previous_72_edo = improve_chord(previous_chord) # see if you can find more in tune steps than default
            note = previous_72_edo
      c.    improve_chord # has several functions:
            chord_72_edo = np.array(note_12_to_72_edo(unequal_12_ratios, initial_chord)) # call the table lookup function
            results = tune_step_choices(chord_72_edo, max_mod = max_mod, min_score = 2002)
            scores = np.array([score_chord(result) for result in results])
            offset = chord_72_edo[0] - best_chord[0]
            best_chord = np.array([(note + offset) % 72 for note in best_chord])
      d.    note_12_to_72_edo # does the table lookup of 12 notes to 72 edo
            ifzero = lambda num: -1 if num == 0 else num % 12 # convert midi number (0 - 127) to step in 12 EDO (0 - 11) unless 0, then -1
            step_in_12_edo = np.array([ifzero(note) for note in midi_numbers]) # execute the lambda function in a list comprehension
            # assign with table lookup
      e.    tune_step_choices # systematically try other 72 EDO choices, higher and lower, for the four notes in the chord,
            selecting the one with the lowest score

4.    Notes: Here is a one line command to find both the initial 12 tone MIDI note and the final best chord transposed:
            egrep "(initial_chord|after transposing: best_chord)" ball6.log
                  2023-04-08 17:22:08,454midi notes in improve_chord: initial_chord = array([62, 62, 62, 62])
                  2023-04-08 17:22:08,640after transposing: best_chord = array([12, 12, 12, 12])
                  2023-04-08 17:22:08,660midi notes in improve_chord: initial_chord = array([71, 66, 62, 52])
                  2023-04-08 17:22:08,831after transposing: best_chord = array([66, 36, 13, 24])
                  ...

5.    Here is the jupyter server on the T15: 
            jupyter lab --no-browser --ip=* --port=8889
            http://localhost:8889/
            http://192.168.68.57:8889/

6.    Bug: midi_to_notes_octaves(chorale)
            29 logging.info(f'72 EDO note value frequencies by voice. {[np.unique(voice, return_counts=True) for voice in note]}')
            30 # return np.stack((note, octave), axis = 0) #  (2, 4, 73) feature, voice, note
            31 # return np.stack((note, octave), axis = 1) #  (4, 2, 73) voice, feature, note
            ---> 32 return np.stack((note, octave), axis = 2)
            note.shape = (4,), octave.shape = (4, 20) # that's not a good sign. No notes got through.

7.    As a result of today's optimization I reduced the time to find the right chord in 72 edo from 45 seconds to 23 seconds. 
      Frankly, I was expecting better than that. I may have to move to the cache scheme described in 2.c above.
      14 seconds on the ThinkCentre. It's the excessive logging to a Windows file from a WSL linux guest. You are a guest after all. Don't expect to be treated as a premium client.

---------------------------------
4/10/23 To do today:

1.    Skinny down the TonicNet_Csound_Arpeggios_adaptive.ipynb so it is just the horns, and no repeated notes. 
      Look for the wierd sounding chords and see if you want to do something about them.

2.    Consider starting horizontal evaluations. Some questions that need answers: 
      How many notes? In what direction? Forwards and backwards 3-4 steps? Limit to just a transposition or actually changing the ratios? Lots of choices here.       

3.    Had a nasty scare trying to connect my notebook in code-server serve-local. 
      It wouldn't connect to my jupyter server because, it said, it wasn't an https link. I finally rebooted and tried it several times, when it finally worked. It asked if I really wanted to connect to an insecure server over http, and I said yes. Then it prompted for my jupyter password, which I entered. Then it asked for which kernel on that jupyter server, and I selected python. Then it worked. I wish I could look at the vscode logs.

4.    Before I get too carried away, what have others done that I might incorporate?      
            audio realizations: https://www.mitpressjournals.org/doi/suppl/10.1162/COMJa00519
            Not found.
            But this page has them: https://bitklavier.com/2020/06/28/bitklavier-papers/
            These are very interesting. Skip the videos about a metronome, and listen to the examples. He has many of the sounds I'm getting with my method.

5.    I'd really like to be able to use the tuning algorithm with live keyboard. That would be interesting. 

6.    But for today, I have to figure out why my woodwinds timing doesn't equal my finger piano timing. 
      It was because I changed the tpq to 1.0, but now I can't find where I did that. It was in the call to either finger piano or woodwinds. Did a search on 0.25 and located the 1.0 just below. 
      Fixed it. 

---------------------------
4/11/23 To do today:

1.    What if I solved the problem of problem of step distances and ratios in edo_72_ratios by switching to cents. 
      This could solve a few problems. I get different results for each of the scores depending on the starting step in 72 EDO. 
      It might have a ratio that was chosen for no good reason, that results in a high score, when an adjacent step has a much lower ratio, and gets a better score. This implies that I'm not getting the optimum score, since the ratios I pick for 72 EDO are very, very important. Maybe too important to use ratios for scoring. Before I start the horizontal adaptive tuning effort, I want to make sure I have the best vertical process in place.

      What will have to be changed to switch to cents:
      a.    Scoring will have to be based on a table of cents that return a score. 
            For example, just to the 3 limit will have a score of 3, 5 limit a score of 5, 7 limit 7, and so forth up to 31 limit. This is just one idea. We might add the total score, or multiply them like I did with denominators and numerators.
      b.    I do six compares today. Given SATB, I evaluate are S to A, S to T, S to B, A to T, A to B, and T to B. 
      c.    tune_step_choices will need to move by a certain number of cents. 
            I set max_mod = 3 today, which enables a move by -3 to +3 72 EDO steps, which is up to minus 55 through plus 55 cents. I don't know if that's the right amount. I changed it to +-7 with step size of 8 from -56 to +56.
      d.    Will I continue to need to use 72 EDO? If so that's another set of changes. 
            I could switch to cents here, and be done with it. Use chord_1200_edo in place of chord_72_edo.
      
      Funtions to change:
      a.    def tune_step_choices_cents(chord_1200_edo, max_mod = 7, step_size_in_cents = 8, min_score = 1002): Done.
      b.    score_chord(new_chord)
      c.    improve_chord(initial_chord, max_mod = 3) calls tune_step_choices needs to call tune_step_choices_cents
      d.    Any function that includes the variable: chord_72_edo needs to be changed to chord_1200_edo.
      e.    def note_12_to_72_edo(unequal_12_ratios, midi_numbers):
            changed to:
            def note_to_1200_edo(midi_numbers): 
            This just has to return a number in cents. It doesn't have to suggest alternatives.
      f.    What are the cent values for the 31 limit ratios:
                  limit_31_ratios = dmu.build_all_ratios() # assemble an array of 256 floating point ratios to the 31 limit
                  limit_31_cents = np.array([int(round(dmu.ratio_to_cents(just_ratio),0)) for just_ratio in limit_31_ratios]) # 256 cent values rounded to integers
                  limit_31_num_den = np.array([_find_limit(str(Fraction(just_ratio).limit_denominator(50))) for just_ratio in limit_31_ratios]) # (numerator, denominator) for an array of 256 values
            This set of arrays provides a way to rank ratios by max(limit_31_num_den[inx]) returns the score as the higher of numerator or denominator. The lower the score, the more consonant.
      g.    I'm thinking what would happen if:
            1.    Convert the midi number (0-127) into a cent value. (midi_num % 12) * 100 61 % 12 * 100 = 100 C#
            2.    choose the cent values that are within a range (20) of the midi_number 
                  [105,  99,  94,  89,  84, 119, 116, 112]
            3.    What are the num & den values for those cent values.
                  [[17, 16], [18, 17], [19, 18], [20, 19], [21, 20], [15, 14], [31, 9], [16, 15]])
            4.    What is the lowest num/dem: 15/14 that is index 5, which is 119 cents. 
                  That's the farthest from the midi_num
                  What is the closest to the midi_num? Do you care? Not really. If you don't like the sound, then reduce the range from 20 to something lower. How about 15?
                  what are the highest num & den and how far away from 12TET is it:
                  [(array([17, 16]), 5), (array([18, 17]), 1), (array([19, 18]), 6), (array([20, 19]), 11), (array([16, 15]), 12)]
                  Just looking at that set of numbers, the lowest ratio is clearly 16/15 12 from 12 TET. Pick that one. I think closeness to 12 TET is overrated. 

------------------------
4/12/23 To do today:

1.    Continue to convert from 72 EDO to cents. The last thing I did caused the notebook to grow to 41 MB in size.
      That's probably due to checking all the cent values instead of just every 8 or so. I also think this grid search is grossly inefficient. Why not just find all the possible just arrangements of notes close to the ones suggested.
      The whole concept of having to test every single possible combination of every single cent value, when you know that 99% won't provide a valid answer is bunk. Some ideas people:
      a.    If you find one note in the chord that doesn't have a ratio in the cent table, stop that chord.
      b.    Don't then test the next one if it has the very same interval that tested out in a previous score call.
            We are retesting chords that include the first value tested 501 cents which wasn't in the table. 
      c.    Is there a faster way to find cent values that match? Sort the table of cent values, removing duplicates. 
            Then search through the table and stop if you are past the value you need. 
      d.    Redo all your loops to use np.searchsorted. 

--------------------------------------------------------
4/13/23 To do today:

1.    I think I can radically simplify the process for the TonicNet_Csound_Arpeggios_adaptive_slim.ipynb notebook.
      This newly discovered searchsorted function opens up new much simpler and far more efficient methods to find the optimum chord structure, at least vertically.
      a.    I can start with any 12 tone scale, including 12 TET
      b.    The first task is to find likely candidates for the first interval.
      c.    move the starting note up and down over a different range and generate another list of alternatives
      d.    Generate a list of alternatives for that interval over a certain range 
      e.    Try this and see what the results are for just one interval. 
            Here are the initial results. I obtained a list of indeciis into the limit_31_values array for the first interval. I found 7 ratios, cents, max_num_dem by choosing those that were from -3 to +3 from where searchsorted would have placed the value for 500 cents. 

            limit_31_values contain 213 values for ratio, cents, max of num_dem
            midi_numbers = array([71, 66, 62, 59])
            initial_chord = array([1100,  600,  200, 1100])
            from 1st to 2nd: distance = 500
            indeciis_to_limit_31 = [86, 87, 88, 89, 90, 91, 92]
            closest to distance = 500 requested: [('25/19', 475, 25), ('29/22', 478, 29), ('4/3', 498, 4), ('31/23', 517, 31), ('27/20', 520, 27), ('23/17', 523, 23), ('42/31', 526, 42)]
            But I need to remember that that target interval is relative to the previous note in the chord, 1100. So the ideal distance is 498 above (or below) 1100. 1100 - 498 = 602. But if I add them, 1100 + 498 = 1598. If I mod 1598 with 1200, I get 398, which is also wrong. I need to make sure I choose the right direction.

            The next question is how do I evaluate the choices. I want the lowest integer ratios that were close to the desired cent value. In this case the best result is based on both factors: lowest ratio integer was 4 for 4/3 only 2 cents from the requested interval. The next chord is more problematic:

            from inx1 = 0 to inx2 = 2: distance = 900
            indeciis_to_limit_31 = [157, 158, 159, 160, 161, 162, 163]
            closest to distance = 900 requested: [('5/3', 884, 5), ('52/31', 896, 52), ('42/25', 898, 42), ('32/19', 902, 32), ('27/16', 906, 27), ('22/13', 911, 22), ('17/10', 919, 17)]
            limit_31_values[indeciis_to_limit_31[best_choice_cent_distance], 1] = 898.0
            initial_chord = array([1100,  498,  898, 1100])
            Here the closest by cent value is 898, which is only 2 away, but that num_dem is 42, rather high. Let's look at the choices:        distance * num_dem +num_dem
            ( '5/3',  884, 5),  16        80    21
            ('52/31', 896, 52),  4        108   56
            ('42/25', 898, 42),  2        84    44
            ('32/19', 902, 32),  2        64    34
            ('27/16', 906, 27),  6        162   33
            ('22/13', 911, 22), 11        242   33
            ('17/10', 919, 17)  19        323   36
            On the fly, how can I evaluate this. What if I take the product of the distance times the highest num_dem or the sum. In this case, I would prefer the result of the sum 21, which yields 5/3, the product 64 which yields 32/19. Try taking the sum of num_dem plus cents from ideal and see what you get.

            On another note, I am searching for the optimum in 6 intervals, but I only have four notes. And one is a duplicate. This means I can end up changing notes more than once. This could be problematic. Here's the first example:

            initial_chord = array([1100,  602,  216, 1100])
            from inx1 = 1 to inx2 = 3: distance = 498
            indeciis_to_limit_31 = [85, 86, 87, 88, 89, 90, 91]
            closest to distance = 498 requested: [('21/16', 471, 21), ('25/19', 475, 25), ('29/22', 478, 29), ('4/3', 498, 4), ('31/23', 517, 31), ('27/20', 520, 27), ('23/17', 523, 23)]
            limit_31_values[indeciis_to_limit_31[best_choice_cent_distance], 1] = 498.0
            limit_31_values[indeciis_to_limit_31[best_choice_num_dem], 2] = 4.0
            limit_31_values[indeciis_to_limit_31[best_choice_overall], 1] = 498.0
            initial_chord = array([1100,  602,  216,  104])  
            It changed the correct value for element 3 from 1100 to 104          
            So I finally was able to get one chord processed correctly, but the very next one I tried:
                  grep "tuned_chord =" save.txt 
                        ...
                        initial chord to tune: untuned_chord = array([1100,  700,  400,  400])
                        tuned_chord = array([1100,  714,  398,  398])
            I have settled down to this method of scoring an interval:
                  best_choice_overall = np.argmin(abs(limit_31_values[indeciis_to_limit_31,1] - distance) + limit_31_values[indeciis_to_limit_31,2]) # distance from the prompted interval plus the maximum of the ratio numerator or denominator
            I wonder if I should implement a cache using the same kind of logic as searchsorted provided. Later.
2.    Bug in ball7.csd I think it has something to do with note numbers being very very high, up to 1199. 
      The ftable is probably bigger than allowed. Actually I had labeled the f3 table as f4. But I'm still getting wrong midi numbers.                should be:
            instr 1:  iMIDInumber = 36.000 36
            instr 1:  iMIDInumber = 40.000 40
            instr 1:  iMIDInumber = 44.000 43
            instr 1:  iMIDInumber = 47.000 46 
            ipitch is
                  instr 1:  p5 = 0.000  ipitch = 0.000  p6 = 3.000  ioct = 3.000
                  instr 1:  p5 = 386.000  ipitch = 0.386  p6 = 3.000  ioct = 3.000
                  instr 1:  p5 = 702.000  ipitch = 0.702  p6 = 3.000  ioct = 3.000
                  instr 1:  p5 = 969.000  ipitch = 0.969  p6 = 3.000  ioct = 3.000
      something wrong here:
            iMIDInumber = int(12 * ipitch) + 12 * ioct
            12 * 0 / .12 + (12 * 3) = 36
            12 * 0.386  + (12 * 3) = 
      Saw this in the csound manual: [Warning] Warning
            The maximum number of p-fields accepted in the score is determined by PMAX (a compilation time varible). PMAX is currently set to 1000. This may discard values entered when using GEN02. To overcome this, use GEN23 or GEN28 to read the values from a file.
      I think that may be obsolete, because the manual for GEN02 now says:
            size -- number of points in the table. The maximum tablesize is 16,777,216 (2^24) points. The value may be given as zero, in which case the number of values decides the table length.

----------------------
4/14/23 To do today:

1.    I think I have the vertical optimizer working. Sort of.
      It chooses ratios from the tonality diamond to the 31 limit. It picks a specific ratio if it's not too many cents away from the MIDI note in 12 TET, and the ratio numerator and denominator are low. It sums the cent distance from 12 TET and the maximum of the ratio numerator and denominator to generate a score for each interval in the chord. In the case of 4 note chords that's six intervals. The lowest score wins. 

      I choose from six alternatives for each interval, starting with the cent value of the MIDI note number in 12 TET, and going three ratios below and three ratios above, then choose the lowest score from those for each interval. I could increase the range of ratios chosen, to try the ratio just outside that range. 
      
      Here are the chosen results (ratio, cents, max num_den) out of the first few chords in Herzliebster, sorted by ratio.

            grep "Optimizer recommends" ball7.log | sort -k 10 | uniq -f 9
                  Optimizer recommends: ('10/9', 182, 10)
                  Optimizer recommends: ('13/11', 289, 13)
                  Optimizer recommends: ('16/15', 112, 16)
                  Optimizer recommends: ('18/17', 99, 18)
                  Optimizer recommends: ('19/12', 796, 19)

      Some interesting choices there. Lots of 19, 13, 17's: 19/12, 19/16, and 19/18. I suspect they were chosen because they were close to the 12 TET number.

      Here we increased the range of ratios to 8. No change in the selection. 

            grep "Optimizer recommends" ball7.log | cut -d " " -f 8-15 | sort | uniq
                  Optimizer recommends: ('10/9', 182, 10),cent_deviation = 0.0
                  Optimizer recommends: ('13/11', 289, 13),cent_deviation = 5.0
                  Optimizer recommends: ('16/15', 112, 16),cent_deviation = 0.0
                  Optimizer recommends: ('18/17', 99, 18),cent_deviation = 1.0
                  Optimizer recommends: ('19/12', 796, 19),cent_deviation = 3.0
                  Optimizer recommends: ('19/16', 298, 19),cent_deviation = 2.0
                  Optimizer recommends: ('19/18', 94, 19),cent_deviation = 0.0

      But it does indicate that the very low distance from the initial choice for the interval, which was either from one 12 TET to another, or from one just cent to a 12 TET choice, or from one just cent to another.
      I could increase the impact of the ratio if I included both the numerator and the denominator in the calculation. In other words, sum the distance plus the numerator plus the denominator to generate the score. This would tend to pick based on low integer ratios rather than distance from the note the composer chose. I implemented this change.

            grep "Optimizer recommends" ball7.log | cut -d " " -f 8-15 | sort | uniq
                  Optimizer recommends: ('10/9', 182, 19),cent_deviation = 0.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 5.0
                  Optimizer recommends: ('16/15', 112, 31),cent_deviation = 0.0
                  Optimizer recommends: ('18/17', 99, 35),cent_deviation = 1.0
                  Optimizer recommends: ('25/24', 71, 49),cent_deviation = 1.0

      Fewer ratios that included 19, but that 25/24 is still there. I guess being only 1 away from the initial guess of what the composer intended makes a difference.

      Here is the results another run on Herzliebster. Look at those 13/11 and 13/9. I hate those ratios, yet there they are.
            grep "Optimizer recommends" ball7.log | cut -d " " -f 8-15 | sort | uniq
                  Optimizer recommends: ('10/7', 618, 17),cent_deviation = 8.0
                  Optimizer recommends: ('10/9', 182, 19),cent_deviation = 0.0
                  Optimizer recommends: ('1/1', 0, 2),cent_deviation = 58.0
                  Optimizer recommends: ('11/9', 347, 20),cent_deviation = 1.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 0.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 2.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 4.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 5.0
                  Optimizer recommends: ('13/9', 637, 22),cent_deviation = 5.0

2.    
3.    Problem upgrading Wordpress:
            Update WordPress
            Downloading update from https://downloads.wordpress.org/release/wordpress-6.2-new-bundled.zip…
            The authenticity of wordpress-6.2-new-bundled.zip could not be verified as no signature was found.
            Unpacking the update…
            There has been a critical error on this website. Please check your site admin email inbox for instructions.
            Learn more about troubleshooting WordPress.

--------------------------------
4/15/23 To do today:

1.    What's happening at 4:30 with the tuning. Isolate the wierd parts to get a better understanding.
      Total lenth: 377 seconds
      start of wierdness: 274 seconds 274 / 377 = .72
      back to normal: 280 280/377 = .75
      chorale.shape = (4,177) 177 * .72 = 127 177 * .75 = 133
      chorale.shape[:,127:133]
      There's your trouble: 58 cent deviation from where Bach wanted to be.
            grep "Optimizer recommends" ball7.log | cut -d " " -f 8-15 | sort | uniq
                  Optimizer recommends: ('10/9', 182, 19),cent_deviation = 0.0
                  Optimizer recommends: ('1/1', 0, 2),cent_deviation = 58.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 2.0
                  Optimizer recommends: ('13/11', 289, 24),cent_deviation = 4.0
      I think I went too far in this case, all the way to 1/1, an outlier. I wanted an interval of 58 cents, and it chose 1/1 which was 0 cents, or 58 away from where I want to be, because 1/1 was such a low value. I was trying to improve the interval from 312 to 370, and I ended up with 312 to 312, instead of 312 to something close to 370. This would not cause greater dissonance, rather less. Unison is pretty consonant, after all.
                  initial_chord = array([700, 601, 312, 370])
                  from inx1 = 2 to inx2 = 3: distance = 58
                  closest to distance = 58 requested: [('1/1', 0, 2), ('32/31', 55, 63), ('31/30', 57, 61), ('30/29', 59, 59), ('29/28', 61, 57), ('28/27', 63, 55), ('27/26', 65, 53)]
                  Optimizer recommends: ('1/1', 0, 2),cent_deviation = 58.0                  
                  improved_chord = array([700, 601, 312, 312])
            I'm on version Version: 1.77.3. Perhaps it's been fixed?
                  Commit: 704ed70d4fd1c6bd6342c436f1ede30d1cff4710
                  Date: 2023-04-12T08:57:43.435Z
                  Browser: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36 Edg/111.0.1661.54
            See if you get a new version first if you close out this one and restart the instance of code-server.
            While you are at it, change the time to autosave to much higher: Auto Save Delay reset to 600,000 milliseconds. That's 10 minutes, which is much better for a file being backed up to Dropbox. Xfinity won't be able to upcharge me for overusing gb transferred, I hope. I didn't sync to my windows machine. No idea why.

2.    So this choice is not wrong. 
      But I need to change from looking at the 3 ratios larger and smaller than the requested value, to keeping it within a certain number of cents. The ratio position in the array is irrelevant. The steps are highly unequal. I added a check on the values discovered to keep only those that are not outliers in terms of cents > 20. 

                  indeciis_to_limit_31 = np.array([inx for inx in indeciis_to_limit_31 if abs(limit_31_values[inx,1] - distance) < 20])
                  logging.info(f'after removing outliers: {indeciis_to_limit_31 = }')                  
                  logging.info(f'{[limit_format(limit_31_values[inx]) for inx in indeciis_to_limit_31] = }')

3.    The strangeness has to be found elsewhere. Try chorale = chorale[:,130:160]. Which notes are causing trouble?

            grep "midi notes in improve_chord: " ball7.log | cut -d " " -f 14-22  | head -n 32
            What measure is this - 130/4 = 32.5. Scale degrees are listed in SATB order.
                  
                  array([69, 66, 62, 60]), ['A♮' 'F♯' 'D♮' 'C♮']8.1.3 119 D maj
                  array([69, 66, 62, 60]), ['A♮' 'F♯' 'D♮' 'C♮']8.1.4 120
                  array([69, 66, 62, 59]), ['A♮' 'F♯' 'D♮' 'B♮']8.2.1 121
                 

---------------------------------------------------------
4/16/23 To do today:

1.    Try increasing the importance of ratio scores. 
      Multiply the num dem by some factor so that higher numbers get much higher scores. Make it a variable, that you can change across the piece.

2.    You are clearly in the dark about what your algorithm is doing. 
      You need to save some values from start to finish, and not just log them. 
      a.    If you save them you can print exactly what you want at the end
      b.    If you log more cleverly, you can continue to just mine the log file. 
            That means having one search string, like a message ID that you can search on to collect vital information.
      c.    Or you can learn to use egrep to search for both "Optimizer" and "improve_chord: " 
            egrep "Optimizer|improve_chord" ball7.log | cut -d " " -f 10-25 | head
                  in improve_chord: initial_chord = array([71, 66, 62, 59]), ['B♮' 'F♯' 'D♮' 'B♮']
                  ('4/3', 498, 7), cent_deviation = 2.0
                  ('5/3', 884, 8), cent_deviation = 16.0
                  ('5/4', 386, 9), cent_deviation = 0.0
                  ('4/3', 498, 7), cent_deviation = 0.0
                  ('5/3', 884, 8), cent_deviation = 0.0
                  in improve_chord: initial_chord = array([71, 66, 62, 59]), ['B♮' 'F♯' 'D♮' 'B♮']
                  ('4/3', 498, 7), cent_deviation = 2.0
                  ('5/3', 884, 8), cent_deviation = 16.0
                  ('5/4', 386, 9), cent_deviation = 0.0

3.    I am looking at score_chord_cents, and it's never called in the other cells. Is it scoring some other way? Nope.
      My changing the factor had no effect. And here I was assuming I was making a difference. How is this possible?
      I guess the function find_intervals does all the work now. It selects individual intervals. Here is the key optimization algorithm:

            half_range = range // 2 # controls how many ratios are compared
            indeciis_to_limit_31 = np.array([np.searchsorted(limit_31_values[:,1], distance) + offset for offset in np.arange(-1 * half_range, half_range + 1, 1)]) # builds an array of potential ratios to choose from
            indeciis_to_limit_31 = np.array([inx for inx in indeciis_to_limit_31 if abs(limit_31_values[inx,1] - distance) < 20]) # eliminate outliers
            # choose the index into limit_31_values that is the minimum of accuracy of cents and sum of num + den.
            #                                                                        +-- absolute cents
            #                                                                        |    +-- interval distance of the original cent location
            #                                                                        |    |                                                +-- num_dim
            best_choice_overall = np.argmin(abs(limit_31_values[indeciis_to_limit_31,1] - distance) + limit_31_values[indeciis_to_limit_31,2])
      So my questions are:
            a.    Does this work to choose the best_choice_overall? Does the argmin iterate over indeciis_to_limit to find it? 
                  I can test that. But I have no reason to doubt it.
            b.    How can I tell for certain? Sum the num den across a chord, not just 4 (not 6) intervals.
            c.    If it works, can I alter it by applying a weight to limit_31_values[indeciis_to_limit_31,2] to make it more important?
            d.    Why have I been trying to optimize intervals instead of chords? It was easy and at first, pretty good.
            e.    Should I switch to chords? Of course. That is the next obvious step before horizontal adaptive.

4.    Where are we now. First few chords with a score that look fine.
            egrep "Optimizer|just" ball7.log | cut -d " " -f 9-25 | head -n 15
                  ('5/3', 884, 8), cent_deviation = 16.0
                  ('5/4', 386, 9), cent_deviation = 0.0
                  ('4/3', 498, 7), cent_deviation = 0.0
                  ('5/3', 884, 8), cent_deviation = 0.0
                  just chord: [1100  602  216 1100], score = 39.0
                  ('4/3', 498, 7), cent_deviation = 2.0
                  ('5/3', 884, 8), cent_deviation = 16.0
                  ('5/4', 386, 9), cent_deviation = 0.0
                  ('4/3', 498, 7), cent_deviation = 0.0
                  ('5/3', 884, 8), cent_deviation = 0.0
                  just chord: [1100  602  216 1100], score = 39.0
                  ('4/3', 498, 7), cent_deviation = 2.0
                  ('5/3', 884, 8), cent_deviation = 16.0
                  ('5/4', 386, 9), cent_deviation = 0.0
                  ('4/3', 498, 7), cent_deviation = 0.0
                  ('5/3', 884, 8), cent_deviation = 0.0
                  just chord: [1100  602  216 1100], score = 39.0
                  
      The score is the sum of the maximum of the numerator and denominators of all six ratios in a 4-note chord. Those look pretty good, but look what we get when we explicitly sort the chord scores by value, highest first:
            egrep "chord-score" ball7.log | cut -d " " -f 9 | sort -n -r | head -n 12
                  571.0
                  571.0
                  552.0
                  552.0
                  529.0
                  529.0
                  493.0
                  493.0
                  491.0
                  491.0
                  491.0
      Pretty bad, I'd say. This is because I'm choosing intervals instead of chord as the metric. I am literally only selecting one interval at a time, not looking at all six as I used to do. 

5.    How can I switch to scoring chords:
      a.    Change find_intervals to return the choices that could have been taken, for each of the six intervals.
      Don't update the 4 notes to new cent values yet. They don't effect the other choices, since I have infinite transpositionality. Also, don't bother picking the best score for individual intervals. Those are irrelevant. Return all the indeciis for possible intervals to the caller. 
      b.    Enhance improve_chord to take those six arrays of alternatives, and cycle through each one and score the total  for each. One should be the best. Return that choice to the caller.
      c.    Enhanve find_intervals to return an array of all six choices from all six intervals. I also need to save, for each interval, the direction up or down the interval goes.
            
-------------------------
4/17/23 To do today:

1.    Put back into find_intervals the notes that it found previoously and return those to improve_chord along with the other cent values.
      Then in improve_chord check the score. If it's low, keep the found notes and move on. If it's over some arbitrary maximum score, like perhaps 50, then start your search for a better score by swapping out values looking for the optimum. 

2.    Why am I getting 7 choices when I expect 6? Because you are stupid:
            range = 6
            half_range = range // 2
            print(f'{np.arange(-1 * half_range, half_range + 1, 1)}')
                  [-3 -2 -1  0  1  2  3]
      That's seven values. 
      Then why am I getting seven different intervals, Mr. Smarty Pants?
            saved_cent_moves.shape = (7,)
            saved_cent_moves.shape = (14,)
            saved_cent_moves.shape = (21,)
            saved_cent_moves.shape = (28,)
            saved_cent_moves.shape = (35,)
            saved_cent_moves.shape = (42,)
            saved_cent_moves.shape = (49,)
            saved_cent_moves.shape = (7, 7), first_choice = array([   0,  386,  702, 1018]), score = 172.0
      It was because I did not start up with the right np.empty settings.
            np.empty(0, dtype = int) is the right way to start an array that you want to concatenate on to. If you specify 
            np.empty(range + 7, dtype = int) it creates the first seven with crumbs left over in memory of dimension (7,)
            That was wrong.
3.    Back to looking at some of the choices that find_intervals picks for challenging chords. In this case:
            
            initial_chord = array([76, 67, 61, 57]), ['E♮' 'G♮' 'C♯' 'A♮']
            before scoring: chord_1200_edo = array([400, 700, 100, 900])
            saved_cent_moves = array([], dtype=int64)
            from inx1 = 0 to inx2 = 1: distance = 300
            from initial_chord[inx1] = 400 to initial_chord[inx2] = 700: add_to_previous = True
            initial_chord[inx1] > initial_chord[inx2] = False
            prior to removing outliers: indeciis_to_limit_31 = array([51, 52, 53, 54, 55, 56, 57])
            [limit_format(limit_31_values[inx]) for inx in indeciis_to_limit_31] = [('13/11', 289, 24), ('32/27', 294, 59), ('19/16', 298, 35), ('25/21', 302, 46), ('31/26', 304, 57), ('6/5', 316, 11), ('29/24', 328, 53)]
            cent_moves = array([289., 294., 298., 302., 304., 316., 328.]), cent_moves.shape = (7,)
            saved_cent_moves.shape = (7,)
      So it's moving all over the place
            egrep '(new_chord|, initial_chord)' save.txt
                  inx1 = 0, inx2 = 1, initial_chord[inx1] = 400, initial_chord[inx2] = 716
                  inx1 = 0, inx2 = 2, initial_chord[inx1] = 400, initial_chord[inx2] = 84
                  inx1 = 0, inx2 = 3, initial_chord[inx1] = 400, initial_chord[inx2] = 898
                  inx1 = 1, inx2 = 2, initial_chord[inx1] = 716, initial_chord[inx2] = 79
                  inx1 = 1, inx2 = 3, initial_chord[inx1] = 716, initial_chord[inx2] = 898
                  inx1 = 2, inx2 = 3, initial_chord[inx1] = 79, initial_chord[inx2] = 893
                  new_chord = array([400, 716,  79, 893])
      I identify sevearal problems with this algorithm:
            a.    I have no way to go back and do the prior modifications, just one chance to get all the intervals right
            b.    If I change one of the lower intervals, such as inx1 = 1 and 2, then the decision made previously is overwritten
            c.    inx0 stays put at 400, when it would be better at some other value.
                  inx1 starts at 700, switches to 716
                  inx2 starts at 100, switches to 84 which is in tune with inx0, then to 79 to be in tune with inx1 Can't have both
                  inx3 starts at 900, switches to 898 to be in tune with inx0, then to 893 to be in tune with inx2
      Great, what can I do about it?
            a.    If I change a value, restart from the beginning. I tried that, it was an improvement, but ended up oscillating between choices for inx2 from 84 (score 183) to 79 with score 359
                  after inx = 2 find_intervals: first_choice = array([400, 716,  84, 898]), score = 183.0
                  inx1 = 0, inx2 = 1, initial_chord[inx1] = 400, initial_chord[inx2] = 716
                  inx1 = 0, inx2 = 2, initial_chord[inx1] = 400, initial_chord[inx2] = 84
                  inx1 = 0, inx2 = 3, initial_chord[inx1] = 400, initial_chord[inx2] = 898
                  after inx = 3 find_intervals: first_choice = array([400, 716,  79, 898]), score = 359.0
                  inx1 = 0, inx2 = 1, initial_chord[inx1] = 400, initial_chord[inx2] = 716
                  after inx = 4 find_intervals: first_choice = array([400, 716,  84, 898]), score = 183.0
                  inx1 = 0, inx2 = 1, initial_chord[inx1] = 400, initial_chord[inx2] = 716
                  inx1 = 0, inx2 = 2, initial_chord[inx1] = 400, initial_chord[inx2] = 84
                  inx1 = 0, inx2 = 3, initial_chord[inx1] = 400, initial_chord[inx2] = 898
                  after inx = 5 find_intervals: first_choice = array([400, 716,  79, 898]), score = 359.0
                  inx1 = 0, inx2 = 1, initial_chord[inx1] = 400, initial_chord[inx2] = 716
                  Keeps repeating this forever.
      I tried reorganizing the input midi notes, and that got me to a score of 147, better than before, but it still oscillated. 
      I was able to stop the oscillation by saving the previous score and previous choices, and returning those if the score increased over the previous score. I got to 147 using that technique. Is that as good as it gets? Could I shuffle the array first? I did that and the best score was 147. Just like without the permutation.
            chord_permutations = np.array(list(permutations(chord))) # requires an import of: from itertools import permutations
            print(f'{chord_permutations.shape = }')

             egrep "final:"  save.txt
                  final: chord = array([900, 402,  86, 704]), score = 147.0
      I removed the bail-out clause from find_intervals and was able to get the best score I made previously 147. But only with one permutation did the score get that low. And what were the ratios of that chord?
      
      I still thing the only viable solution is to retrieve the possible ratios and try them all. How would this work:
      a.    Do the search within find_intervals. 
      b.    Do the search within improve_chord. This puts too much reliance on find_intervals efficiently finding the optimum chord, which it hasn't exactly done so far.

4.    Itertools has a bunch of things I could use.
            from itertools import combinations
            combinations('ABCD', 2) # all the combinations taken two at a time 
                  AB AC AD BC BD CD
            
            from itertools import combinations
            chord = np.array([57, 61, 76, 67])
            for a, b in combinations(chord, 2):
                  print(f'{a = }, {b = }')
                        a = 57, b = 61
                        a = 57, b = 76
                        ...
                        a = 76, b = 67
5.    I became so enamored of itertools combinations, that I changed the variable names in find_intervals from initial_chord[inx] to inx, and same for inx2. But that means I can't change their values. I could change them all back again, or I could make the changes in improve_chord. I fixed that. Lost tons of time in the process. Next time you make a major change like that, make a copy of the cell you are changing before you start messing around.

6.    I got to 147 in a systematic way without using the saved_cents. 
      Next step is to use saved_cents to systematically try to improve even more. Or maybe just try roll instead of combinations. That didn't work. This would simplify restoring the correct order for the array, which as you may have noticed is no longer voiced correctly.
            egrep "(final|saved_cents|best:)" save.txt
                  find_intervals: result = array([900,  86, 402, 718]), score = 183.0, saved_cents.shape = (7, 6)
                  find_intervals: result = array([900,  86, 704, 388]), score = 294.0, saved_cents.shape = (7, 6)
                  find_intervals: result = array([900, 402,  86, 704]), score = 147.0, 
                  best: chord = array([900, 402,  86, 704]), score = 147.0
            before find_intervals: initial_chord = array([900, 100, 400, 700])

-------------------------------------
4/18/23 To do today:

1.    Get the permutation method working and completed. Done. It's pretty slow, though. Each chord takes almost three seconds, 177 chords = 500 seconds, over 8 minutes. Not going to work here. 
            1.87 s ± 22.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
            2.79 s ± 39.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) # after fine tuning, it's worse
      Reducing the range of ratios doesn't help at all. How was I able to do it in 1.87, and better yet how can I get even lower.
      
2.    Some notes: Gave up on this, but came up with a compromise that seems to work pretty well.
      a.    You may want to start with a smaller range than 6. Try 4 first. There is no benefit in performance from lower range, because the design using np.argmin is already efficient.
      b.    What itertools function would enable me to easily iterate over each of the ratios for each of the notes?
                  for inx, interval in zip(count(0, 1), combinations(result, 2)):
                        # interval is a tuple, which needs to addressed as interval[0] and interval[1]
      c.    saved_cents has a shape of (6, 5), which results from range = 4. Five ratios for each of the six intervals.
      d.    it would be nice if I could avoid checking the same interval more than once.
      e.    it's hard to line up the ratios with the right intervals. I had reshaped them incorrectly
      f.    how many new arrays of chords will I create? if the range = 4, that's a total of 5 different choices for each of 6 intervals. But I only have four notes, so which one takes precedence? Are the saved_cents useless? If so, what would be better? I'm really only duplicating the work already done in find_intervals. I had clearly not thought this out properly. Perhaps there is some way I can transform the six intervals into four notes mathematically. Start with a chord:
            initial_chord = array([60, 67, 64, 71]), ['C♮' 'G♮' 'E♮' 'B♮'] C major 7th
            result = array([   0,  702,  386, 1088]), saved_cents.shape = (6, 5)

3.    This method could prevent oscillation, and avoid having to permute the chords to find the best score.
            [ 680.,  683.,  702.,  722.,  725.] 0 to 1      affects 1 take result[0] and add saved_cents[0,:] store in result[1]
            [ 386.,  399.,  401.,  404.,  409.] 0 to 2      affects 2 take result[0] and add saved_cents[1,:] store in result[2]
            [1088., 1095., 1101., 1106., 1111.] 0 to 3      affects 3 take result[0] and add saved_cents[2,:] store in result[3]
      stop here and score it. compare that score with the one that follows, and keep the better one. How do you determine the better one? Score the whole chord before and after the change.
            [-302., -304., -316., -328., -331.] 1 to 2      affects 2 take result[1] and add saved_cents[3,:] store in result[2]
      stop here and score it. compare that score with the one that follows, and keep the better one
            [ 374.,  386.,  399.,  401.,  404.] 1 to 3      affects 3 take result[1] and add saved_cents[4,:] store in result[3]
      stop here and score it. compare that score with the one that follows, and keep the better one
            [ 680.,  683.,  702.,  722.,  725.] 2 to 3      affects 3 take result[2] and add saved_cents[5,:] store in result[3]
            I went back to this idea. Don't change a note if it would not improve the overall score. Keep the one you picked earlier. This affects notes 2 and especially 3, since 2 gets picked twice and 3 gets 3 chances. I get good scores in around 1.4 seconds per runthrough. 
            1.42 s ± 76.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
      
----------------------------------
4/19/23 To do today:

1.    Something is wrong with the dimensions of the chords making it through the cycle:
      a.    main module calls 
                  chorale, root, mode, s = read_from_corpus('bwv244.3')
                  chorale_in_cents = midi_to_notes_octaves(chorale) # here is where we convert midi notes to cents
                  logging.info(f'in main line. {chorale_in_cents.shape = }')
                        in main line. chorale_in_cents.shape = (4, 20, 2) (voice,notes,features)
      b.    midi_to_notes calls     
                  in midi_to_notes_octaves. chorale.shape = (4, 20)
                  octave = np.array([midi_number // 12 for midi_number in chorale])
                  previous_chord, score = improve_chord_slim(chord)
      c.    improve_chord_slim calls
                  chord_in_1200 = np.array(note_to_1200_edo(initial_chord))
                  result = find_intervals(chord_in_1200, range = range) 
                  score = score_chord_cents(result)
      d.    find_intervals calls
                  # goes through all six intervals in a 4-note chord
                  # recommends intervals based on closeness to proposed cent and lowest numerator/denominator ratio maximum value 
                  # comes up first with recommendations for 0, 1, 2, & 3 for initial values first. array([1100,  602,  216, 1100])
                  # determines what to do for chord notes 2 & 3, which can move if 0-2 differs from 1-2 recommendation
                  # same for 0-3, 1-3, 2-3 which has three different potential values
                  # compares the scores for the chord at the time there is a new proposed value. Low score wins.
                  prev_score = score_chord_cents(initial_chord) # what the chord was before this new interval sugggested a new value
                  new_score = score_chord_cents(initial_chord) # what the score will be after replacing the note this new interval suggested
                        find_intervals: result = array([1100,  602,  216, 1100]), score = 39.0
                  
      I discovered that I was continuing to call improve_chord instead of improve_chord_slim, which was extending the time and resulting in bad output. Oops.

2.    What to do if score_chord_cent discovers a chord with an interval not in limit_31_values. 
      This is caused by scoring bug, where it provides a low score even if it's not in the table. That should be a disqualifier. It happens when I change a note to a cent value that changes a previously chosen interval. That's what I suspect. I'm not certain. For now, set the penalty for this case to 1000 points. I made change, and there were temporary states when the scores were 2138 and 1165, and it chose the latter. But then a subsequent change that scored 135. There is not assurance that this will happen always. 

3.    Keep track of the common cent values for several notes. 
      There may be a reason to transpose them before you start find_intervals. 
      For example, F# changes to 602 cents, so it makes sense to change it on the chords that start with 600. It's only 2 cents, but it's the principal of the thing. And it could get much worse. Example:
            find_intervals: result = array([  -1,  203,  602, 1087]), score = 1145.0
      How did I end up with -1? Because it started with -1. I think that might be a signal to drop that note.
            in find_intervals. initial_chord = array([  -1,  200,  600, 1100]), range = 6
      Here's the line that does this. I suspect that I should have gotten rid of this before it made it anywhere.
            ifzero = lambda num: -1 if num == 0 else original_12[num % 12] 
            step_in_1200_edo = np.array([ifzero(note) for note in midi_numbers]) # execute the lambda function in a list comprehension
      Setting up a test case for what to do with a silent note: zero MIDI number means don't play, so I change them to -1 in the cent arrays
            initial_chord = array([ 0, 74, 66, 59]), ['C♮' 'D♮' 'F♯' 'B♮']
            in cents: np.array(note_to_1200_edo(initial_chord)) = array([  -1,  200,  600, 1100])
            result = array([  -1,  203,  602, 1087])
            score = 1145.0
      I decided that instead of replacing a 0 MIDI note with -1, I would replace it with a non-zero note in the chord. The fact that it's zero in the octave array will mean that it will be ignored. So it won't affect the music. It just makes it easier to deal with in scoreing, and cord tuning.

4.    It's up to 1/2 second per chord now.

5.    There is something whack about the chords. 

----------------------------------
4/20/23 To do today:

1.    Change the loop over chorale.T to be like the others that use zip(count(0,1), chorale.T) at the top of the loop.
      This avoids having to put in an index, unless you want to reach a different chord, or if you want to change a value. It would allow me to log the chord number.

2.    Find out why I was getting scores over 1000. That should not happen. 
      But you will need the chords numbered, logged to find the offenders. Example:
            inx = 150, chord = array([76, 67, 58, 49]), chorale.T[inx - 1] = array([76, 67, 59, 49])
            In improve_chord_slim. initial_chord = array([76, 67, 58, 49]), ['E♮' 'G♮' 'A♯' 'C♯'] # dim 7th, always a challenge
      It picks a set of ratios that are pretty good, only gets into trouble when it is looking to optimize 1 to 2, and that would require changing 0 to 2, which was already picked.
            Optimizer: ('17/12', 603, 29), cent_deviation = 3.0
      In the check for 1 to 2
            inx1 = 1, inx2 = 2, first = 716, sec = 1003
            from first = 716 to sec = 1003: distance = 287
            Optimizer: ('13/11', 289, 24), cent_deviation = 2.0
            score for the chord before changing [ 400  716 1003   84]: prev_score = 2124.0 <-- there's your trouble. 
      It's just a victim of choosing optimum ratios for 0-1, 0-2, 0-3, which end up with ratios for the other intervals that are terrible. 
            after_first_round = np.array([ 400,  716, 1003,   84])
            score = score_chord_cents(after_first_round)
            print(f'{score = }')
                  score = 2124.0

      I think I may need to include a few other ratios in the base set. What would an ideal dim 7th chord look like? List the thirds that are available in the overtone and undertone series: I like 5:6:7. Paul Erlich likes minor seventh chords like this (10:12:15:18) (My preference is for 5:6:7:9) and diminished triads (25:30:36). I like 5:6:7:?, where ? could be 17/16, but I haven't tried it yet.
            ('5/4', '5/4') = 0    + 386 = 386
            ('5/4', '3/2') = 316  + 386 = 702
            ('3/2', '7/4') = 267  + 386 = 969
            ('7/4', '2/1') = 231  + 386 = 1200
            ([ 386,  702,  969, 1200])      
            702 - 386 = 316
            969 - 386 = 583, which is the ratio from 5/4 to 7/4 is 7/5, which I would think would be part of the ratio table. Perhaps I need a new ratio table. One that is 15 limit, but includes all the intervals between the other ratios. Hang on there. 10/7 and 7/5 are both in the ratio table. Why does the search not find them?
                  int(round(dmu.ratio_to_cents(dmu.ratio_distance('5/4', '7/4')), 0)) = 582
            This might explain. I think I need to deal with cent values near ones in the table.
                  index_to_limits = np.searchsorted(limit_31_values[:,1], distance) # ratio, cents, num_den
            This is how I search the table, by cents. All the calculations in score_chord_cents are done by cents.
            This could be the source of trouble. With all the cent rounding I'm doing, I end up with ratios not being found in the table. Here's an example. I look for the ratio of 5/4 to 7/4, a very conventional just ratio. 
      Steps:
            find the ratio distance and convert it to cents. 7/5 in cents is 582
                  print(f"{int(round(dmu.ratio_to_cents(dmu.ratio_distance('5/4', '7/4')), 0)) = }")
                        int(round(dmu.ratio_to_cents(dmu.ratio_distance('5/4', '7/4')), 0)) = 582
                  ratio_to_find = 7/5
            search for that ratio by ratio, and it finds it.
                  print(f'{found_ratio = }, {limit_31_values[found_ratio] = }')
                        found_ratio = 103, limit_format(limit_31_values[found_ratio]) = ('7/5', 582, 12)
                  found_ratio = np.searchsorted(limit_31_values[:,1], 583) 
            But searching by cent value of 583, calculated by calculating 968 - 386 and you get 583, which is not found
            If I subtract one from the found_ratio, I find the one I'm looking for. But it's not equal to the distance. The distance is wrong, 
                  if limit_31_values[found_ratio, 0] != ratio_to_find: found_ratio -= 1
                        print(f'{found_ratio = }, {limit_31_values[found_ratio] = }')
            If I pick the element in the array one less than the requested on, I find 582, but I'll never find 583
                        found_ratio = 103, limit_format(limit_31_values[found_ratio]) = ('7/5', 582, 12)                        
            Is this common? Just for fun, see if one less is found, and use that. Maybe one more.
            So it's searching for 583. It's not in the limit_31_values[,:1] table. But 582 is there. What do you do? Subtract or add one to the distance being searched for. Fixed it. Four hour challenge met. Here is the crux of the matter:
                  dmu.cents_to_ratio(583) = '7/5'
                  int(round(dmu.ratio_to_cents(7/5))) = 582
            There are multiple values for one ratio, due to adding cents to create a new ratio, and the effect of rounding to the nearest cent.
            The only problem is it now takes 4 minutes 15 seconds to doa 177 chord chorale. And the log file as 12,900 lines in it.
          
            Next run found these, none of which is a dim 7 chord:
                  inx = 102, chord = array([73, 64, 55, 54])
                        in find_intervals. initial_chord = array([100, 400, 700, 600]), range = 6
                        initial_chord = array([73, 64, 55, 54]), ['C♯' 'E♮' 'G♮' 'F♯']
                        new_chord = array([100, 416, 703, 598]), score = 1123.0
                  inx = 132, chord = array([67, 66, 59, 52])
                        in find_intervals. initial_chord = array([ 700,  600, 1100,  400]), range = 6
                        initial_chord = array([67, 66, 59, 52]), ['G♮' 'F♯' 'B♮' 'E♮']
                        new_chord = array([ 700,  601, 1086,  384]), score = 1099.0
                  inx = 140, chord = array([66, 64, 61, 46])
                        initial_chord = array([66, 64, 61, 46]), ['F♯' 'E♮' 'C♯' 'A♯'] This is F# major, why the challenge?
                        new_chord = array([600, 396, 102, 986]), score = 1165.0
      
      Looking for high scores:
            grep "improved the chord. previous_chord_1200 = array" ball7.log | cut -d " " -f 13-25    

3.    I need to find a way to adjust the starting note so that it matches some note from the previous chord. 
      Once I choose four chord cent values, that should affect the initial value of the next chord.

4.    How can I make score_chord_cents more efficient? Test it in [102, 132, 140]. 

-----------------------------------
4/21/23 To do:

1.    Figure out why the voicing of the F# maj flat 7th scored. 
      I used combinations and found a much better score. Did I really want permutations? np.roll does just as well. Proved it.

2.    I found something strange when I was writing up the blog post to ball7-t18.mp3 this morning.
            -----------------------------------------
            inx1 = 1, inx2 = 2, first = 396, sec = 102
            from first = 396 to sec = 102: distance = 294
            prior to removing outliers: [49 50 51 52 53 54 55]
            [(49, ('27/23', 278, 50)), (50, ('20/17', 281, 37)), (51, ('13/11', 289, 24)), (52, ('32/27', 294, 59)), ), (54, ('25/21', 302, 46)), (55, ('31/26', 304, 57))]
            cent_moves = array([-278., -281., -289., -294., -298., -302., -304.]), cent_moves.shape = (7,)
            best_choice_overall = 2
            Optimizer: ('13/11', 289, 24), cent_deviation = 5.0
      It wants to pick the interval at 294 cents, it chooses #2, which is 13/11 at 289 cents instead of #3 which 32/27 at 294 cents. That's odd. I see that the former has lower num_den values than 13/11, (24 vs 59), but still... 289 is only five away from 294, but the num_den is 35 higher, so it has no choice but to pick the bad interval, based on the algorithm. Minimize distance and ratio numerator & denominator integer sizes. So at this point it does a compare:
            
            chord_voicing = array([66, 64, 61, 46]), ['F♯' 'E♮' 'C♯' 'A♯']
            new_chord = array([600, 396, 102, 986]), score = 1165.0
               0    1    2    3
            [600, 396, 102, 986]

            0 to 1: 600-396 = 204 cents ratio: 9/8
            0 to 2: 600-102 = 498 cents ratio: 4/3
            0 to 3: 600-986 = 386 cents ratio: 5/4
            1 to 2: 396-102 = 294 cents ratio: 32/27
            1 to 3: 986-396 = 590 cents ratio: 7/5 it's at 582, not 590 so it requires a 1,000 point penalty
            2 to 3: 986-102 = 884 cents ratio: 5/3
            Why did it score so badly?

            -----------------------------------------
            inx1 = 1, inx2 = 3, first = 396, sec = 986
            from first = 396 to sec = 986: distance = 590
            prior to removing outliers: [101 102 103 104 105 106 107]
            [(101, ('25/18', 569, 43)), (102, ('32/23', 572, 55)), (103, ('7/5', 582, 12)), (104, ('38/27', 592, 65)), (105, ('31/22', 594, 53)), (106, ('24/17', 597, 41)), (107, ('17/12', 603, 29))]
            cent_moves = array([569., 572., 582., 592., 594., 597., 603.]), cent_moves.shape = (7,)
            best_choice_overall = 2
            Optimizer: ('7/5', 582, 12), cent_deviation = 8.0
      Anyway, why do we get such a lower score when we just revoice the chord. Is that a fair manipulation? These four get 69 as a score
      The all started with 'A♯'. Coincidence? I don't think so. 
            chord_voicing = array([46, 66, 64, 61]), ['A♯' 'F♯' 'E♮' 'C♯']
            new_chord = array([1000,  614,  383,  116]), score = 69.0
            chord_voicing = array([46, 66, 61, 64]), ['A♯' 'F♯' 'C♯' 'E♮']
            new_chord = array([1000,  614,  116,  383]), score = 69.0
            chord_voicing = array([46, 61, 66, 64]), ['A♯' 'C♯' 'F♯' 'E♮']
            new_chord = array([1000,  116,  614,  383]), score = 69.0
            chord_voicing = array([46, 61, 64, 66]), ['A♯' 'C♯' 'E♮' 'F♯']
            new_chord = array([1000,  116,  383,  614]), score = 69.0
      What if we take those note choices and the run them through the score in a different order?
                                      ['F♯' 'E♮' 'C♯' 'A♯']
            revoiced_chord = np.array([614, 383, 116, 1000 ]) - 14
            revoiced_chord = array([600, 369, 102, 986]) # why didn't we pick this one, why the 32/27 ratio?
      I think what this shows is that I might get better results by using the combinations, then resorting the notes to their original configuration. 
      
            inx1 = 0, inx2 = 1, distance = 231
            found a cent in the table. ('8/7', 231, 15)
            inx1 = 0, inx2 = 2, distance = 498
            index_to_limits = 88, 498
            found a cent in the table. ('4/3', 498, 7)
            inx1 = 0, inx2 = 3, distance = 386
            index_to_limits = 69, 386
            found a cent in the table. ('5/4', 386, 9)
            inx1 = 1, inx2 = 2, distance = 267
            index_to_limits = 47, 267
            found a cent in the table. ('7/6', 267, 13)
      Notice that I had to search for the ratio using the gap here.
            inx1 = 1, inx2 = 3, distance = 617
            checking near distances. gap = 1
            index_to_limits = 110, 618
            found a cent in the table. ('10/7', 618, 17)
            inx1 = 2, inx2 = 3, distance = 884
            index_to_limits = 157, 884
            found a cent in the table. ('5/3', 884, 8)
            in score_chord_cents. score = 69.0
      The problem is the combination algorithm takes 18 seconds per chord. Not good. Maybe I could use combinations instead of permutations? Of rolls instead of either one. The best scores were obtained when we started with one of the four notes. That was all that was required to get optimum results. Got it down to 5 seconds per chord. What can I do to go farther? Can I slim down the score_chord_cents? Maybe fewer gaps?
            initial_chord = array([66, 64, 61, 46]), ['F♯' 'E♮' 'C♯' 'A♯'], new_chord = array([ 614,  383,  116, 1000]), score_chord_cents(new_chord) = 69.0
      Scores are dramatically better. But it does now take 4 min 32 seconds to go through the whole chorale. Only have to do it when I want to make a piece.
            egrep "(final_result)"  ball7.log | cut -d ' ' -f 10 | sort -g  | uniq
                  0
                  39.0
                  40.0
                  41.0
                  49.0
                  51.0
                  53.0
                  59.0
                  61.0
                  63.0
                  67.0
                  68.0
                  69.0
                  71.0
                  76.0
                  80.0
                  84.0
                  87.0
                  97.0
                  101.0
                  102.0
                  105.0
                  106.0
                  107.0
                  111.0
                  122.0
                  124.0
                  138.0
                  153.0

2.    Build a method to transpose chords, after they are formed, into locations based on rational judgements.
      What this will require:
      a.    A database of cent values for the 12 notes in the MIDI scale, stored by MIDI note. How many?
      b.    A way to evaluate conflicts, such as one note that wants the transposition to one place, and another wants a different spot, even up and down for the same chord. It will be up to the code to break those ties.
      c.    It should be started in the conversion from midi to cents in midi_to_notes_octaves. This is the routine that starts with midi numbers and ends up with tuned and scored cents for every chord. midi_to_notes_octaves
            octave = np.array([midi_number // 12 for midi_number in chorale])
            chord = remove_zeros_from_midi(chord)
            previous_chord_1200, score = improve_chord_permutations(chord)
            notes = np.concatenate((notes, previous_chord_1200.reshape(4,-1)), axis = 1)
      Remember that notes has all the previously notes saved in a nice array. Might as well use that, rather than any other dulicate and possibly corrupted place. 
      What I need is a database of what cent values were used for each 12 TET note. 
      Here's a zipped list of values, counts, and 12 tet together for all the unique notes. What would you change if you could fix as many as possible? 
      Numbers on the left are in 12 TET 
      0 = C 1 = C# 2 = D 3 = D# 4 = E 5 = F 6 = F# 7 = G 8 = G# 9 = A 10 = A# 11 = B
      From the list below, I've indicated some that have more than 10 candidates. That may not mean much
            1183 2 11   C
            0 2 0       C
            11 4 0
            16 2 0
            84 22 0           keep this one
            86 4 0
            88 4 0
            100 24 1    C#    keep this one
            102 4 1
            103 2 1
            116 10 1          keep this one
            196 2 1
            198 6 1
            200 48 2    D     keep this one
            202 10 2          keep this one
            214 22 2          keep this one
            216 18 2          keep this one
            283 2 2
            286 12 2          keep this one
            314 2 3     D#    
            370 2 3
            383 8 3
            384 14 3          keep this one
            386 2 3     
            398 8 3
            400 30 4    E     keep this one
            402 6 4
            416 6 4
            418 2 4     F
            584 8 5
            586 26 5          keep this one 
            598 42 5          keep this one
            600 20 6    F#    keep this one
            601 2 6
            602 30 6          keep this one
            604 4 6
            614 10 6          keep this one
            617 2 6
            698 2 6
            699 2 6
            700 21 7    G     keep this one
            714 18 7          keep this one
            716 13 7          keep this one
            784 2 7     G#
            884 2 8
            898 22 8          keep this one
            900 18 9    A     keep this one
            902 10 9          keep this one
            904 2 9
            916 10 9          keep this one
            984 20 9          keep this one
            986 2 9
            1000 10 10  A#    keep this one
            1018 1 10        
            1082 2 10        
            1084 30 10        keep this one
            1086 13 10        keep this one
            1096 4 10
            1098 10 10        keep this one
            1100 64 11  B     keep this one
            1102 6 11
      What you want is a way to quickly determine if the incomming notes can be improved if you transpose them to another cent key.
      Also would be helpful to know what sets of notes are associated with other notes to the exclusion of others. That will help decide if they can be all safely moved.
      Another idea is to move them a certain amount as a ratio to the notes in the next chord. Kind of like 3-d chess in a way.

-----------------------------
4/22/23 To do today:

1.    Why are the results so much better when I roll the chord. It requires 4 times the calculations. 
      Is there a more efficient way to get the same thing accomplished?
      What is it about starting at a different place that causes a better analysis?
      Could I do this without having to duplicate processeses?
      What happens when I roll today:
      start with C E G B
            0 to 1 C to E
            0 to 2 C to G
            0 to 3 C to B
            1 to 2 E to G
            1 to 3 E to B
            2 to 3 G to B
      In this 1st case, C and E are never challenged, while G is challenged twice and B is challenged 3 times
      My response is that we can always move C later, as we are doing after the roll operation.
      This becomes: E G B C
            0 to 1 E to G
            0 to 2 E to B
            0 to 3 E to C
            1 to 2 G to B
            1 to 3 G to C
            2 to 3 B to C
      In this second case, E and G are never challenged, but B is twice, C is 3 times
      This becomes: G B C E
            0 to 1 G to B
            0 to 2 G to C
            0 to 3 G to E
            1 to 2 B to C
            1 to 3 B to E
            2 to 3 C to E
      In this third case, G and B are never challenged, but C is twice, E is 3 times
      This becomes: B C E G
            0 to 1 B to C
            0 to 2 B to E
            0 to 3 B to G
            1 to 2 C to E
            1 to 3 C to G
            2 to 3 E to G
      In this 4th case, B and C are never challenged, but G is twice, E is 3 times

2.    Another idea: I could roll, but send through the already chosen cent values from the prior roll. Didn't help.

3.    What if I want to force more exotic ratios? Then you must lessen the penalty for going far in distance from the start.
      I now have four levers I can use to influence the process:
            improve_chord_permutations(initial_chord, range = 12, roll = 4, ratio_factor = .2, dist_factor = .2)
      range is how many ratios to optimize over. It finds some far away ones that have good interestingness.
      roll is how many times to try to rearrange the notes in a chord. 4 is good, because the stop_when = can control how bad to allow through.

4.    I put a check in the roll routine to see if the score is better than 30 and to break. It significantly speeds up the process. 
      27.5 seconds for the whole 177 chord chorale. It's not that fast any more. Not sure what changed.

5.    The woodwinds are about an octave too high. Fixed it in woodwind_part:
            octave_alteration_mask = build_octave_alteration_mask(repeats, voices, chorale, octave_reduce = 3)
      Big improvement. It's now listenable as ball7-t23. Haven't posted it anywhere. I want to take the first step towards horizontal first. 

6.    I still need to fix the horizontal optimizations. Some ideas:
      a.    Just worry about a few key notes, like F#, B, and the like. Don't I count up the presense of notes using unique, counts?
            chorale.shape = (4, 177)
            unique_note_names = array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11])
            unique note names:          ['C♮' 'C♯' 'D♮' 'D♯' 'E♮' 'F♯' 'G♮' 'G♯' 'A♮' 'A♯' 'B♮']
            count_of_note_names = array([ 10,  70, 106,  16,  78, 144,  56,   2,  64,  33, 129])
            Automate the process of picking the few most common notes, and when those note shows up, transpose so it into the value that you have preselected. 
      b.    For example, make sure, when practical, that if an B is present, that it be 1100 cents 
            if a F# is present, it be 602 cents
            if a D is present, it be either 216 or 
            For example, subset the chorale:
                  new_chorale = chorale[:, [0, 15, 20, 48, 102, 132, 140]]
                  0. initial_chord = array([71, 66, 62, 59]), ['B♮' 'F♯' 'D♮' 'B♮']
                  new_chord = array([1100,  602,  216, 1100]), round(score,1) = 7.8 # don't do anything to this one
                  1. initial_chord = array([68, 66, 59, 54]), ['G♯' 'F♯' 'B♮' 'F♯']
                  new_chord = array([ 800,  596, 1094,  596]), round(score,1) = 21.4 # up 6 cents to 806, 602, 1100, 602
                  2. initial_chord = array([71, 66, 59, 50]), ['B♮' 'F♯' 'B♮' 'D♮']
                  new_chord = array([1100,  602, 1100,  216]), round(score,1) = 7.8 # do nothing here
                  3. initial_chord = array([73, 66, 58, 54]), ['C♯' 'F♯' 'A♯' 'F♯']
                  new_chord = array([100, 598, 984, 598]), round(score,1) = 8.0 # up 4 cents to 104, 602, 988, 602
                  4. initial_chord = array([73, 64, 55, 54]), ['C♯' 'E♮' 'G♮' 'F♯']
                  new_chord = array([100, 416, 683, 598]), round(score,1) = 20.6 # up 4 cents
                  5. initial_chord = array([67, 66, 59, 52]), ['G♮' 'F♯' 'B♮' 'E♮'] # how did this get here?
                  before find_intervals: chord_in_1200 = array([ 700,  600, 1100,  400]) # lots of movement. get the B & F# right
                  new_chord = array([ 684,  572, 1070,  368]), round(score,1) = 16.0 # up 30 cents to 714, 602, 1100, 398
                  6. initial_chord = array([66, 64, 61, 46]), ['F♯' 'E♮' 'C♯' 'A♯']
                  new_chord = array([600, 418, 102, 986]), round(score,1) = 19.4 # up 2 cents to 602, 420, 104, 988
            What needs to happen is that all the F# should be set to 602 and the B to 1100. If you do that, you might be finished.
            I can do this much in improve_chord_permutations or midi_to_notes_octaves.

            

7.    Vscode select columns: cursor in one corner of the selection, then press shift-alt.
      https://code.visualstudio.com/docs/editor/codebasics#_column-box-selection

8.    What if I add two more interval checks to the six I already have.
      0 to 1
      1 to 2
      2 to 3
      0 to 2
      1 to 3
      0 to 3
      2 to 1
      3 to 2
      3 to 1

9.    It's reasonably speedy now that I've implemented the few simplifications, shortcuts, and retuning for horizontal purposes.
            Execution Time 1m 37.1s The log file is 14,500 lines. That's pretty loggy.

-------------------------------------------
4/23/23 To do today:

1.    Try transposing the chord back to it's origin, either the highest or lowest notes. You did that previously, but then forgot about it.
      In improve_chord_permutations at the end, first log the changes you might make, then see how it might work. And my conclusion is that there are no important changes other than those that make the two top_notes correct. All other changes to make one of the starting notes like the ending notes would ruin the top_notes. It would make things worse, not better. So I chose right yesterday. Except for that bug thing. All the transpose requested wold make the result worse, or at best neutral.

2.    While looking at improve_chord_permutations I noticed that I don't ensure it pushed the chord in the right direction. Oops.
      I fixed it. There are some problems that need addressing with E in top_notes:
            found a top_note at inx = 0. cent value note = 600 which is a F♯ that is not at the cent value we expect It should have cent value of: 602
            found a top_note at inx = 1. cent value note = 102 which is a C♯ that is not at the cent value we expect It should have cent value of: 104
            found a top_note at inx = 3. cent value note = 418 which is a E♮ that is not at the cent value we expect It should have cent value of: 398
            gaps = array([  2,   2,   0, -20,   0])
            gaps are found: gaps_found = array([0, 1, 3]), gaps[gaps_found] = array([  2,   2, -20])
            transposing failed. gaps = array([  2,   2,   0, -20,   0]) not all equal. 2 -20 What do I do boss?
      These are the only chords that had the possibility of being transposed, according to my log files. Also all the D would have been transferred without their presense, so I can reduce the size of the top_notes to just C#, B, F# and get the same result.
      Fixed that. Sliced the top_notes array:
            top_notes = top_notes[:,[0,3,4]]
      This is another finger on the scale. 
      Now I'm up to 6:49 to run the whole chorale. Getting worse. 

3.    Would adding C# to the top notes make a difference? Only for the worse.

3.    I'm thinking that before I go any further with this algorithm, I should really try reinforcement learning just to see if it can't do a better job of finding the optimum tuning. Might take a bit longer, but wouldn't it be cool?

4.    Some other ideas:
      a.    Find that piece from the WTC that goes through all the keys, and is largely atonal, and see how my algorithm handles it. bwv891. Very chromatic. Too few voices to make useful. 
      b.    Build a series of orchestras with different instruments, like strings, martele strings, pizzicato strings; horns, baritone guitar, finger piano, balloon drums; 

5.    Another chorale from the St. Matthew Passion 244.17 very familiar. Erkenne mich, mein Huter. 
            chorale.shape = (4, 257), KEYS_FLATS[root] = 'E♭', mode = 'major'
            Which notes should I use to guide the transpositions? Eb & Bb to start
            sliced chorale: chorale.shape = (4, 257)
            [ 0    2    3    4    5    7   8    9   10   11]
            ['C♮' 'D♮' 'E♭' 'E♮' 'F♮' 'G♮' 'A♭' 'A♮' 'B♭' 'B♮']
            [216  80  226   12  102  152  72   12  140   16]
            Top five most used in the chorale: 
            [ 5,  10,   7,   0,  3]
            ['F♮' 'B♭' 'G♮' 'C♮' 'E♭']
            102  140  152  216  226
            Using these to retune chords
            cent values for top_notes before tuning: chord_in_cents = array([ 500, 1000,  700,    0,  300]).
            top_notes.shape = (2, 2)
            top_notes = array([[   5,   10],
                  [ 500, 1000]])
            Something is screwey with the transpositions with this one. Sounds really off. I had swapped the Eb for Bb. There are so many indeciis at that point that it's hard to keep things straight.
            Other problems. My transposition function threw up:
                  after rearranging. round(best_score,1) = 28.0, final_result = array([  0, 332, 969, 702])
                  note at 1 E♭ should have cent value of: 300
                  note at 2 B♭ should have cent value of: 1002
                  gaps are found: gaps_found = array([1, 2]), gaps[gaps_found] = array([-32,  33])
                  transposing failed. gaps = array([  0, -32,  33,   0]) not all equal. 33 -32 What do I do boss?

---------------------------
4/24/23 To do today:

1.    Get a clean Erkenne mich, mein Hüter with just the winds and no screwy envelopes. 
      Try different tuning levers: 
                                                                  +-- how far to go looking for interesting intervals - this is a very low cost addition, up to a point, say 12.
                                                                  |          +-- roll 4 times, unless you find a good score early (see stop_when), then stop
                                                                  |          |         +-- multiply the distance by this when calculating score - small numbers reduce the impact on distant ratios
                                                                  |          |         |                 +-- multiply the num den by this when calculating score - small numbers penalize big ratios less
                                                                  |          |         |                 |                  +-- scores below this are considered good enough. 
            improve_chord_permutations(initial_chord, top_notes, range = 12, roll = 4, dist_factor = .2, ratio_factor = .2, stop_when = 25):
      calls:
            find_intervals(initial_chord, range = 6, ratio_factor = 1, dist_factor = 1):
      in this way: result = find_intervals(np.roll(best_choice,inx), range = range, ratio_factor = ratio_factor, dist_factor = dist_factor) 

2.    Must get legato on the holds.      

3.    Something wierd happens at 50 seconds in. Clearly microtonal movement. It's measure 8 beats 12-15 chords 140-143
      142 is highly suspect: 
            top_notes[0]] = array(['C♮', 'G♮', 'B♭'] 
            initial_chord = array([72, 63, 58, 55]), ['C♮' 'E♭' 'B♭' 'G♮'] # Cm7 or Eb6
            after rearranging. round(best_score,1) = 28.0, final_result = array([  0, 332, 969, 702])
            note at 2 B♭ should have cent value of: 1018
            transposing chord: 142 adding gaps[gaps_found][0] = 49 to the chord
            142, after transposition: final_result = array([  49,  381, 1018,  751])
      So it already had a C and G at the top_notes spot so needed no movement, but because the Bb wasn't where it wanted it, it moved it 49 cents. 
      When should I have a vote about a movement?
      49 is a half semitone. 1/4 tone, as they say. Sticks out like a sore thumb, or if you prefer a skunk cabbage in a swamp.
      Start here tomorrow.

4.    I need to be able to track every message back to what chord_number it's on. Done. 
      
5.    It keeps seeming to jump octaves on its own. It could be it's reassigning notes in top_notes? 
      I figured out the problem and fixed it. Not so fast. By the fourth note in the first measure, it's off already. The problem starts at chord_number = 12 - 15
      Once I included more notes, the problem went away. 
            if not np.array_equal(chord, previous_chord): # if this is a new chord, then calculate the conversion to cents for previous_chord
                  logging.info(f'new chord arrived. {chord_number = }, {chord = }, {previous_chord = }')
                  previous_chord_1200, score = improve_chord_permutations(chord, top_notes, chord_number - 1)
                  logging.info(f'{chord_number = } improved the chord. {previous_chord_1200 = }, {round(score,1) = }')   
      
      chord: 19 adding gaps[gaps_found][0] = 1198 to the chord             
            found a top_note at inx = 2. cent value note = 2 which is a C♮ that is not at the cent value we expect
            note = 2 at position 2 C♮ should have cent value of: 0
            gaps are found: gaps_found = array([2]), gaps[gaps_found] = array([1198])
            transposing chord: 19 adding gaps[gaps_found][0] = 1198 to the chord
      I removed the % 1200 at the end. It was turning -2 into 1098. Oops.
            gaps[inx] = (expected_value - note) # % 1200 # commented it out.
      Two seconds per quarter note. 8 seconds per measure. Something goes whack at chords 20, 21 which is 12 seconds in. That was the modulo 1200 problem. Fixed it.

6.    This is the highest score in the whole chorale: only 23:  This is beat 174, 175 which is in measure 10, beats 14 & 15 out of 16
            174 final_score previous_chord_1200 = array([ 830,  702,  702, 1200]), round(score,1) = 23.0 
            175 final_score previous_chord_1200 = array([ 830,  702,  702, 1200]), round(score,1) = 23.0
            array([68, 67, 60, 55]), ['A♭' 'G♮' 'C♮' 'G♮']
            in cents before find_intervals: chord_in_1200 = array([800, 700,   0, 700])
            This is a very challenging chord, he did the best he could


-------------------
4/25/23 To do today:

1.    Make it so transpose_top_notes stops looking for a viable transposition if one of the top_notes is already where it belongs. Just bail. This won't work:

      if gaps[inx] == (expected_value - note): # if you found that one of the top_notes is where it belongs, bail
                logging.info(f'found one of the top_notes @ {inx} where it belongs. {gaps[inx] = }, {expected_value = }, {note = }. Bail. ')
                return final_result
      But this did:
            if note in top_notes[1]: # if this is the exact cent value of one of the top_note values, you're done
            logging.info(f'found one of the top_notes @ {inx} is where it belongs. {note = }. {KEYS_FLATS[note_12 % 12]} Bail.')
            return final_result

2.    Somthing is wrong with 192,3. It should have E as a high note, and it gets turned into F somehow
            new chord arrived. chord_number = 192, chord = array([75, 65, 60, 57])
            initial_chord = array([75, 65, 60, 57]), ['E♭' 'F♮' 'C♮' 'A♮'] [300, 500,   0, 900]
            in cents before find_intervals: chord_in_1200 = array([300, 500,   0, 900])       
      And then just before concatenation it's an F.
            chord_number = 192 improved the chord. chord_1200 = array([ 496,  882,  314, 1198]), round(score,1) = 19.0         

      Here is the progression of the chord. I wonder if it was a mistake in the rearrangement after the roll found a great score?
            score for the chord before changing [ 300  504 1184  882]: round(prev_score,1) = 1031.8
            in score_chord_cents. round(score,1) = 1031.8
      Here is where it first rolled and got a great result: 31.4 [ 882  300  496 1198] ['A♮' 'E♭' 'F♮' 'C♮' ] [900, 300, 500,  0]
            
            results_so_far: np.roll(best_choice,inx) = array([ 300,  504, 1184,  882]), ['E♭' 'F♮' 'A♮' 'C♮' ] [ 300, 500, 900,  0] round(score,1) = 1031.8
            in score_chord_cents. round(score,1) = 31.4 
            score for the chord before changing [ 882  300  496 1198]: round(prev_score,1) = 31.4
            in score_chord_cents. round(score,1) = 31.4
            results_so_far: np.roll(best_choice,inx) = array([1198,  882,  300,  496]), [ 'C♮' 'A♮' 'E♭' 'F♮' ] round(score,1) = 31.4
            in score_chord_cents. round(score,1) = 1030.0
            score for the chord before changing [ 496 1198  882  292]: round(prev_score,1) = 1030.0
      Here is where it rolled again and got an even better result: 19.0 [ 496 1198  882  314]  ['F♮' 'C♮' 'A♮' 'E♭' ]
            in score_chord_cents. round(score,1) = 19.0
            score for the chord after making a change to [ 496 1198  882  314]: round(new_score,1) = 19.0
            in score_chord_cents. round(score,1) = 19.0
            score for the chord before changing [ 496 1198  882  314]: round(prev_score,1) = 19.0
            in score_chord_cents. round(score,1) = 19.0
      Is this the optimum rearrangement? F on top, when it should be Eb on top.
            after rearranging. round(best_score,1) = 19.0, final_result = array([ 496,  882,  314, 1198])
      And here it is about the concatenate to the chorale_in_cents: 
            chord_number = 192 improved the chord. chord_1200 = array([ 496,  882,  314, 1198]), round(score,1) = 19.0
      The problem was that it didn't think 1198 was close to 0, which of course it isn't. We need a better way to determine proximity than the one I'm using.
      Could we get by with just a roll instead of permutations? I think so, but I have to do it carefully. For example, my fix had this unintended consequence:
            178. start here initial_chord = array([68, 65, 60, 58]), ['A♭' 'F♮' 'C♮' 'B♭']
            after rearranging. round(best_score,1) = 13.6, final_result = array([ 982,  800,  484, 1186])
      It should have picked 800, 484, 1186, 982
            before rearranging. chord_in_1200 = array([ 800,  500,    0, 1000]), best_choice = array([ 800,  484, 1186,  982])
            sum_of_sums = [1220, 1152, 2184, 2184]
            index of the minimum sum of sums: 1
            after rearranging. round(best_score,1) = 13.6, final_result = array([ 982,  800,  484, 1186])
      I have to suppose that it's that 1186 masquerading as a 0 that is causing the trouble. How can I made the 1186 look more like a 0?
            rounded_best_choice_12 = np.array([int(round(note / 100,0)) % 12 for note in best_choice])
            rounded_chord_in_1200 =  np.array([int(round(note / 100,0)) % 12 for note in chord_in_1200])
            print(f'{chord_in_1200 = }\n{best_choice = }\n{rounded_best_choice_12 = }\n{rounded_chord_in_1200 =}')
            sum_of_rolls = [[abs(val1 - val2) for val1, val2 in zip(np.roll(rounded_best_choice_12, inx), rounded_chord_in_1200)] for inx in np.arange(4)]
      That fixed it. Convert the decision about rearrangement into numbers between 0 and 11. Solves the whole problem.
      Still a few problems. But nothing major. That 869 in measure 8 chord 142 is wierd, but in a charming way. 
      Also some octaves are whack in measure 8 chords 128-132. Here is what is happening with those notes.
            egrep "(rounded|rearranging)" testing.log | cut -d " " -f 8-30
                  before rearranging. chord_in_1200 = array([300,   0, 700,   0]), best_choice = array([ 300, 1184,  686, 1184])
                  rounded_best_choice_12 = array([3, 0, 7, 0]), rounded_chord_in_1200 =array([3, 0, 7, 0])
                  after rearranging. round(best_score,1) = 7.8, final_result = array([ 300, 1184,  686, 1184])
                  before rearranging. chord_in_1200 = array([300,   0, 700,   0]), best_choice = array([ 300, 1184,  686, 1184])
                  rounded_best_choice_12 = array([3, 0, 7, 0]), rounded_chord_in_1200 =array([3, 0, 7, 0])
                  after rearranging. round(best_score,1) = 7.8, final_result = array([ 300, 1184,  686, 1184])
                  before rearranging. chord_in_1200 = array([ 300, 1000,  700,    0]), best_choice = array([ 300, 1002,  686, 1184])
                  rounded_best_choice_12 = array([ 3, 10,  7,  0]), rounded_chord_in_1200 =array([ 3, 10,  7,  0])
                  after rearranging. round(best_score,1) = 11.8, final_result = array([ 300, 1002,  686, 1184])
                  before rearranging. chord_in_1200 = array([ 300, 1000,  700,    0]), best_choice = array([ 300, 1002,  686, 1184])
                  rounded_best_choice_12 = array([ 3, 10,  7,  0]), rounded_chord_in_1200 =array([ 3, 10,  7,  0])
                  after rearranging. round(best_score,1) = 11.8, final_result = array([ 300, 1002,  686, 1184])
      That looks fine. So what about those octaves?
                  chorale_in_cents[:, 129:132].shape = (4, 3, 2)
                  [[[ 316 1200  702 1200] # <-- 1200 cents is not legal. Although it's in the table. Not really, the size is 1200 starting at 0 it ends at 1199 But that's not the problem I'm working on now
                  [ 316 1018  702 1200]
                  [ 316 1018  702 1200]]

                  [[   6    6    5    5]
                  [   6    5    5    5]
                  [   6    5    5    5]]]
      Octaves look fine here. What about in new_output.csd. Measure 8 is 2 seconds per quarter note * 32 quarter notes = 64.0 seconds
            
      After fixing the 1200 problem:
            ;Inst Sta       Hold Vel Ton       Oct Voi Ste En1 Gls Ups Ren 2gl 3gl Vol
            i 1.0 63.992 2.02 64.0 0.0       5.0 10.0 5.0 16.0 0.0 0.0 16.0 0.0 0.0 5.0 
            i 1.0 63.997 2.02 66.0 702.0       5.0 7.0 11.0 16.0 0.0 -1.0 16.0 0.0 0.0 5.0 
            i 1.0 64.001 2.02 66.0 702.0       5.0 8.0 12.0 1.0 0.0 -1.0 1.0 0.0 0.0 5.0 
            i 1.0 64.003 1.01 64.0 0.0       6.0 9.0 5.0 16.0 0.0 -1.0 16.0 0.0 0.0 5.0 
            i 1.0 64.005 2.02 66.0 316.0       6.0 8.0 10.0 1.0 0.0 0.0 1.0 0.0 0.0 5.0 
            i 1.0 64.006 2.02 66.0 316.0       6.0 7.0 2.0 1.0 0.0 -1.0 1.0 0.0 0.0 5.0 
            i 1.0 64.009 2.02 66.0 0.0       5.0 9.0 4.0 16.0 0.0 0.0 16.0 0.0 0.0 5.0 
            i 1.0 64.011 1.01 64.0 0.0       6.0 10.0 6.0 16.0 0.0 -1.0 16.0 0.0 0.0 5.0 
            i 1.0 64.997 1.01 66.0 1018.0 5.0 10.0 5.0 16.0 0.0 -1.0 16.0 0.0 0.0 5.0 
            i 1.0 65.008 1.01 66.0 1018.0 5.0 9.0 15.0 16.0 0.0 0.0 16.0 0.0 0.0 5.0 

4.    What is that 1200 doing there. print(f'{np.max(chorale_in_cents[:,:,0])}') # 1222 That's not valid at all!

            after rearranging. round(best_score,1) = 13.6, final_result = array([ 800,  484, 1186,  982])
            found a top_note at inx = 3. cent value note = 982 which is a B♭ that is not at the cent value we expect.
            note = 982 at position 3 B♭ should have cent value of: 1018
            gaps are found: gaps_found = array([3]), gaps[gaps_found] = array([36])
            transposing chord: 177 adding gaps[gaps_found][0] = 36 to the chord
            after transposition: final_result = array([ 836,  520, 1222, 1018])
      Fixed it:
            final_result = (final_result + gaps[gaps_found][0]) % 1200 # took me a while.


-------------------------------------------
4/26/23 To do today:

1.    I can't remember how I generated this list of keys:
      ([1100,  602,  216, 1100]) ['B♮' 'F♯' 'D♮' 'B♮'] [('1/1', 0), ('4/3', 498), ('5/4', 386), ('5/3', 884)]
      There are a number of other reports I could generate that would evaluate the settings in place at the time. For example:
      a.    List all the intervals between notes in every chord in cents and ratios 
      b.    Different sorts and groups by to look for trends. For example, if one note moves too much
      c.    Group different cents used for each of the notes in 12 TET.
      b.    Recommend changes to levers based on results of the reports. 
      c.    Consider playbooks - preconfigured sets of settings or changes to settings to improve performance and increase or decrease wolfiness.

      Try different tuning levers: 
            range = 12 # how far to go looking for interesting intervals - this is a very low cost addition, up to a point, say 12.
            roll = 4 # roll 4 times, unless you find a good score early (see stop_when), then stop. I see no reason for any other value
            dist_factor = .2 # multiply the distance by this when calculating score - small numbers increase the likelihood of ratios farther from the 12 TET cents. Large numbers use ratios closer to 12 TET cent values
            ratio_factor = .2 #  multiply the num den by this when calculating score - small numbers penalize big ratios less - not involved in ratio selection, only in scoring. A chord with high numerator/denominator values increase the score, unless you set ratio_factor to a low value. 
            stop_when = 25 # scores below this are considered good enough, stop doing any additional rolls when the score is this good or lower.
            cent_reach = 36 # limit the distance in cents from the starting point you are willing to go to find a ratio. 
            top_notes # This is an array of (12TET note values, cent values). These are the notes (0-11) that the algorithm strives to keep on one particular cent value (0-1200). After all the interval ratios have been chosen, the program examines the generated chord. If a top_note is in a chord, and not located at the top_note cent value, the program will transpose the whole chord to meet that the top_note cent value. There should not be too many of these, because it could cause a conflict when the algorithm is presented with a chord that has two different top_notes, and they ask to be moved to a cent value that would cause other notes to move away from their preferred cent value, or in different directions. Our program gives up at that point and 
                                                                 
            improve_chord_permutations(initial_chord, top_notes, range = 12, roll = 4,,  stop_when = 25):
      calls:
            def find_intervals(initial_chord, range = 6, ratio_factor = 1, dist_factor = 1):
      called in this way: 
            result = find_intervals(np.roll(best_choice,inx), range = range, ratio_factor = ratio_factor, dist_factor = dist_factor)
      Where are these values used:
            def score_chord_cents(chord_1200, ratio_factor = 1): #
            def find_intervals(initial_chord, range = 6, ratio_factor = 1, dist_factor = 1, cent_reach = 36):
            limit_31_values[ratio,:] # This is a list of valid ratios to choose from. I set them to the 213 ratios in the tonality diamond to the 31 limit.
            limit_value = 31 # this sets the number of overtones and undertones in the tonality diamond. 31 works for me, but very few of the upper ratios ever make it into a piece, unless you set ratio_factor to a very low number, like less than .2

2.    Some of the worst offenders report has uncovered some issues:
            report of the worst offenders in terms of numerator and denominator
            # of chord  cents in the chord names of the notes cents and ratios in the intervals sum of the numerator and denominator in the ratios of the intervals
            32 [ 200  516 1084  200] ['D♮', 'F♮', 'B♮', 'D♮'] (316, '6/5') (884, '5/3') (0, '1') (568, '68/49') (316, '6/5') (884, '5/3')       117
            50 [ 204  520 1088  702] ['D♮', 'F♮', 'B♮', 'G♮'] (316, '6/5') (884, '5/3') (498, '4/3') (568, '68/49') (182, '10/9') (386, '5/4') 117
            ...
            206 [316 702   0 884]       ['E♭', 'G♮', 'C♮', 'A♮'] (386, '5/4') (316, '6/5') (568, '68/49') (702, '3/2') (182, '10/9') (884, '5/3') 117
            Maximum numerator and denominator in the piece: 117
            Take a look at the chords by chord number and see if there isn't something you can do about it

      It could be:
      So what happened that caused the algorithm to choose ratios like 68/48, which is not in the interval table, as far as I know.
      Here's what happened. The scoring was suspicious.
            def score_chord_cents(chord_1200, ratio_factor = 1): 
      It fiddles with the cent value to find a ratio near where there is a ratio in the table.
      It starts out looking for a ratio at distance = 568 in limit_31_values, the database of valid ratios, their cent equivalents, and the num_den sum
      
            inx1 = 1, inx2 = 2, distance = 568
            checking near distances. gap = 0
            index_to_limits = 101, 568
      It then searches for 1 less the 568 at 567 and does not find an entry in the table of ratios for 567 either
            checking near distances. gap = -1
            index_to_limits = 101, 567
      It then searches for 1 more than 568 and finds the cent value at 568 for 25/18, that well known ratio we all have come to love.
            checking near distances. gap = 1
            index_to_limits = 101, 569
      It then reports that it's found a near hit, slight miss, close enough for horseshoes, within specifications. 
            found a cent in the table. ('25/18', 569, 43)
            limit_31_values[index_to_limits,2] = 43.0
      Reports a locate, and moves on. But when my report comes along, it doesn't have the time to do all that work, it just says it's 68/48. But if I limit the denominator, I can get close enough. When presented with 568 cents, if the limit_denominator is set at 67 or above, it reports 25/18. Any lower and it reports 68/49. That's not what I would have expected. But then limit_denominator is a black box for me. 
            (67, '25/18')
            (66, '68/49')
      So I need to go back to my worst case report and adjust the limit_denominator
      Interesting feature of Fraction:  f = Fraction(1, 5)
      f.numerator
      1
      f.denominator
      5
      I can skip a lot of code now. But that won't solve my accuracy problem. I set to limit_denominator = 48 and it works now.
      I made  a new function to speed up the transition from cents to numerator & denominator:
            def cents_to_num_den(cents, limit_denominator = 105):
                  f = Fraction(np.power(2, cents/1200)).limit_denominator(limit_denominator)
                  return f.numerator, f.denominator
      Fixed it, temporarily:
            report of the worst offenders in terms of numerator and denominator
            # of chord  cents in the chord names of the notes cents and ratios in the intervals sum of the numerator and denominator in the ratios of the intervals
            142 [  0 332 969 702] ['C♮', 'E♭', 'B♭', 'G♮'] (332, '63/52') (969, '7/4') (702, '3/2') (637, '13/9') (370, '26/21') (267, '7/6') 73
            154 [316 520 814 316] ['E♭', 'F♮', 'A♭', 'E♭'] (204, '9/8') (498, '4/3') (0, '1') (294, '32/27') (204, '9/8') (498, '4/3') 59
            Maximum numerator and denominator in the piece: 73
            Take a look at the chords by chord number and see if there isn't something you can do about it
            It could be:
            1.   A problem with conversion of cents to numerator & denominator of a ratio. It relies on the python Fraction function, which is subject to floating point issues
      Another solution would be to query the limit_31_values table for a cent value, and accept near misses, because that's what the score_chord_cents function does.

3.    Posted the ball8-t1.mp3 on a new substack page. Very nice user interface. I like it better than my Wordpress site at ripnread.com. 
      It includes a way to upload music, which is nicer than having to FTP, create a link code, copy the link code, and test the whole thing. Very nice.      

--------------------------------------
4/27/23 To do today:

1.    Create a report of all the chords used and post it on Ripnread. Find out how it handles diminished 7th chords. I like 5:6:7:8 - not sure about 17 though.
      The report choked on 176 [ 800  484 1186  800]. IndexError: index 12 is out of bounds for axis 0 with size 12 in line:
            print([KEYS_FLATS[int(round(note / 100, 0))] for note in final_result], end = '\t')
      I decided I should not try to replicate the numerator/denoninator calculations, and just sent the chords to the score_chord_cents function, along with the ratio_factor = .2. That works, and it has the added benefit of being simpler and more in line with how the algorithm processes the scoring. The score_chord_cents function, for example, is willing to go up and down a cent to locate a ratio, like 568 cents, which isn't in the limit_31_values, but 559 is a 7/4, one of my favorites. 

2.    In the report, include both the notes as rounded from chorale_in_cents, but also the notes as the occurred in the MIDI file in chorale. 
      Maybe zip them to gether and only print the discrepancies. Goal is to highly wrong notes in the conversion.

3.    Think about how you could use np.diff:
            arr = np.array([12, 10, 45, 65, 3])
            diff_arr = np.diff(arr)
            print(diff_arr)
            Output:
            [ -2  35  20 -62]
      It looks inside a single array and calculates the difference between adjacent elements of the array.
            10 - 12 = -2
            45 - 10 = 35 
            65 - 45 = 20
            3 - 65 = -62
      This could be useful to compare intervals, instead of using (inx + 1) % 4
      Found a good use here while searching for where there is a difference between the midi_notes (chorale.T) chords and what rounding the chorale_in_cents chord finds.
            chord_12_rounded = np.array([int(round(note / 100, 0) % 12) + (octv * 12) for (note, octv) in zip(chord_1200, octaves)])
            delta = np.argmax(np.abs(np.diff(np.array([chord_12_rounded, midi_notes]), n=1, axis=0))) # where is the difference located. Needs that abs to prevent negative numbers not showing up.
            if octaves[delta] == 0: pass #  0 in the octave means this note will never be played
      You make an array out of two arrays, then the np.diff returns the index where there is a difference. If the only difference is in a column where the octave is zero, then you can ignore it, since all notes with 0 in the octave field are ignored in the send_to_csound_file function.

4.    Thinking about what Paul Erlich said in the Facebook link to Tonalsoft article on Adaptive Just Tuning: 
      http://tonalsoft.com/enc/a/adaptive-ji.aspx 
      ?fbclid=IwAR2wIVa0HHXARiK0NMghZMtoE-7vGkY0uSNvqgUGaIs7n2e7pqrfkME1M2U
      He defines it as "A form of temperament in which some algorithm is used which keeps the ratios of simultaneous sounds exactly in just-intonation, but uses non-JI melodic intervals to reduce the retuning motion and/or drift relative to a strict JI realization." That's exactly what I'm doing. 
      "In adaptive JI the pain of having vertical sonorities deviate from JI is infinite, while in adaptive tuning, all the different components of pain get traded off against one another."
      So he distinguishes between Adaptive Just Intonation, and Adaptive Tuning.
      "The two types of Strict JI would be
            (a) one with a finite set, though not necessarily closed, set of fixed pitches, so that drift doesn't occur; and
            (b) one with a potentially infinite use of pitches from the JI lattice, with a preference for observing common tones, so that drift may occur.
      I've called the former "Fixed-pitch JI" and the latter "Freestyle JI" -- the term "strict" qualifies both these subcategories."
      Mine is not really like those two, so I guess I'm an innovator.
      He talks about Dave Keenan's challenge:
      "Below is an example by Dave Keenan of a I-VI-II-V-I "comma-pump" chord progression, written in the "sagittal" notation developed by he and George Secor in 2002, and tuned by Monzo in 1/4-syntonic-comma adaptive-JI (click on the graphic to hear the MIDI-file)."
                  C  Am Dm G  C
                  G  A  A  G  G
                  E  E  F  D  E
                  C  C  D  B  C
      Here is the report out of Keenan at ratio_factor = .75, which tends to find lower integer ratios, 
            top_notes = np.array([[7, 9], [702, 902]])
      
            report the chords used, with chord scores
      #  names of the notes       cents of notes       intervals between notes, the cents and ratios of the intervals  chord score
      1   ['A♮', 'E♮', 'C♮', 'A♮'] [902 404  18 902]       (0, 1, 498, '4/3') (0, 2, 884, '5/3') (0, 3, 0, '1') (1, 2, 386, '5/4') (1, 3, 498, '4/3') (2, 3, 884, '5/3')  29.2
      2   ['D♮', 'A♮', 'F♮', 'D♮'] [200 902 516 200]       (0, 1, 702, '3/2') (0, 2, 316, '6/5') (0, 3, 0, '1') (1, 2, 386, '5/4') (1, 3, 702, '3/2') (2, 3, 316, '6/5')  30.8
      3   ['G♮', 'G♮', 'D♮', 'B♮'] [ 702  702  204 1088] (0, 1, 0, '1') (0, 2, 498, '4/3') (0, 3, 386, '5/4') (1, 2, 498, '4/3') (1, 3, 386, '5/4') (2, 3, 884, '5/3')  30.0
      4   ['C♮', 'G♮', 'E♮', 'C♮'] [  0 702 386   0]       (0, 1, 702, '3/2') (0, 2, 386, '5/4') (0, 3, 0, '1') (1, 2, 316, '6/5') (1, 3, 702, '3/2') (2, 3, 386, '5/4')  29.2
      Maximum score was: 30.8

      And here is the same at ratio_factor = .2 - same exact cent values and ratios.
      report the chords used, with chord scores
      #  names of the notes  cents of notes  intervals between notes, the cents and ratios of the intervals     chord score
      1   ['A♮', 'E♮', 'C♮', 'A♮'] [902 404  18 902]       (0, 1, 498, '4/3') (0, 2, 884, '5/3') (0, 3, 0, '1') (1, 2, 386, '5/4') (1, 3, 498, '4/3') (2, 3, 884, '5/3')  7.8
      2   ['D♮', 'A♮', 'F♮', 'D♮'] [200 902 516 200]       (0, 1, 702, '3/2') (0, 2, 316, '6/5') (0, 3, 0, '1') (1, 2, 386, '5/4') (1, 3, 702, '3/2') (2, 3, 316, '6/5')  8.2
      3   ['G♮', 'G♮', 'D♮', 'B♮'] [ 702  702  204 1088] (0, 1, 0, '1') (0, 2, 498, '4/3') (0, 3, 386, '5/4') (1, 2, 498, '4/3') (1, 3, 386, '5/4') (2, 3, 884, '5/3')  8.0
      4   ['C♮', 'G♮', 'E♮', 'C♮'] [  0 702 386   0]       (0, 1, 702, '3/2') (0, 2, 386, '5/4') (0, 3, 0, '1') (1, 2, 316, '6/5') (1, 3, 702, '3/2') (2, 3, 386, '5/4')  7.8
      Maximum score was: 8.2

5.    If you want to change the ratio_factor, or any other lever, you have to do it when you call:
            midi_to_notes, that's where you can set it for all downstream functions/
            chorale_in_cents = midi_to_notes_octaves(chorale, top_notes, ratio_factor = .75) 

6.    I wish I could put that final report in better form. I'm thinking if I could load it into a pandas array, I could really get some insights.

----------------------------
4/26/23 To do today:

1.    I'd like to greatly expand my orchestra to include many more instruments, and more envelopes. 
      I like what happens to the finger piano when the envelope changes, but I would prefer it if it happened more gradually and over longer time horizons. I'd like to be able to fade from finger piano to pizzicato strings to marimbas & xylophone to vibraphone & harp, to martele strings; and from woodwinds to brass to bowed strings to piano with no attack. So in total that's a lot of sample files.
            voices      instrument  csound samples # samples
      finger_piano_part:
            8           finger piano      1           25
            8           pizzicato         4           64
            4           marimbas          1           18
            4           xylophone         1           20
            4           vibraphone        1           13
            4           harp              1           20
            8           martele strings   4           36
                        guitar strings
                        baritone guitar   1           45
                        ernie ball super  1           36
                        long strings      1           30
                        original strings  1           24
      woodwind_part:
            8           woodwinds         5
                        bassoon           1           6
                        clarinet          1           19
                        flute no vib      1           15
                        oboe              1           15
                        french horn       1           20             
            8           bowed strings vib 4
                        violin            1           20
                        viola             1           18
                        cello             1           20 
                        --------------------------------
                        single set samples           464 from 601 to 1131 in the ball9.csd file.
      
      both parts: Wait a bit before adding the piano. It's terribly complicated and prone to untraceable errors.     
            8           Bosendorfer       11         494 # 11 different velocity levels
                                    -------
                                                     958 samples in total
                  
      The current design for samples is that it reserves some ftables for envelopes, and others for slides, and in between are the samples. 
            f3 - 4 for scales 
            298 - 261 for envelopes
            601 - 798 for samples - change this to end at 1499
            800+ for glissandi. I could move that perhaps. It's a variable in diamond_music_utils.py:
                  current_gliss_table = 1500 # raised on 4/28/23 to make more room for samples. Previously, samples occupied 601 - 798 increased it  to 1500
            Now I have enough room for all the samples I want to include. 

----------------------
4/29/23 To do today:

1.    Get the new ball9 working with the above orchestra. 
      a.    I could work on the samples.pas file and update all the references to ton, tone, t, etc to integer from binary, but I'm worried I'll mess something else up.
      b.    I could just use it as is, ignoring the note numbers which are all wrong.
      c.    I could change it to something like 12 TET, and use it to test.
            Current f3:
                  lf3 0 1200  -7 0 1200 0.1200 
            proposed f3:
                  lf3 0 12 -7 0 12 0.1200
            That worked to get through the note problem, but I still have a problem with the tempo. Something is setting:
                  t0 17
            No matter how I set the q value, it has not effect. I've tried everything I can think of, and the only thing that works is to edit the file to change the t0 17 to:
                  t0 600
            If I make that change in the ball9.mac file to:
                  lt0 600
            csound throws up about it, and every ftable in the file is called invalid. I saw this in the csound manual: N.B. If the CSound command includes a -t flag, the interpreted tempo of all score t statements will be overridden by the command-line tempo.
            Try that:
                  csound ball9.csd -t 600 -Oball9.log
            I've created a third parameter in csnow.sh
                  ./csnow.sh ball9 nop "-t 900"
            This sets the tempo to 900 regardles of the t0 values in the input file. Workaround for now.
      Got it working. I added some guitar strings at the end.
      moved it to the TonicNet directory, and had to make some changes to the paths to the sample files and music directory. Not enough ../..
            
2.    Why you can't connect to the jupyter kernel from code-server serve-local:
      When you provide the address of the jupyter server, leave off the trailing slash:
            http://localhost:8888 # <-- no trailing / 
      That was so frustrating. It expects to have a port at the end, not a slash.            

3.    I would really like to make it so the KEYS_FLATS and KEYS_SHARPS were automatically selected. Fixed it. 
      set flats = True or False in the header cell.

4.    I need to update all the pointers to voice_time = {
            "fp1": {"full_name": "finger piano 1", "start": 0, "csound_voice": 1, "time_tracker_number": 0},
            "...
            "bs2": {"full_name": "bassoon", "start": 0, "csound_voice": 9, "time_tracker_number": 31},
            "fr2": {"full_name": "french horn", "start": 0, "csound_voice": 10, "time_tracker_number": 32},  
                  }      
      Use these note names and numbers
      Arpeggios:
            4      fing 1
            2      vlip 2
            1      vlap 3
            1      celp 4
            1      mari 5
            1      xylp 6
            1      vibp 7
            1      harp 8
            1      bgui 20
            1      ebss 21
            1      long 22
            1      stri 23
      Long chords:
            2      vlim 9
            1      vlam 10
            1      celm 11
            1      basn 12
            1      clar 13
            1      flut 14
            1      oboe 15
            4      frnh 16
            2      vliv 17
            1      vlav 18
            1      celv 19
            Fixed it.

5.    It would be nice if all the instruments had a range, saved in the voice_time dictionary, for the pitches that are legitimate. 
      For example, the very low octaves like 2 & 3, should never be played by the marimba samples. Too many enharmonic overtones. Same for the xylophone and vibraphone. But also the pizzicato in the violin, and high notes on the cello. It would be nice to have guardrails that could take them up or down an octave to get them into the correct range automatically.

6.    You really need to make sure that you are not upsampling some of these samples. 
      I need a way to be certain that when I set upsample to 0, the equivalent MIDI note is being used for the sound generation, and not some other octave upsampled or downsampled.  Make sure all the samples get played. I print out iMIDInumber = 43.000, so I should also print out the sample name.
      Fixed it.

------------------------------
4/30/23 To do today:

1.    Set up the samples in ball9.csd so that it has fewer samples for the test runs. Is that possible? 
      Csound says it defers loading the sample file, but not what that accomplishes in terms of speeding up the processing of so many ftables. 

2.    Include max_oct and min_oct in voice_time dictionary. See #5 from yesterday.

3.    Make sure all the octaves are correct. I made the mistake of assuming that the strings were right, and they were not. 
      So I chanced the finger piano to match the strings, and messed up the finger piano. Had to undu that and redo the strings.
      The bass finger piano is much stronger on the low end. I'm thinking I need to add that in.
      Fixed it. I now have the right octaves for all 24 voices. 

4.    Once I am confident in the adaptive just intonation code, I'll run hundreds of synthetic chorales through it, and the have a corpus of before and after files to build a reinforcement learning exercise.

5.    Learn how the levers work:
      a.    I now have four levers I can use to influence the process:
            Where they are applied today:
                  ratio_factor = .2 # this reduces the cost of high integer ratio numerator and denominator
                  dist_factor = .2 # this reduces the cost of straying far from the initial 12 TET note
                  stop_when = 25 # scores below this are considered good enough, stop doing any additional rolls when the score is this good or lower. Normalize for ratio_factor.
                  cent_reach = 36 # limit the distance in cents from the starting point you are willing to go to find a ratio. Discards ratios more than this amount away from 12 TET.
                  top_notes # This is an array of (12TET note values, cent values). These are the notes (0-11) that the algorithm strives to keep on one particular cent value (0-1200). After all the interval ratios have been chosen, the program examines the generated chord. If a top_note is in a chord, and not located at the top_note cent value, the program will transpose the whole chord to meet that the top_note cent value. There should not be too many of these, because it could cause a conflict when the algorithm is presented with a chord that has two different top_notes, and they ask to be moved to a cent value that would cause other notes to move away from their preferred cent value, or in different directions. Our program gives up at that point and puts out an error message that is buried in the log.

            I should normalize the scores to ratio_factor in the final report. Also stop_when? Yes. Done.
            
      Main line order of calls:
            dist_factor = .2
            ratio_factor = 1
            stop_when = 25
            cent_reach = 36
            chorale_in_cents = midi_to_notes_octaves(chorale, top_notes, range = 12, ratio_factor = ratio_factor, dist_factor = dist_factor, stop_when = stop_when, cent_reach = cent_reach)            
           
            midi_to_notes_octaves(chorale, top_notes, range = 12, ratio_factor = .2, dist_factor = .2, stop_when = 36, cent_reach = 36): # these values are overridden by the calling function.
                  This calls improve_chord_permutations. It doesn't touch range, ratio_factor, dist_factor, stop_when, or cent_reach. 
                  chord_1200, score = improve_chord_permutations(previous_chord, top_notes, chord_number, range = range, ratio_factor = ratio_factor, dist_factor = dist_factor, stop_when = stop_when, cent_reach = cent_reach)

            improve_chord_permutations(initial_chord, top_notes, chord_number,  range = 12, roll = 4, dist_factor = .2, ratio_factor = .2, stop_when = 25, cent_reach = 36):
                  uses stop_when to end the rolls. Does not pass that through to downstream functions.
                  This calls: result = find_intervals(np.roll(best_choice,inx), range = range, dist_factor = dist_factor, ratio_factor = ratio_factor, cent_reach = cent_reach) 

            find_intervals(initial_chord, range = 12, dist_factor = 1, ratio_factor = 1, cent_reach = 36): # these values are overridden by the calling function
                  used ratio_factor, dist_factor, and cent_reach to control the adaptive just algorithms.
                  This calls: prev_score = score_chord_cents(initial_chord, ratio_factor = ratio_factor) to evaluate a potential change to a note in the chord that has already been selected.

6.    So what are you going to do with all those new voices:
      a.    make 2 minute sections with just two collections, an arpegiation section and a long chord section.
      b.    Switch from one to the next, to the next. 
            1.    8 Finger piano & 8 Woodwinds (flute, oboe, french hord, bassoon)
            2.    8 pizzicato strings & 8 strings with vibrato
            3.    8 mallet percussion & 8 guitar strings with slow to sound envelopes
            4.    8 martele strings & 8 strings with vibrato
            5.    4 of everyone all together.
      c.    Bring them all back for a grand finale.
            
7.    Maybe some other winds: @ 7 piccolo 26, 8 english horn 93, 9 bass clarinet 76, 10 Bach trumpet 39, 11 contra bassoon 84            

-------------------------------------
5/1/23 To do today:

1.    Fix the problems with adjusting levers.
      a.    music21_to_sample_root_mode - this function has been performing admirably for weeks. What changed? Near the 1200 cent level it reaches index 213, which is invalid. Fixed it.
      b.    index_to_limits = np.searchsorted(limit_31_values[:,1], distance + gap) # how can this get set to 213? If it's looking for something larger than 1.0
            if limit_31_values[index_to_limits, 1] == distance + gap: IndexError: index 213 is out of bounds for axis 0 with size 213
            limit_31_values contains the 213 valid ratios. Asking for the 213 is out of range. index_to_limits should not be set to 213, ever,
            index_to_limits = 213, distance + gap = 1199, limit_31_values.shape = (213, 3)
            The problem is that this distance + gap is nearly 1200, and so it's place in the array is at 213, but limit_31_values only goes to and index of 212
            Should I add another entry for 2/1?. Yes:
                  limit_31_ratios = np.append(limit_31_ratios, [2.0], axis=0) # notice the braces around 2.0. Otherwise I get a dimensionality collision.
            Fixed it.

2.    Move as much code as you can into utility library, so that old notebooks can take advantage of improvements in the functions moved into utilities.
            jupyter nbconvert TonicNet_Csound_adaptive_big_ensemble.ipynb --to python
                  [NbConvertApp] Converting notebook TonicNet_Csound_adaptive_big_ensemble.ipynb to python
                  [NbConvertApp] Writing 67168 bytes to TonicNet_Csound_adaptive_big_ensemble.py
      Some things I have to change in the notebook:
      1.    You must obtain tonal_diamond_values by calling atu.build_tonal_diamond(limit_value=31). 
            It returns tonal_diamond_values as an array. Done
      2.    all calls to score_chord_cents must also pass tonal_diamond_values
            score_chord_cents(chord_1200, tonal_diamond_values, ratio_factor = 1). Done
      3.    Calls to find_intervals must include tonal_diamond_values. Done
            find_intervals(initial_chord, tonal_diamond_values, range = 6, dist_factor = 1, ratio_factor = 1, cent_reach = 36)
      4.    Calls to midi_to_notes_octaves must include tonal_diamond_values because it calls improve_chord_rolls, and that needs tonal_diamond_values. Done.
      4.    The constant KEYS is no longer available. You have to call set_accidentals(True) to be returned an array of note names for flats, and set_accidentals(False) for an array of sharps. I created a new function called sett_accidentals, and where keys were needed, each function just calls that to get the accidentals. Done. But what if I want it to be sharps. I will have to change the utility function. Where is it needed?
            a.    def transpose_top_notes(final_result, top_notes, chord_number, flats = True):
            b.    def improve_chord_rolls(initial_chord, top_notes, chord_number, tonal_diamond_values, \
            range = 12, roll = 4, dist_factor = .2, ratio_factor = .2, stop_when = 25, cent_reach = 36, flats = True):
            c.    def midi_to_notes_octaves(chorale, top_notes, tonal_diamond_values, range = 12, ratio_factor = .2, dist_factor = .2, stop_when = 36, cent_reach = 36, flats = True):
            d.    def find_root_mode(midi_name) # this uses keys, but only to find the key of a MIDI file sequentially testing the strings.


      5.    I need to centralize the setting of flats = True or False in one location. It's in transpose_top_notes as a constant, which is wrong.
      6.    I should probably rename improve_chord_permutations to improve_chord_rolls, since it no longer does permutations, but it does do rolls. 


3.    Consider a way to start with cents instead of MIDI numbers. This could allow the focus to shift on different chord changes, like Tsantsa Circle Dance and Mirror Walk. 

4.    Passwords on all machines: RPI, HP800, Jetson, T15, ThinkCentre, update software while you are there. 
            sudo rpm-ostree upgrade
            sudo apt-get upgrade

5.    Found a bug in what I think is the octave setting operation. A midi_note is 0, yet the octave is not zero.
                  mismatch between the original MIDI notes chord_num = 4, midi_notes = array([ 0, 72, 63, 56]), chord_12_rounded =  array([72, 72, 63, 56])
                  chord_12_rounded[delta] = 72, midi_notes[delta] = 0, chord_1200 = array([  0,   0, 316, 814]), octaves = array([6, 6, 5, 4])
            print(f'{chorale[:,4] = }')
            print(f'{chorale_in_cents[:,4] = }')
                  chorale[:,4] = array([ 0, 72, 63, 56])
                  chorale_in_cents[:,4] = array([[  0,   6],[  0,   6], [316,   5], [814,   4]])
      The octave should have been set to 0 because the note was zero, but it was set to 6 instead. And this is just when I set the ratio_factor and dist_factor to .7. That's odd. The problem vanished when I changed from ratio_factor and dist_factor from .7 to 1 for both values. 
      I wonder if it had something to do with setting those levers to integer values (1) instead of (1.0). Let's see if that had an effect. No effect at all.
      Next I'm going to close down wsl and restart it. It improved a lot, but it's still not as good as real Linux. Amazing difference. 
      h1.7 Maximum score was: 97.0, ratio_factor = 0.7, dist_factor = 0.7, KEYS[top_notes[0]] = array(['E♭', 'C♮', 'G♮'] in cents: top_notes[1] = array([316,   0, 702]) 3:47 on WSL, 4.3 seconds on linux. 60:1 reduction in time to process, on a machine that is much faster than the T15.

-------------------------
5-2-23 To do today:

1.    Make a chorale with one long continuous slide. 
      Might have to re-write it to work from cents instead of ratios. It would also be nice if you could pass in an array of durations for each step and slide in the set.

2.    Write up a substack of three different hn lever sets, showing the range of different adaptive just the algorithm is capable of. 

3.    Redo the Dave Keenan chord progression to include potential anchor notes. Take note that the graphic on the substack does not include all the chords. Is there a bug in the report logic?

4.    Transpose doesn't handle a C at 1198 cents properly. 
      It was caused by 1198 rounding to 12, which is not a valid 12 TET note.
            note_12 = int(round(note / 100, 0)) % 12 # this fixed part of the problem, but not all.
      This one still slipped through: note#: 192 ['E♭', 'F♮', 'C♮', 'A♮'] [ 300  496 1198  882] 
            (0, 1, 196, '28/25') (0, 2, 898, '42/25') (0, 3, 582, '7/5') (1, 2, 702, '3/2') (1, 3, 386, '5/4') (2, 3, 316, '6/5')  157.0
      And it was the high score: 157
      Why didn't it transpose? Because the expected_value should be set to 1200 when the incomming cent value is 1100 or more.
      Fixed it. Had a problem but it was caused by thinking A was 8, when it's really a 9.

5.    I was kind of thinking out loud on substack: 
      I was referring to the Kennan comma pump. It "originally moved the D♮ from 200 to 204 cents, which I could not detect audibly. I could have anchored the D♮ at 202 cents, but then the algorithm would not know how to handle the request to move the A♮ to 902 and the D♮ to 202 at the same time. At present, it only knows how to transpose the whole chord in the same direction and amount. I suppose it could transpose each note a different amount, but that would require compromising the integrity of the ratios. I suppose if it’s only a slight movement, I could allow it."

      "Perhaps I could code up an offer to split the difference. I’d prefer to just hand code a slide for the D♮ up 4 cents, but that would take a good deal more coding."

      "It’s clear that adaptive just intonation is a basket of troubles, with edge cases after edge cases to befuddle the coder."
      Today what I do is detect that one of the top_notes is at the right spot, I bail out and don't move anything. I suppose I could keep looking and move one of the notes and not the other. It wold have to have a cap on the distance I would move, like 4 cents or so. I could make that a lever to adjust. My concern is that it would open the "basket of troubles". "Give a mouse a cookie" kind of thing. No end in sight.

6.    I did a rendition of  as slow17.mac in February 20, 2010 posted to an old blog. It's saved on the godaddy site as slow20.mp3 http://ripnread.com/listen/slow20-c9-t.mp3 There it is in 72 EDO. O Sacred Head Now Wounded. So I went down this road before. Noone cared.

--------------------------------
5/3/23 To do today:      

1.    Post the results of your analysis on the bwv244.17 chorale on substack. This only applies to this chorale. 
      The purpose is to show that the algorithm can provide different results depending on the strategy you want to employ, such as closer to 12 TET but higher ratios, or lower ratios if you allow it to stray fro the original 12 TET. But not too far in either direction. Make it clear that I'm still at the start of this journey, and some strange results are to be expected.
      Key results: 
      
      h1 Maximum score was: 140.0, ratio_factor = 1, dist_factor = 0.2, keys[top_notes[0]] = array(['E♭', 'C♮'] in cents: keys[top_notes % 12][1] = array(['E♮', 'C♮'], dtype='<U2') - strategy: decrease penalty for distance from 12 TET, no change to high integer ratios. version = "1"

      # h2  Maximum score was: 157.0, ratio_factor = 0.1, dist_factor = 1.0, keys[top_notes[0]] = array(['E♭', 'C♮'] in cents: keys[top_notes % 12][1] = array(['E♮', 'C♮']this one sounds better than h1 - strategy go farther from 12 TET and reduce penalty from higher ratio integers.

      # h1.6 Maximum score was: 97.0, ratio_factor = 1.0, dist_factor = 0.6, keys[top_notes[0]] = array(['D♮', 'G♮', 'A♮'] in cents: top_notes[1] = array([204, 702, 902]) - I really don't like the beginning of measure 12 at 192. ['E♭', 'F♮', 'C♮', 'A♮'] [334 516  18 902] (0, 1, 182, '10/9') (0, 2, 316, '6/5') (0, 3, 568, '25/18') Eb is too high, F is off. A is perfect.

      # h1.8 Maximum score was: 107.0, ratio_factor = 1.0, dist_factor = 1.0, keys[top_notes[0]] = array(['E♭', 'C♮'] in cents: keys[top_notes % 12][1] = array(['E♮', 'C♮'], dtype='<U2')  - Strategy: show that keeping distance and ratio in balance gets the best result

      # h1.5 Maximum score was: 97.0, ratio_factor = 0.5, dist_factor = 0.5, keys[top_notes[0]] = array(['E♭', 'C♮'] in cents: keys[top_notes % 12][1] = array(['E♮', 'C♮'], dtype='<U2')  - Strategy: show that keeping distance and ratio in balance gets the best result. I liked the notes at chord 192: ['E♭', 'F♮', 'C♮', 'A♮'] [316 498   0 884] (0, 1, 182, '10/9') (0, 2, 316, '6/5') (0, 3, 568, '25/18') A is low, but it sounds better. Once I made the change to accept the lesser transposition, it sounds and bad as h1.6. 

      # h3 dist_factor = 4  ratio_factor = .1 stop_when = 25 cent_reach = 36 1:49 Maximum score was: 10162.0, ratio_factor = 0.1, dist_factor = 4 keys[top_notes[0]] = array(['C♮', 'E♭', 'G♮'] in cents: top_notes[1] = array([  0, 316, 702])- This one is very close to 12 TET, because I made it pay a significant penalty for being far from the original note.

      # h4 dist_factor = 7  ratio_factor = .1 stop_when = 25 cent_reach = 10 2:42 Maximum score was: 10162.0, ratio_factor = 0.1, dist_factor = 7, keys[top_notes[0]] = array(['C♮', 'E♭', 'G♮'] in cents: top_notes[1] = array([  0, 316, 702]) Also very close to 12TET, and ugly as sin.
      
2.    What should I do if the transposing function has two different notes that should be transposed? Here's and example:
      transposing failed. gaps = array([ 0, 16,  0, 34]) not all equal. 34 16 What do I do boss?
      205, improve_chord_rolls after adjustment. final_result = array([ 300,  686, 1184,  868])      
      I could have transposed the G from 686 to 702 by adding 16 and that would have improved the chord, or transposed the A from 868 to 902 and that would have fixed the A, but ruined the G. I did neither. Perhaps I could split the difference, or just make one of them right?
      For now, I'll go with making the one that requires less movement right. Made a choice:
            found a top_note at inx = 3. cent value note = 868 which is a A♮ that is not at the cent value we expect
            note = 868 at position 3 A♮ should have cent value of: 902
            gaps are found: gaps_found = array([1, 3]), gaps[gaps_found] = array([16, 34])
            transposing failed. gaps = array([ 0, 16,  0, 34]) not all equal. 34 16
            transposed by smallest_gap = 16      

3.    Before you go all triumphalist on Substack, try some other chorales and see what else surfaces to cause pain:
      Try one of these, also from St. Matthew Passion
            bwv244.10.mxl
            bwv244.15.mxl
            bwv244.17.mxl
            bwv244.25.mxl
            bwv244.29-a.mxl
            bwv244.3.mxl
            bwv244.32.mxl
            bwv244.37.mxl
            bwv244.40.mxl
            bwv244.44.mxl
            bwv244.46.mxl
            bwv244.54.mxl
            bwv244.62.mxl
      Trying 244.25. It has one chord that has no chance: [73, 62, 59, 46]), ['C♯' 'D♮' 'B♮' 'A♯'] chord_in_1200 = array([ 100,  200, 1100, 1000]) This is a cluster. I might pick: 15/16, 9/8 15/16. The algorithm's first choice was  [ 100,  199, 1118,  984])
      0,1: 99: 18/17
      0,2: 1018: 9/5
      0,3: 884: 5/3 
      100  199 1118 984
      1,2: 18/17 to 9/5 1118 - 199 = 919 closest is 884 5/3 35 cents away
      1,3: 18/17 to 11/7 984 - 199 = 785 closest is 782 11/7 3 cents away
      Would it help any to increase the cent_reach beyond 36? I doubt it. But it would help to reduce the dist_factor from 1.0 to 0.7.
      170   ['C♯', 'D♮', 'B♮', 'A♯'] [  82  181 1100  966] (0, 1, 99, '18/17') (0, 2, 1018, '9/5') (0, 3, 884, '5/3') (1, 2, 919, '17/10') (1, 3, 785, '63/40') (2, 3, 134, '27/25')  1185.0
      That's "better". Reduced the penalty for going farther away from the 12 TET.
      version = '244.25'. Maximum score was: 1185.0, ratio_factor = 1.0, dist_factor = 0.7, keys[top_notes[0]] = array(['B♮', 'D♮', 'F♯'] in cents: top_notes[1] = array([1100,  216,  602])
      bwv244.40 has trouble here:
      144   ['C♯', 'B♮', 'G♮', 'E♮'] [  86 1082  668  379] (0, 1, 996, '16/9') (0, 2, 582, '7/5') (0, 3, 293, '45/38') (1, 2, 414, '47/37') (1, 3, 703, '3/2') (2, 3, 289, '13/11')  1150.0
      keys[top_notes[0]] = array(['E♮', 'A♮', 'C♯']. Tried eliminating A, and it's still having transposition clashes. 
      144   ['C♯', 'B♮', 'G♮', 'E♮'] [  86 1082  668  379] (0, 1, 996, '16/9') (0, 2, 582, '7/5') (0, 3, 293, '45/38') (1, 2, 414, '47/37') (1, 3, 703, '3/2') (2, 3, 289, '13/11')  1150 Same trouble as before. E minor 7th shouldn't be this hard. 
      144   ['C♯', 'B♮', 'G♮', 'E♮'] [ 102 1098  684  395] (0, 1, 996, '16/9') (0, 2, 582, '7/5') (0, 3, 293, '45/38') (1, 2, 414, '47/37') (1, 3, 703, '3/2') (2, 3, 289, '13/11')  1150.0 Anchored F# and C#, and still 1150 score, same ratios, just transposed differently, I wonder if this is an error in the midi file in the corpus. I see on the written score measure 9, which is where I think 144 falls (144 / 16 = 9) is G B E E, with no C#. What gives? I look at the midi file, and that measure doesn't have a C#. Tomorrow try reading it in from the midi file and track chord 144 through the whole process. chord_number = 144, chord = array([73, 71, 67, 52]), ['C♯' 'B♮' 'G♮' 'E♮']

4.    The flute is too soft. Can't hear the soprano parts. Couldn't fix is properly.
      I'll need a more comprehensive solution here.    

-----------------------------------------------------
5/4/23 to do today:

1.    Fix the 144 chord in bwv244.40. What do we know: Correct is [71, 67, 64, 64]  [11, 7,  4, 4,] ['B♮' 'G♮' 'E♮' 'E♮']
            wrong is                                             ([73, 71, 67, 52]), [1, 11, 7, 4], ['C♯' 'B♮' 'G♮' 'E♮']
            The question is when and how does the 71 11 'B♮' become 73 1 'C♯'
      a.    The Music21 corpus is correct when I s.show() it.
      b.    When I s.write("midi", "bvw244.40.mid") and open it with Musescore, it's also correct.
      c.    At the end of the notebook: chorale[:,144]% 12 = array([ 1, 11,  7,  4]) array([73, 71, 67, 52])
            It shows C♯ as the high note, when it should be B♮. Where does it go wrong? I suspect something between reading the Music21 corpus and loading it into chorale, something goes wrong. It's and interesting failure, because I only caught it because that note had such a high score, which persisted even after I made alterations in the hyperparameters. I wonder if there are other hidden wrong notes elsewhere that didn't trigger such a clearly wrong note. In other words, if you find the problem, you should probably go back and do all the previous pieces. Only 5 at this point. While you do, either save the chorale_in_cents in a numpy array named for the corpus name (e.g.  bwv244.40), or at least the levers that did the best. I favor the first one.
                  numpy.save(version, chorale_in_cents)
            Pretty simple, don't you think? The time saved is not in running the algorithm, it's figuring out the anchor notes and the levers. The anchor notes discovery process is very time consuming.

      d.    What are the transformations the midi file goes through:
            0.    When it comes out of the mainline: chorale[:,144:148].T is:
                        [[73 71 67 52]
                        [73 71 67 52]
                        [73 71 67 52]
                        [73 71 67 52]]
                  So before it calls atu.midi_to_notes_octaves(chorale,...  it's damaged goods.
            1.    A utility function does the actual read: music21_to_sample_root_mode this includes a transformation to piano_roll
                        piano_roll = muspy.to_pianoroll_representation(music, encode_velocity=False) # this could make a mistake
                              music.resolution is q: 24. q16: 6 time_steps: 257 1/16th notes. piano_roll.shape = (1537, 128)
                              time_steps: 257 1/16th notes. piano_roll.shape = (1537, 128) # piano roll is one-hot encoded
                  Some of my code takes the piano roll and converts it into a sample structure. Could be buggy.
                  Check notes 142 through 146. Here is #144: 73, 71, 67, 52
                        time_interval = 144, voice = 3, inx = 52
                        time_interval = 144, voice = 2, inx = 67
                        time_interval = 144, voice = 1, inx = 71
                        time_interval = 144, voice = 0, inx = 73
                  145, 146, 148 are identical.
                  So it's wrong when it hits muspy_to_sample_root_mode
                  The odds that my code is only buggy on this one chord are pretty low. But also low on every other location where the bug could be living.
                  So it looks like it's damaged when it hits muspy_to_sample_root_mode. No. I inspected the muspy_object structure and it has the correct notes. Here is measure 9, which I determined by counting the 24 beats per quarter note.
                        9 soprano
                        Note(time=768, pitch=71, duration=24, velocity=64), 
                        Note(time=792, pitch=73, duration=24, velocity=64), 
                        Note(time=816, pitch=74, duration=12, velocity=64), 
                        Note(time=828, pitch=73, duration=12, velocity=64), 
                        Note(time=840, pitch=74, duration=12, velocity=64), 
                        Note(time=852, pitch=76, duration=12, velocity=64), 
                  I wonder if I can fix all this by just setting q to 24. Maybe. What if I don't skip any? send all the notes to the next step. chorale.shape = (4, 385). That's a strange number. 

            2.    Another utility function reads from corpus:
                  s = m21.corpus.parse(work) # use music21 to pull a chorale from the corpus. For example Herzliebster is 'bwv244.3'
                  Is it damaged here? Could it be a problem of resolution, causing the note at 144 to read from the next note in the soprano and alto part? Can't set the resolution to any other value. 
                  muspy can read from a midi file. Should I try that? No. 
                  sample, root, mode, pit_cl_ent, pcu = music21_to_sample_root_mode(muspy.from_music21(s))
                        sample.shape = (257, 4), root = 6, root = 6, mode = 'minor', round(pit_cl_ent,2) = 2.92, pcu = 10
                  chorale = sample.T
            3.    Read the corpus into chorale  
                  chorale, root, mode, s = atu.read_from_corpus(version) 
            4.    Once we have the chorale, we convert it to just tuned cents using midi_to_notes_octaves
                  chorale_in_cents = atu.midi_to_notes_octaves(chorale, top_notes, tonal_diamond_31, range = range, ratio_factor = 
                  ratio_factor, dist_factor = dist_factor, stop_when = stop_when, cent_reach = cent_reach, flats = flats) 

2.    So after several hours of work, I changed the function to read every time_step in the piano roll.
      216   ['C♯', 'B♮', 'G♮', 'E♮'] [ 102 1098  684  395] (0, 1, 996, '16/9') (0, 2, 582, '7/5') (0, 3, 293, '45/38') (1, 2, 414, '47/37') (1, 3, 703, '3/2') (2, 3, 289, '13/11')  1150.0
      There's that 1150 score again, with a C#, except it's chord number 216. Go figure. It might just be a different set of repeats.
      Anyway, the notes are the same wrong notes. ['C♯', 'B♮', 'G♮', 'E♮'] vs ['C♯' 'B♮' 'G♮' 'E♮']. Identical. 
      As a reminder, here's how I started the day:
      Fix the 144 chord in bwv244.40. What do we know: Correct is [71, 67, 64, 64]  [11, 7,  4, 4,] ['B♮' 'G♮' 'E♮' 'E♮']
            wrong is                                             ([73, 71, 67, 52]), [1, 11, 7, 4], ['C♯' 'B♮' 'G♮' 'E♮']
            The question is when and how does the 71, 11 'B♮', 'G♮', become 73, 1 'C♯', 'B♮'
      in the loop chord 216:  73, 71, 67, 52 ['C♯', 'B♮', 'G♮', 'E♮']
      It's still a mystery.

---------------------------------
5/5/23 To do today:

1.    Fix the 1150 score problem. 
      Am I certain I'm looking at a problem as described above, or it is just a case of an actual MIDI chord that matches the one described, and I'm looking at the wrong midi chord. Is there a mismatch? If there is, the report would show it, and it doesn't. That should be definitive, in my opinion. Look for the chord 864 ['C♯', 'B♮', 'G♮', 'E♮'] in the MIDI file.
            chorale[:,864] = array([73, 71, 67, 52])
            chorale[:,864] % 12 = array([ 1, 11,  7,  4])
      There it is starting measure 10. It's not a bug in the code. And I no longer need to preserve all 1537 time_steps, can revert to 257. That moves the troublesome chord back to cord_number 144.

2.    Speaking of buggy code, clean up the crap-a-hole muspy_to_sample_root_mode function. 
      It converts the one-hot encoded piano roll to chorale. Should be one line of numpy code. It turns out that decoding one-hot encoded arrays is very uncommon. 
            decoded_piano_roll = np.argmax(piano_roll, axis = 1) # returns decoded_piano_roll.shape = (1537,) which is the midi note for each time step. If I only grab every 6th note, that's 256 notes, but I need 256 times 4 voices or 1024 notes. 
            sample.shape = (256, 4) How is that possible when I'm only taking 1/6th of the notes. 
      Need to slow it all back down now. I decided to just leave it as is. I was too confused by the numbers 1537 time steps, 257 chords, and 4 voices. The numbers just don't add up.

3.    So I rearranged the troublesome chord and got the score down to 61 with these 6 permutations. Is this fair?
      Is it equivalent to the way the ear perceives the intervals of chord?
            161. start here initial_chord = array([67, 52, 71, 73]), ['G♮' 'E♮' 'B♮' 'C♯']
            final_result = array([ 685,  369, 1071,  102]), round(score,1) = 61.0      
      More importantly, should I check every score, and if it's over a certain amount, like 500, I should invoke the permutations in a function? I will also need to be able to rearrange them.

      logging.info(f'before rearranging. {chord_in_1200 = }, {best_choice = }')
      best_voicing = np.argmin(np.array([sum(np.array(abs(chord_in_1200 -  voicing))) for voicing in np.array(list(permutations(best_choice)))]))
      final_result = np.array(list(permutations(best_choice)))[best_voicing]
      logging.info(f'after rearranging. {round(best_score,1) = }, {final_result = }')
      Results of calling try_permutations:
            (keys[new_chorale.reshape(4,) % 12]) = array(['C♯', 'B♮', 'G♮', 'E♮'], dtype='<U2')
            new_chord = array([ 118, 1087,  700,  385]), score = 61.0
            keys[[int(round(note / 100)) for note in  new_chord]] = array(['C♯', 'B♮', 'G♮', 'E♮'], dtype='<U2')
      It works when called from the main line. Will it work when called from improve_chord_rolls. Apparently not:

            (keys[new_chorale.reshape(4,) % 12]) = array(['C♯', 'B♮', 'G♮', 'E♮'], dtype='<U2')
            new_chord = array([102, 916, 685, 418]), score = 71.0
            keys[[int(round(note / 100)) for note in new_chord]] = array(['C♯', 'A♮', 'G♮', 'E♮'], dtype='<U2')
      It changed the midi note, and ignored the 70.

4.    I modified score_chord_cents to return round(score / ratio_factor,1). 
      That means anywhere I've been doing that bit of arithmetic needs to be changed. 

5.    Now the highest score is 210   ['D♮', 'G♯', 'E♮', 'F♯'] [214 796 410 600] (0, 1, 582, '7/5') (0, 2, 196, '28/25') (0, 3, 386, '5/4') (1, 2, 386, '5/4') (1, 3, 196, '28/25') (2, 3, 190, '29/26')  191.0
      Should I send that through the permutation? 
      I lowered the max_score for using permutation to 100: Now every chord that has that high a score gets sent through the permutation. I wonder if I should just give up on roll and keep them all going through permutation. Later.
            def improve_chord_rolls(initial_chord, top_notes, chord_number, tonal_diamond_values, \
                  range = 12, roll = 4, dist_factor = .2, ratio_factor = .2, stop_when = 25, \
                  cent_reach = 36, flats = True, 100):
------------------------------
5/6/23 To do today:

1.    Simplify the process of finding top_notes. Finish the rest of the bwv244 chorales.

2.    Cache the results for each chord. 
      Bach reuses chords a lot, and I could probably save 75% of the cpu time if I took advantage of that. Is there a library for cache? No but numpy provides a way to insert into a sorted list, and searchsorted to find it later using binary search. There you go. Where should I put it?
      def midi_to_notes_octaves(chorale, top_notes, tonal_diamond_values, range = 12, ratio_factor = .2, dist_factor = .2, stop_when = 36, cent_reach = 36, flats = True):
            This works on the chorale, and calls 
                  chord_1200, score = improve_chord_rolls(chord, top_notes, chord_number - 1, tonal_diamond_values, range = range, dist_factor = dist_factor, ratio_factor = ratio_factor, stop_when = stop_when, cent_reach = cent_reach)
            Just before making that call, it checks to see if the previous chord is the same as this chord, and that's a good place to see if it's been stored from earlier in the piece. You can keep the cache local to this function from cradle to grave. 
            # check the cache to see if you have already found the chord_1200 and score for this chord.
            # data structure:
                  midi_chord # chorale.shape = (4, 256)
                  chord_1200 # array([590, 204, 906, 204])
                  score # int
            chord_cache = np.zeros((chorale.shape[1],4,4,1), dtype = int)

-----------------------------
5/7/23 To do today:

1.    Pick up where you left off with the cache. 
      a.    Don't create a zero array, create an empty one.
      b.    Don't index by the midi chord array, index by a hash of the midi chord array.
      c.    Don't worry about the hash algorithm speed, just accuracy.

2.    Fix the problems:
            chord_cache.shape = (3, 2). contents of chord_cache: 
            ...
            [61 61 61 61], [541 844 518  30]
            new chord unhashed: [61 61 61 61], [1021 1053 1050  793] # this is not a new chord. You can see it just above as [61 61 61 61], [541 844 518  30]. Why is it not flagged as a duplicate? Is it they way I use searchsorted? Or the hash?
            location_to_insert = 1
            proposing to insert at: location_to_insert = 1 # and yet he wants to insert it anyway. 
            chord_cache.shape = (4, 2). contents of chord_cache: 
            [61 61 61 61], [1021 1053 1050  793] # now the new one is inserted even though it's a duplicate.
            ...
            [61 61 61 61], [541 844 518  30] # now the original is there
      I converted the compare to np.array_equal, and it still failed to detect a duplicate: I think it was because the ones I was comparing were not the right compares to make.
      It would tell me to insert it in a place that was not next to where the previous one was located. It's like I get different results of the conversion to hash each time.
            chord_cache.shape = (9, 2). contents of chord_cache: 
            ...
            [60 61 61 60], [ 877   65  742 1018]
            ...
            new chord unhashed: [60 61 61 60], [646 648 717 698]
            location_to_insert = 1
            proposing to insert at: location_to_insert = 1
            chord_cache.shape = (10, 2). contents of chord_cache: 
            ...
            [60 61 61 60], [646 648 717 698]
            ...
            [60 61 61 60], [ 877   65  742 1018]

3.    I'm thinking i just need a loop of checks on a sorted list of chords of midi notes. There can't be more than 50 distict chords to search. 
            
-----------------------------------
5/8/23 To do today:

1.    Get control over your logging. Use warn, info, other levels. Advice here: https://towardsdatascience.com/building-and-exporting-python-logs-in-jupyter-notebooks-87b6d7a86c4
      Changed all the logging.info to logging.debug, then selectively changed some to logging.info. The log file is now tiny. 
            
2.    St John Passion has some nice chorales. 245.14 converts to lots of 7 ratios
      ⬢[prent@toolbox TonicNet]$ grep "/7" bwv245.14.txt -c
            8
      ⬢[prent@toolbox TonicNet]$ grep "7/" bwv245.14.txt -c
            13
      Had to go to 
      grep "try_permutations" ball9.log -c
            11 times out of 68 total chords needed permutations to get the score down 
      982.0 - INFO - total_improve_chord_rolls = 68, cache_hit = 13      

3.    To be consistent, score should include a sum of the absolute value of cent distance from the midi note cent value for all four notes.                  

-------------------------------
5/9/23 To do today:

1.    Track the changes made to one challenging chord as it goes through all the hoops before settling on a set of 4 cent values. 
      You will need to set logging to debug, and make some changes to the code that does logging so we can effectively track the changes.
      Consider this one in 245.14:
      170   ['D♯', 'A♮', 'F♯', 'G♮'] [316 898 583 702] (0, 1, 582, '7/5') (0, 2, 267, '7/6') (0, 3, 386, '5/4') (1, 2, 315, '6/5') (1, 3, 196, '28/25') (2, 3, 119, '15/14')  127.0
      That one certainly blows a hole in using a 9 limit diamond. Or maybe it could have prevented this one from being out minimum. 
      When I turned on the DEBUG logging flag, it generated 8,237 lines of log records in 47 seconds. I think it has something to do with writing to the Windows file system from linux. I bet I could shave some time off if I didn't have it under the control of Windows and Dropbox.
      Some interesting results: Optimizer had 168 for one chord. Score was displayed 524 times. Scored 328 times. 
      My goal is to capture all the interim cent values and related scores.
----------------------------
5/11/23 To do today:

1.    Consider a smaller tonality_diamond_values, like a 5 or 7 limit diamond, need at least 9
      The build_all_ratios can handle all sizes of limits. I spent a few minutes looking at different diamond shapes and discovered that the size of the diamond of a certain limit can be converted into square by taking one dimension as the square root of the size of the diamond. A 15 limit diamond has a length of 64. Square root of 64 is 8. So a 15 limit diamond is 8 by 8. I also discovered how to find the number of unique elements in a tonality diamond, but I had to do it brute force, asking numpy to provide the unique elements, then taking the shape of the resulting pruned array.
            limit_for_diamond = 9
            small_diamond = np.array(dmu.build_all_ratios(limit_for_diamond))
            limit_dims = np.sqrt(small_diamond.shape[0]).astype(int)
            print(f'{limit_dims = }')
            print(f'{small_diamond.shape = }')
            diamond_array = np.array([str(Fraction(ratio).limit_denominator(105)) for ratio in small_diamond]).reshape(-1,limit_dims)
            print(*diamond_array, sep = '\n')
            unique_ratios = np.unique(small_diamond)
            print(f'{unique_ratios.shape = }')
                  limit_dims = 5
                  small_diamond.shape = (25,)
                  ['1' '6/5' '7/5' '8/5' '9/5']
                  ['5/3' '1' '7/6' '4/3' '3/2']
                  ['10/7' '12/7' '1' '8/7' '9/7']
                  ['5/4' '3/2' '7/4' '1' '9/8']
                  ['10/9' '4/3' '14/9' '16/9' '1']
                  unique_ratios.shape = (19,)
            This might be sufficient. Not for chord # 170 above.

----------------------------------------
5/12/23 To do today:

1.    Finish up the tracking of all the changes to the chord over time. 
      I think I might benefit from keeping the changes in an array, instead of trying to log them. Sounds like a useless rat-hole.
      I could avoid checking arrangements in try_permutations that were already checked in rolls. What number are they in the permutation? 
            # What is the overlap between rolls and permutations? 
            # answer: roll 0 is permutations 0, roll 1 is permutations 18, roll 2 is permutations 16, roll 3 is permutations 9
            # so it is not necessary to check permutations 0, 9, 16, or 18

            for inx, _ in zip(count(0,1), chord_1200):
            print(f'{inx = }, {np.roll(chord_1200, inx) = }')

            for inx, initial_chord in zip(count(0,1),np.array(list(permutations(chord_1200.reshape(4,))))):
            if inx in np.array([0, 9, 16, 18]):
                  print(f'{inx = }, {initial_chord = }')
            
            if inx in np.array([0, 18, 16, 9]): # skip the ones that were already checked in improve_chord_rolls
                 logging.debug(f'skipping {inx = }, already checked')
      That was able to eliminate the ones checked in improve_chord_rolls. 
      
2.    Danger rat-hole alert: What other ones could be eliminated. Each one takes 15 ms or so. I found no other pattern that I could trust. Just make sure you limit the calls to try_permutations to those that are necessary.
      Notice that 1,2,3,4 all have the same score. Is that significant? No. Just coincidence. Does not repeat consistently.

            973.0 - DEBUG - permutation: 1. start here initial_chord = array([1100,  400,  600, 1000]), midi numbers: [11, 4, 6, 10]
            994.0 - DEBUG - permutations results_so_far: result = array([1100,  398,  602, 1001]), score = 154.0
            994.0 - DEBUG - permutation: 2. start here initial_chord = array([1100, 1000,  400,  600]), midi numbers: [11, 10, 4, 6]
            16.0 - DEBUG - permutations results_so_far: result = array([1100, 1001,  398,  602]), score = 154.0
            16.0 - DEBUG - permutation: 3. start here initial_chord = array([1100, 1000,  600,  400]), midi numbers: [11, 10, 6, 4]
            33.0 - DEBUG - permutations results_so_far: result = array([1100, 1001,  602,  398]), score = 154.0
            33.0 - DEBUG - permutation: 4. start here initial_chord = array([1100,  600,  400, 1000]), midi numbers: [11, 6, 4, 10]
            49.0 - DEBUG - permutations results_so_far: result = array([1100,  602,  398, 1001]), score = 154.0
            50.0 - DEBUG - permutation: 5. start here initial_chord = array([1100,  600, 1000,  400]), midi numbers: [11, 6, 10, 4]
            66.0 - DEBUG - permutations results_so_far: result = array([1100,  602, 1001,  398]), score = 154.0

            6,7,8,10,11: 1079.0
            12, 13 154

            Don't draw any conclusions until you understand if there is a pattern. Try another challenging chord. There are no consistent patterns.
            1,2,3,4,5 all the same 147
            6,7,8 all the same 127 best score
            10,11 same 1033
            12 191
            13 1175
            14 191
            15 139 
            17 1175
            19 1192
            20,21 1093
            22 1205 
            23 1140

            130 scores 106
            1,2,3,4,5,6,7,8,10,11 144
            12, 13 134 
            14, 15 106 best score 
            703.0 - DEBUG - permutation: 14. start here initial_chord = array([ 900,  600, 1100,  800]), midi numbers: [9, 6, 11, 8]
            736.0 - DEBUG - permutations results_so_far: result = array([ 900,  584, 1082,  815]), score = 106.0
            737.0 - DEBUG - permutation: 15. start here initial_chord = array([ 900,  600,  800, 1100]), midi numbers: [9, 6, 8, 11]
            773.0 - DEBUG - permutations results_so_far: result = array([ 900,  584,  815, 1082]), score = 106.0
            17 180
            19 106 
            20 134
            22 180
            23 180

            80 scores 107.0
            1     126
            2,3   133
            4,5   126
            6,7   175
            8     107 best score
            10    175
            11    107 another best score
            12,13 133
            There is no pattern here.
      I think the best course is to keep using several different methods at increasing coverage to find the best chord. Now that the time to find a good set of notes is a few seconds, optimization is not required. Now see if you could get better results in terms of the average score, not just the maximum, with all them going to permutation. 
      I set a new parameter that would send to try_permutation unless the score was 0. This effectively forced every chord to go to try_permutations. The average score dropped from 65 to 64.9. Not a big change. 3.3 seconds with every chord going through try_permutations. 1.8 seconds when scores lower than 100 were not sent through try_permutations. There was one chord that went from 71 to 61, with more 7 ratios. Another was transposed. Not significant.

2.    Consider the analogy to AI applied to chess playing. There were three key technniques that combined to create world class chess AI.
      1.    Evaluation of position - sounds like a score
      2.    What's a sensible move to consider
      3.    Monte Carlo rollout of all future moves and potential responses.
      He says it does reasonably well with just the first two, as long as you train it with experts in evalation and move considerations.
      He thinks that's where we are with ChatGPT, and the next step could be even more dramatic. Internal reasoning to ensure consistency between the things they "believe". Next step is thought experiments. 

            Geoffrey Hinton podcast at MIT Media lab this week went through this. Is there an analogy for my adaptive tuning? 
            Transcript here: https://steno.ai/in-machines-we-trust/live-a-conversation-with-geoffrey-hinton
            I think they'll be able to reason. So let me give you an analogy. If you take Alpha Zero, which plays chess, it has three ingredients. It's got something that evaluates the board position to say, is that good for me. It's got something that looks at the board position and says, what's the sensible move to consider? And then it's got Monte Carlo rollout where it does what's called calculation, where you think if I go here and he goes there and I go here and he goes there. Now, suppose you leave out the Monte Carlo rollout and you just train it from human experts to have a good evaluation function and a good way to choose moves to consider. It still plays a pretty good game of chess, and I think that's what we've got with the chatbots. And we haven't got them doing internal reasoning, but that will come and once they start doing internal reasoning to check for the consistency between the different things they believe, then they'll get much smarter and they will be able to do thought experiments.

3.    Copilot is very cool for jupyter inside vscode. Great autocomplete support. Especially in the comments. It will complete a series, sometimes wrong, but often right.

4.    Danger rat-hole alert: Scores should include the sum of the absolute value of the distance from 12TET from the cents. Are you sure? That's not exactly how intervals are chosen. Let's get into the weeds of the find_intervals function.
            best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2]) # shouldn't the second half of that sum get multiplied by ratio_factor?
      It looks for an interval that is as close as possible to the input chord interval cent distance. Typically, there's a ratio that is close to the input interval cent value, perhaps off by as much as 20 cents. This distance can be moderated by multiplying it times a distance_factor (typically 1.0). That product is then added to the the max of the numerator and denominator of the ratio, (typically less than 17, as found in the ratio 10/7 or 9/8, sometimes as low as 1, or as high as 25/18 = 43). So if the input chord is something like 1100 600 200 1100, which is the midi_number % 12 * 100, we are searching for a ratio that is close to that, without having too high integer ratios. It will tend to pick low 9 limit ratios, rather than some 15 or 31 limit ratio. 

      The program's job at this point is to pick an interval that is close to the desired cent distance of the input chord. Which can start out as the midi_number % 12 * 100, which is in effect 12 TET. So it has everything to do with the distance from 12TET. But after some changes to the cent value of notes, during the iterations through find_intervals, the input cent values of intervals can drift away from 12TET. The task is to match that distance as closely as possible, with as low a ratio integers as possible. But the ratio_factor doesn't come into play until it starts evaluating conflicts between a value chosen previously. Then it scores using score_chord_cents, which includes ratio_factor in the decision. Should it also include ratio_factor in the argmin? I'm thinking it should, so I changed it to:
            best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2] * ratio_factor)

            atu.score_chord_cents(chord_1200, tonal_diamond_31, ratio_factor = ratio_factor) # shouldn't the score include the distance from 12TET? That depends. If you want it to, then you will need to get passed the octave array, because that is needed to get back to the original MIDI number. Do I need that? Maybe not. The score doesn't need the octave. I just spent all that time including octaves in the function calls. It's irrelevant. Or is it? The more important question is do I care how far from 12TET the model strays? I say we don't. Move on.

---------------------------------
5/13/23 To do today:

1.    Take another look at how notes change over time. Could the movement from one chord to another be optimized just by transpositions? 
      Will I have to trade off on optimaly tuning a chord to tuning movement from one chord to another? Could I do this after generating the chords? 
      Are there some notes that move for no good reason that I could fix by transposing the chord? I think there might be.
      Consider a report that showed all the 12TET notes, and all the cent values and how many times it had that cent value. <-- I can see value in knowing this piece of information. 
      midi_to_notes_octaves calls improve_chord_rolls which does the conversion from midi_notes to cent values. note_to_1200_edo is where the conversion takes place:
            chord_in_1200 = np.array(note_to_1200_edo(initial_chord)) # assign a 1200 edo step to each midi note
      I tried to cherry pick the initial notes, but the results were terrible. Lots of:
            mismatch between the original MIDI notes chord_num = 25, midi_notes = array([76, 67, 57, 49]), 
            chord_12_rounded =  array([76, 69, 55, 49])
            chord_12_rounded[delta] = 69, midi_notes[delta] = 67, chord_1200 = array([400, 898, 667,  84]), octaves = array([6, 5, 4, 4])
      Could it have just been a failure in rearrangement. I commented out the rearrangement in try_permutation. Was that a mistake?
      This was true after I set the conversions to np.arange(0, 1200, 100), which is what it was before. Something new is wrong here.
      Could it be due to using the ratio_factor while selecting the intervals? I made lots of changes today. 
      The mismatch is between the original chord 67 and the rounded cent chord 69. That's a very large gap. also 57 became 55. One went up and and the other went down.
      I tried several things to get back to where I was previously:
      a.    was:
                  initial_notes_cents = np.array([0, 84, 196, 300, 400, 500, 582, 700, 786, 898, 1000, 1102])
            now:
                  initial_notes_cents = np.arange(0, 1200, 100)
            changed it back 
      b.    best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2] * ratio_factor)  # tried without the ratio_factor. no effect.
      c.    What else is different? I had removed the rearrangement in try_permutations, and changed the return statement to:
                  return best_choice, best_score
            This was the value before rearrangment. Changed it to:
                  return final_result, best_score
      d.    So I guess I could put those changes described in 1 & b above. 
      e.    Made all those fixes, and now the high score is over 1000:
            108   ['C♯', 'F♯', 'C♯', 'A♯'] [  84  582   84 1003] (0, 1, 498, '4/3') (0, 2, 0, '1') (0, 3, 919, '17/10') (1, 2, 498, '4/3') (1, 3, 421, '51/40') (2, 3, 919, '17/10')  1109.0


2.    What does cent_deviation in the Optimzer mean? 
      Long answer lead to a potential revelation. 
      Imagine your first two notes are 100, 500, 800, 1100. The cent distance is 400. The closest ratio to 400, with the lowest ratios is 386 at 5/4. the cent_deviation in this case is 400 - 386 = 14. So you reset the second note to 100 + 386 = 486 from 500. 
      Hang on, have I been doing this all wrong all along? Why am I going back to 100 here. I should instead use the next interval is 486 to 800. This would gain the knowledge that the second note is now 486, which means the next interval to pick could benefit from that adjustment. Maybe. 
      That's 314. The closest ratio is 316 at 6/5, so reset the third note to 486 + 316 = 802. The next interval is 1100 - 802 = 298. The closest ratio to that is 
      It's how far off the best ratio is from the initial interval cent distance, which may have been the 12TET cent value, or one that has been altered previously. It's how far you are moving the note from when it first arrived 
            +-- look inside a file
            |     +-- allow regular expressions, multiple search terms
            |     |  +-- search term
            |     |  |           +-- file to search. Wildcards allowed
            |     |  |           |             +-- eliminate cruft
            |     |  |           |             |   +-- field separator is a space
            |     |  |           |             |   |      +-- field numbers to keep
            |     |  |           |             |   |      |         +-- sort the results
            |     |  |           |             |   |      |         |    +-- treat numbers like numbers
            |     |  |           |             |   |      |         |    |    +-- eliminate duplicates
            grep -E "Optimizer"  testing.log | cut -d " " -f 9-20 | sort -n | uniq
                  cent_deviation = 0.0
                  cent_deviation = 1.0
                  cent_deviation = 14.0
                  cent_deviation = 15.0
                  cent_deviation = 16.0
                  cent_deviation = 18.0
                  cent_deviation = 5.0 

3.    Danger: rat-hole alert: Optimize the interval searches with combinations instead of inx1, inx2, where possible. 
      I have to deal with the testing if a change should be made, or keep the existing note cent value
            if already_changed[inx2]: # this could be trouble. I don't have inx2 any more
            prev_chosen_note = initial_chord[inx2] # save what it used to be
            new_note = (initial_chord[inx1] + cent_moves * tonal_diamond_values[indeciis_to_tonal_diamond[best_choice_overall], 1]) % 1200 
      I tried, but ran into trouble because I needed to insert the new interval cent value into the initial_chord, and I didn't know where I had obtained the values, which notes in the chord are not visible.

4.    Should I try to make a change to the first note in the chord before looking at the intervals? 
      I'm already changing if it's one of the top_notes, after the intervals are chosen. There is no value in doing it earlier in the process. What if I could start the interval evaluation with default values for all the notes in the scale? Allow them to change, but just start there. It might speed things up. 

---------------------
5/14/23 To do today:

1.    How did this one slip through. Was there something that I changed that introduced a bug in all the changes I made on Saturday?. 
      The high score is over 1000:
            108   ['C♯', 'F♯', 'C♯', 'A♯'] [  84  582   84 1003] (0, 1, 498, '4/3') (0, 2, 0, '1') (0, 3, 919, '17/10') (1, 2, 498, '4/3') (1, 3, 421, '51/40') (2, 3, 919, '17/10')  1109.0
      I think it's just a bug. When I islolate the offending chord, it gets a very low score.
            # 88   ['G♯', 'F♮', 'C♯', 'C♯'] [786 502  84  84] (0, 1, 284, '33/28') (0, 2, 702, '3/2') (0, 3, 702, '3/2') (1, 2, 418, '14/11') (1, 3, 418, '14/11') (2, 3, 0, '1')  1084.0
            keys[new_chorale.T % 12] = array([['G♯', 'F♮', 'C♯', 'C♯']], dtype='<U2')
            initial_chord = array([68, 65, 61, 49]), initial_chord % 12 = array([8, 5, 1, 1])
            chord_1200 = array([786, 470,  84,  84]), [int(round(note / 100,0)) for note in chord_1200] = [8, 5, 1, 1], score = 39.0
      It's not a bug, it's a bad design decision. When I preset the original_12 to the most common notes, it gets worse results. So much for that idea.
            initial_chord = array([68, 65, 61, 49]), initial_chord % 12 = array([8, 5, 1, 1])
            chord_1200 = array([786, 502,  84,  84]), [int(round(note / 100,0)) for note in chord_1200] = [8, 5, 1, 1], score = 1084.0
            original_12 = array([   0,   84,  196,  300,  400,  500,  582,  700,  786,  898, 1000,
                  1102])
      Unless I change the original_12 to include 470 instead of 500 as an starting note. But it only improves to the same result as not includeing anything other than original_12 = np.arange(0, 1200, 100) 
            chord_1200 = array([786, 470,  84,  84]), [int(round(note / 100,0)) for note in chord_1200] = [8, 5, 1, 1], score = 39.0
            original_12 = array([   0,   84,  196,  300,  400,  470,  582,  700,  786,  898, 1000,
            1102])
      If I change the 500 to 470, it screws up chord #12, 16, 100. 
      This whole method is very unpredictable. I'm going to hard code the initial notes to 100 cents per semitone. 

2.    But what if you could have top_notes and top_notes_2nd_tier? In other words, if the top_notes are not present in the chord, it will attempt to transpose to another note note in top_notes. This opens up a lot of questions:
      a.    Do we need three top_notes, or would one do as well. We know have the ability to inspect the output with the report and also the value counts on notes. See if there is any change when we have fewer top_notes.
      b.    Could we have a priority of notes for transposition. In this case each of the top_notes would have an integer that dictated if it was the first one attempted, then another that was the second prioority.
      c.    I ended up implementing a first come - first served algorithm. Put the most important top notes at the front of the line, and bail after the first one is discovered. Make sure the order is correct. 

3.    But first examine again the value of different input settings, including dmu.build_all_ratios(limit_for_diamond))
      a.    distance_factor = 2, ratio_factor = .5 expected result: higher ratio integers, not as far from 12TET
      b.    distance_factor = 4, ratio_factor = .25 expected results: much higher ratio integers, nearly exact 12TET
      c.    Even more if the results don't vary 
      d.    distance_factor =  .5, ratio_factor = 2 expected result: lower ratios even farther from 12TET
      e.    distance_factor = .25, ratio_factor = 4 lowest ratios, farthest from 12TET
      f.    Try different build_all_ratios limits, 15, 31, 72

4.    Pick more top_notes. 
      I seem to have better results if I start with just one top_note, and keep adding more until it goes whack. But I need to continuously pay attention to the collions. There were 17 with 6 top_notes. I need to come back to this when I've made the enhancement to choose the most important note.
      a.    6 top_notes 65/154 but 17 collisions where it arbitrarily picks the smallest movement. Should pick the most important one.
      Instead of defaulting to the smallest transposition, I should transpose to the most important note, the one earlier in the top_notes array.
            (716, 7, 14) same
            (604, 6, 20) same
            (196, 2, 32) same
            (218, 2, 37) fewer
            (786, 8, 70) more
            (582, 6, 92) same
            (1102, 11, 142) fewer of these
            (84, 1, 157)
            (898, 9, 164)
            (400, 4, 174)
      b.    5 top_notes 65/1544 15 collisions
            (716, 7, 14)
            (604, 6, 20) more
            (196, 2, 32) fewer
            (218, 2, 41) more of these
            (786, 8, 68) same
            (582, 6, 92) fewer of these
            (1102, 11, 144) twice as many of these
            (84, 1, 157) fewer of these
            (898, 9, 164) same
            (400, 4, 174)      
      c.    Try 4 top-notes A E C# F# 65/154 5 collisions
            (1084, 11, 14)
            (470, 5, 16)
            (1080, 11, 16)
            (1100, 11, 24)
            (196, 2, 42)
            (786, 8, 68)
            (1102, 11, 78)
            (582, 6, 104)
            (84, 1, 169)
            (898, 9, 172)
            (400, 4, 174)
      d.    Try 3 top_notes A E C# got the same 65 average 154 max score. The more top_notes, the more of the most most common notes in the output set. No collisions.
            (1080, 11, 12)
            (218, 2, 13)
            (470, 5, 16)
            (1084, 11, 16)
            (1100, 11, 24)
            (196, 2, 32)
            (786, 8, 68)
            (1102, 11, 78)
            (582, 6, 92)
            (84, 1, 169) # this is higher
            (898, 9, 172)
            (400, 4, 174)      
      e.    Try fewer top_notes. switched to 2 and got the same 65 average 154 max score 
            (1084, 11, 18)
            (1100, 11, 28)
            (196, 2, 29)
            (786, 8, 48)
            (1102, 11, 74)
            (582, 6, 87)
            (84, 1, 134)
            (898, 9, 172)
            (400, 4, 174)
      f.    Try with one top_notes:
            (1084, 11, 22)
            (786, 8, 24)
            (784, 8, 28)
            (196, 2, 29)
            (1102, 11, 30)
            (398, 4, 34)
            (1100, 11, 68)
            (582, 6, 85)
            (84, 1, 129) # lower
            (400, 4, 134)
            (898, 9, 172)      
                  
5.    Bug alert. When I decrease the tonality diamond limit to 15, the range of ratios should also go down. 
      At present it's going below zero and exceeding the range of the array. I should really precheck that. I lowered the range from 12 to 10, but it's still looking at 17 ratios. Not good. Fixed it.
            883.0 - INFO - best_choice_overall = 8
            884.0 - INFO - Optimizer: ('9/8', 204, 17), cent_deviation = 4.0
            885.0 - INFO - ratios to evaluate: [-7 -6 -5 -4 -3 -2 -1  0  1  2  3  4  5  6  7  8  9]
            886.0 - INFO - [(-7, ('20/11', 1035, 31)), (-6, ('11/6', 1049, 17)), (-5, ('24/13', 1061, 37)), (-4, ('13/7', 1072, 20)), (-3, ('28/15', 1081, 43)), (-2, ('15/8', 1088, 23)), (-1, ('2', 1200, 3)), (0, ('1/1', 0, 2)), (1, ('16/15', 112, 31)), (2, ('15/14', 119, 29)), (3, ('14/13', 128, 27)), (4, ('13/12', 139, 25)), (5, ('12/11', 151, 23)), (6, ('11/10', 165, 21)), (7, ('10/9', 182, 19)), (8, ('9/8', 204, 17)), (9, ('8/7', 231, 15))]
            887.0 - INFO - best_choice_overall = 8
            888.0 - INFO - Optimizer: ('16/15', 112, 31), cent_deviation = 0.0
            889.0 - INFO - ratios to evaluate: [34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50]               
      Two questions:
      a.    Why is it not recognizing the range value - who cares
      b.    Why am I bothering with ranges at all if I'm using binary search for the lowest value? 

-------------------------------------------------------------
5/15/23     To do Today:

1.    Update the range problem, get rid of it. 
      Actually, I just reduced the load of making the range, since it's just a certain number of values higher and lower than the result of searchsorted. That was trivial to find. And there is no reason to make it any bigger than 6 on each side. But I check to see if it's out of range and clip it if it is.
            indeciis_to_tonal_diamond = np.array([inx for inx in indeciis_to_tonal_diamond if inx < tonal_diamond_values.shape[0] and inx >= 0])
      copilot wrote the last half of that list comprehension. Neat. Conditional python list comprehensions often confused me. 

2.    Simplify the transposition to pick the first target in the list and move on. Make top_notes a priority list.
      It should only get to the elements at the end of the list if it doesn't find one earlier. Finished the change to simplify transposition. It's very limited, but at least now there are no collisions. Start here tomorrow increasing the number of top_notes. It ignores those down the line, and does the first ones it encounters first. Done. Well not quite. New bug found if multiple notes in a chord all match in some way. Fixed it. More checks.

3.    Have you ever heard of @cache in python? It can really speed things up, but only if I'm passing in a hashable object. 
      Arrays aren't hashable. Bummer.

      @cache
      def factorial(n):
            return n * factorial(n-1) if n else 1
      It caches all results. Is this for real? But you can't cache unhashable objects, like numpy arrays.

4.    Reconsider changing the order of the interval selection to the following:
            #                              +-- changes 1
            #                              |      +-- changes 2 based on 1
            #                              |      |      +-- changes 3 based on 1 & 2
            #                              |      |      |      +-- challenges 0 based on 1,2,3
            #                              |      |      |      |      +-- challenges 2 based on 0,1,3
            #                              |      |      |      |      |      +-- challenges 3 based on 0,1,2
            #                              |      |      |      |      |      |      +-- challenges 1 based on 0,2,3
            #                              |      |      |      |      |      |      |      +-- challenges 0 based on all 
            #                              |      |      |      |      |      |      |      |      +-- challenges 2 based on all 
            #                              |      |      |      |      |      |      |      |      |      +-- challenges 1 based on all 
            #                              |      |      |      |      |      |      |      |      |      |      +-- challenges 1 based on all 
            #                              |      |      |      |      |      |      |      |      |      |      |      +-- challenges 2 based on all 
            order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]])
      This is 12 compares. That is twice as much as a combinations(4,2). Is it worth it? The advantage is that it changes all the notes quickly. That's a speculative advantage. Keep your eyes open. I implemented it, but can back it off my commenting out the list of 12 in favor of a list of 6. 
            order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]])
            # order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3]]) # this is the original compare order.
            
5.    Limiting the number of ratios has non-linear effects. Tried 15, 31, 72 and results were all over the place.
      I don't know if I'm jumping to a conclusion, but one chord was able to reduce the score from 1091 to 139 when I used limit 31 instead of limit 15. Boosting it up to limit 72 does worse.

------------------------
5/16/23 To do today.

1.    Build out the top_notes with the view towards reducing the proliferation of unique notes that might be consolidated without pain. 

2.    Bug found. If a chord has two of the same notes, this fails if it's in multiple locations in the chord. 
      We need to know the cent value of the chord note in order to build the gap to add to the chord to transpose it.
            print(f'found {top_note = } in {int(note_in_12[note_in_12 == top_note]) = }')

3.    Back to the grid search:
      Examine the value of different input settings, including dmu.build_all_ratios(limit_for_diamond))
      a.    dist_factor = 2, ratio_factor = .5 expected result: higher ratio integers, close 12TET
            bwv245.14.d2r.5.txt
            11.8 seconds
            Maximum score was: 154.0
            Total score was 5205.0
            Average score was: 64.3
            ratio_factor = 0.5, dist_factor = 2.0
            keys[top_notes[0]] = array(['A♮', 'E♮', 'C♯', 'B♮', 'F♯', 'G♯'], dtype='<U2')
            (218, 2, 24)
            (196, 2, 36)
            (786, 8, 68)
            (582, 6, 96)
            (1102, 11, 122)
            (84, 1, 163)
            (400, 4, 172)
            (898, 9, 172)
      a1.   dist_factor = 3, ratio_factor = 0.3
            bwv245.14.d3r.3.txt
            19.8 seconds
            Same max score
            Total score was 5123.0
            Average score was: 63.2
            ratio_factor = 0.3, dist_factor = 3.0
            (218, 2, 24)
            (196, 2, 36)
            (786, 8, 68)
            (582, 6, 95)
            (1102, 11, 122)
            (84, 1, 162)
            (400, 4, 172)
            (898, 9, 172)
      a2.   dist_factor = 5, ratio_factor = 0.2
            4.1 seconds - changed a lot of logging.info to logging.debug. Don't know why there were so many set to info.
            bwv245.14.d5r.2.txt
            Maximum score was: 154.0
            Total score was 5123.0 <-- no change
            Average score was: 63.2
            ratio_factor = 0.2, dist_factor = 5.0
      a3.   dist_factor = 10, ratio_factor = .12 expected results: much higher ratio integers, nearly exact 12TET
            4.1 seconds
            bwv245.14.d10r.12.txt
            no score changes. That's unexpected. I'm not getting the results I predicted here. I was expecting higher integer ratios when distance was punished so much. Is it not effective? 
            (218, 2, 24)
            (196, 2, 36)
            (786, 8, 68)
            (582, 6, 95)
            (1102, 11, 122)
            (84, 1, 162)
            (400, 4, 172)
            (898, 9, 172)
      a4.   dist_factor = 20, ratio_factor = 0.1
            bwv245.14.d20r.1.txt
            No change from distance_factor = 5. I'm getting suspicious now. I think the reason that it tends to revert to the lowest score regardless of the hyperparameters is that it has so many chances to change ratios to improve scores. For example, chord_number 214 is the worse scoring chord among all the different runs. When the distance ratio is high, the first four ratios chosen for the intervals are: 
                  296.0 - DEBUG - Optimizer: ('3/2', 702, 5), cent_deviation = 2.0
                  302.0 - DEBUG - Optimizer: ('17/12', 603, 29), cent_deviation = 1.0
                  307.0 - DEBUG - Optimizer: ('29/23', 401, 52), cent_deviation = 0.0
                  312.0 - DEBUG - Optimizer: ('4/3', 498, 7), cent_deviation = 2.0
            two of those are low, but two are very high, which will lead to high scores. Since I can't preserve the distance_factor beyond the initial choice, the scores based on ratio_factor will dictate the scores received. Some high ones in later optimizer choices, thanks to the very low (0.1) ratio_factor. 

                  317.0 - DEBUG - Optimizer: ('18/17', 99, 35), cent_deviation = 2.0
                  362.0 - DEBUG - Optimizer: ('4/3', 498, 7), cent_deviation = 0.0
                  367.0 - DEBUG - Optimizer: ('9/8', 204, 17), cent_deviation = 2.0
                  371.0 - DEBUG - Optimizer: ('3/2', 702, 5), cent_deviation = 2.0
                  403.0 - DEBUG - Optimizer: ('18/17', 99, 35), cent_deviation = 0.0
                  409.0 - DEBUG - Optimizer: ('9/8', 204, 17), cent_deviation = 0.0
                  414.0 - DEBUG - Optimizer: ('17/12', 603, 29), cent_deviation = 0.0
                  419.0 - DEBUG - Optimizer: ('34/27', 399, 61), cent_deviation = 0.0
                  437.0 - DEBUG - Optimizer: ('4/3', 498, 7), cent_deviation = 0.0
                  442.0 - DEBUG - Optimizer: ('3/2', 702, 5), cent_deviation = 0.0
                  447.0 - DEBUG - Optimizer: ('17/12', 603, 29), cent_deviation = 0.0
                  451.0 - DEBUG - Optimizer: ('34/27', 399, 61), cent_deviation = 0.0            
                  in score_chord_cents. score = 3015.3
            That's pretty high. It then takes only a few tries before it comes up with 154.0 as a score:
            about 80 ms later it's here: 80.0 - DEBUG - score for the chord after making a change to initial_chord = array([1100,  398, 1001,  602]): score = 154.0
            I also think changing the order of the interval choices reduces the influence of the 12TET starting cent values. They quickly become irrelevant. It's all about searching for a low score, to hell with where it started out. Go for the goal.
            
      a5.    Even more if the results don't vary. They don't vary with larger distance_factors. And the scores are influenced by the very low ratio_factor values. Remember that the score is divided by the ratio_factor before being used. So even if it looks low, it's still full of high ratio values.

      b1.   dist_factor =  .5, ratio_factor = 2 expected result: lower ratios even farther from 12TET
            bwv245.14.d.5r2.txt
            same scores, but different ratios
      b2.   dist_factor = .25, ratio_factor = 4 lowest ratios, farthest from 12TET - Including crossing midi note lines.
            bwv245.14.d.25r4.txt
            Got a mismatch:
                  228   ['C♯', 'E♮', 'A♮', 'D♮'] [ 84 400 898 196] (0, 1, 316, '6/5') (0, 2, 814, '8/5') (0, 3, 112, '16/15') (1, 2, 498, '4/3') (1, 3, 204, '9/8') (2, 3, 702, '3/2')  84.0
            mismatch between the original MIDI notes chord_num = 230, midi_notes = array([74, 66, 57, 49]), chord_12_rounded =  array([74, 65, 57, 48])
                  midi_notes % 12 = array([2, 6, 9, 1]), chord_12_rounded % 12 =array([2, 5, 9, 0])
                  chord_12_rounded[delta] = 65, midi_notes[delta] = 66, chord_1200 = array([196, 512, 898,  14]), octaves = array([6, 5, 4, 4])
                  initial_chord = array([74, 66, 57, 49]), initial_chord % 12 = array([2, 6, 9, 1])
                  chord_1200 = array([196, 512, 898,  14]), [int(round(note / 100,0) % 12) for note in chord_1200] = [2, 5, 9, 0], score = 59.0
                  Start here tomorrow. 
            Isolated: initial_chord = array([74, 66, 57, 49]), initial_chord % 12 = array([2, 6, 9, 1])
                  chord_1200 = array([196, 512, 898,  14]), [int(round(note / 100,0) % 12) for note in chord_1200] = [2, 5, 9, 0], score = 59.0
            No permutation. This may be a case of just moving too far:
                  after rearranging. best_score = 59.0, final_result = array([239, 555, 941,  57]) The 941 is discovered as a top note, but the top_note value is 898, 43 cents lower. So it starts as 2, 6, 9, 1, but when it's lowered 43 cents, it becomes [2, 5, 9, 0]. Can't let that happen.  
            Should I apply the transposition before I rearrange the notes? Basket of snakes alert. It wasn't very hard, but it didn't make a difference. 
                  after rearranging. best_score = 59.0, final_result = array([239, 555, 941,  57])
                  Checking top_cent = 898, top_note = 9 to determine if transposition is advised
                  top_note = 9 is in note_in_12 = array([2, 6, 9, 1])
                  found = array([0, 0, 1, 0])
                  at least one note in final_result was in top_notes final_result[np.nonzero(found)] = array([941])
                  made an transposition to the chord. gap = -43 final_result = array([196, 512, 898,  14]) 
            Does the transposition function know what the original midi notes are? It can be provided that information.

            Well, it turns out this is not a location problem, but rather a design problem. Moving the transposition to before the rearrangement or after the rearrangement doesn't change the fact that the transposition moves the note to a different midi note, which is sonething I can't allow to happen. Before applying the transposition, check to see if it would move it to a different note, and don't do the transposition in that case. Being 43 cents off on note 9 (A) is not deireable. What if one of the later top_notes has a better transposition idea? To find out if that would work, I'd have to do what?
            a.    in transpose_top_notes, check to see if the transposition would move the note to a different midi note. If so, don't do the transposition.
            b.    Don't stop moving through the top_notes with that discovery. See if another top_note is in the chord. In this case, top_notes = np.array([[9,    4,    1,   11,    6,    8], [ 898,  400,   84, 1102,  582,  786]])
            It found 9, then it would look for 4, then 1 and find 1 @ 57 cents, and move the chord up 27 cents to 84, the top_notes cent value.
            note_in_12 = array([2, 6, 9, 1]) 
            final_result = array([239, 555, 941,  57])
            So I think I implemented this, but the result looks like it just gave up after trying 9:
            chord_1200 = array([239, 555, 941,  57]), [int(round(note / 100,0) % 12) for note in chord_1200] = [2, 6, 9, 1], score = 59.0
            chord_1200 should have been 
            chord_1200 = array([266, 582, 968,  84]), [int(round(note / 100,0) % 12) for note in chord_1200] = [3, 6, 10, 1]
            It did the right thing, and chose not to move the 27 cents because that would change the note 2 to 3, and 9 to 10.
            What would you have done here? You have to find a just version of ['D♮' 'F♯' 'A♮' 'C♯']. That's just a D major 7th chord. I'd want the D to be harmonious with the A, which is one of the top notes. But D is not in top_notes. Where is it? chord_number 230. See what would happen with other dist_factor, ratio_factor.
            Still getting mismatches after making the latest changes. It's not just the transposition that is changing the midi notes, it's the fact that you reduce the penalty for distance to 0.25, and boost the ratio penalty. That forces the model to search farther from the +-50 cents from a midi note, resulting in changes to the midi notes.
                  mismatch between the original MIDI notes chord_num = 118
                  midi_notes % 12 = array([ 2,  6, 11,  9]), chord_12_rounded % 12 = array([ 2,  5, 10,  9])
                  chord_1200 = array([ 156,  542, 1040,  858])
                  118   ['D♮', 'F♮', 'A♯', 'A♮'] [ 156  542 1040  858] (0, 1, 386, '5/4') (0, 2, 884, '5/3') (0, 3, 702, '3/2') (1, 2, 498, '4/3') (1, 3, 316, '6/5') (2, 3, 182, '10/9')  59.0
                  in transpose_top_notes. after rearranging. score = 59.0, final_result = array([ 156,  542, 1040,  858])
                  No transpose was done in this case. 
                  First score was taken:                                      2,    6,   11,    9 # it's right where it belongs
                  score for the chord before changing initial_chord = array([ 178,  586, 1084,  880]): score = 165.0
                                                         5,    10,     9,    2 # it's wrong should be 6,11 not 5/10, and the 9 is whack
                  rolls results_so_far: result = array([ 542, 1040,  858,  156]), score = 59.0
            I guess if you set dist_factor to 0.25, it doesn't pay a penalty for moving to a better ratio. Even if that movement crosses into another midi_note.
      b3.   dist_factor = .125, ratio_factor = 10 lowest ratios, farthest from 12TET - Including crossing midi note lines.
            bwv245.14.d.125r10.txt
            Lots of mismatches 118 - 203 chord = np.array([ 2,  6, 11,  9]) array(['D♮', 'F♯', 'B♮', 'A♮'] is turned into [ 2,  5, 10,  9]) ['D♮', 'F♮', 'A♯', 'A♮']. Where in the chorale is that chord. Measure 9 beat 7,8
            It sounds like shit in several places. 8 or 9 spots it goes off the rails. 

      c.    Try different build_all_ratios limits, 15, 31, 72 - I only get decent results with 31. 

4.    Bug in try_permutations voicing. The voicing is done in try_permutations:
                  before rearranging. chord_in_1200 = array([600, 900,   0, 200]), best_choice = array([ 600,  214,  916, 1183]), 
            If I had reduced it to (round(numbers,0) / 100) % 12 on both sides, I bet it would have given me the right result.
            Fixed it: I reduced it to 12TET for purposes of voicing like the original chord. That worked.
                  best_choice_12 = np.array([round(note / 100,0) % 12 for note in best_choice])
                  chord_in_12 = np.array([round(note / 100,0) % 12 for note in chord_in_1200])
                  best_voicing = np.argmin(np.array([sum(np.array(abs(chord_in_12 -  voicing))) for voicing in np.array(list(permutations(best_choice_12)))]))

---------------------------------
5/17/23 To do today:

1.    Summarize what you learned:
      a.    Moderate values of 1 for both dist_factor and ratio_factor work best. Setting those either high or low leads to unpredictable outcomes.
            Higher distance values and lower ratio_factor values stop having any effect after a while. The ones that deviate from 1 for both values sound bad, have risks of moving notes away from the original midi values, and find all sorts of bugs that aren't really bugs. Lower distance values encourage wide divergences from the midi values, resulting in strange sounding results. 
      b.    Changing the build_all_ratios didn't improve results, and often made tbest_choiceerrible results. 
      c.    I have safely set the top values to the 6 most common notes with good effect.

----------------------------------------            
5/18/23 To do today:

1.    Fix the bugs: check to see if this gap is large enough to transpose off the midi_note value. gap = 500
      How did I end up thinking this is reasonable? There are tons of gaps that are way too big. Here are the worst offenders:
            grep -E "check to see if this gap" ball9.log | cut -d " " -f 22-24 | sort -n
                  168 183 203 210 220 283 283 286 316 316 403 472 481 483 500 508 578 688 701 793 799 812 866 880 884 886
      Think you have a problem? I neglected to find the new best_choice_12 array after the rearrangement of the notes. 
            after rolls, before rearranging. original chord: [1100 1100  400  800], best_choice = array([ 800, 1116, 1116,  414])
            after rolling and permutations. best_score = 41.0, final_result = array([ 800, 1116, 1116,  414])
      Need to find best_choice_12 now, after rearrangement:
            best_choice_12 = np.array([round(note / 100,0) % 12 for note in final_result])
      Result:
            grep -E "check to ensure" ball9.log | cut -d " " -f 18-30 | sort -n | uniq
                  -30 -29 -26 -22 -21 -18 -17 -16 -15 -14 -12 -4 -2 -1 1 2 3 4 5 10 16 17 18
            Much better. By the way, to convert the line feeds into spaces in vscode do this:
                  mark the line feed that follows the first number, and ctrl-c copy it to the clipboard.
                  crl-h to open the replace dialog box, and copy the number and its trailing line feed into the find box. 
                  carefully erase the number, leaving the line feed.
                  in the replace box put one space, then press replace all. 
                  That's it. Neat.

2.    Post a version of the most recent work on Substack. Done.

3.    Try a different chorale.

------------------------
5/19/23 To do today:

1.    Provide a way to control the overall volume of each instrument relative to other instruments. This is harder than I expected.
      a.    Where to put it. How about the voice_time dictionary. I already have a pair of fields to control the octaves, but never implemented. I could put a volume setting there as well. 
             "min_oct": 2, "max_oct": 10, "volume": 1.0
      b.    I could then use that volume value to add to the current volume in the dmu.send_to_csound_file function. I'm not comfortable with that, since it's used by diamond_music as well. There are other places I could put it, but they are all in diamond_music as well. 
      I think the best place is where I combine all the features, like atu.add_features(chorale, guev_array)
      That is just used by adaptive_tuning_utils.py. line 582 is where it goes. First put it in the voice_time dictionary. Not so fast. There are massive changes to the octaves after that function has completed. I'll need to put the volume boost and octave clipping in the instruments after the octave enhancements have completed. And you can't mess with zero octave notes, since that's a code for silence. So the min_oct can't affect the zero octave notes. More code to write. 
      c.    As long as I'm there, check the octaves against the limits in the dictionary for min_oct, max_oct, too.
      d.    Call it  "volume_factor": 1.0, "min_oct": 2, "max_oct": 10
      e.    Should look like this:
                  for voice in voice_names: # for each voice, "fing1", "fing2", etc.
                        velocity += voice_time[voice]["volume_factor"] # add the voice_time["volume"] to the velocity. Each voice adds a different value based on voice_time dictionary
                        octaves = np.clip(octaves, voice_time[voice]["min_oct"], voice_time[voice]["max_oct"])
            If you can think of other constraints for other features, put them here. Quick and easy.
            The problem is that the octaves get changed later in the process. Fixed it. Put it at the end of each of the two instrument functions inside the notebook
            octave_array = notes_features_6[1]
            ... after all the changes to it to spread out the octaves, which may spread them too far.
            velocity_array = notes_features_6[5]
            for voice in voice_names: # for each voice, "fing1", "fing2", etc.
                  logging.info(f'before boosting: {np.max(velocity_array) = }')
                  logging.info(f'{velocity_array[0,:4] = }, {voice_time[voice]["volume_factor"] = }')
                  velocity_array += voice_time[voice]["volume_factor"] # add the voice_time["volume"] to the velocity. Each voice adds a different value based on voice_time dictionary
                  logging.info(f'after boosting: {np.max(velocity_array) = }, {velocity_array[0,:4] = }')
                  logging.info(f'before clipping the octave: {np.max(octave_array) = }')
                  octave_zero = np.where(octave_array == 0, 0, 1) # save the locations of all the zeros in the octaves array in a new array called octave_zero, which has zeros where the octaves were zero and ones where some other number is located.
                  octave_array = np.clip(octave_array, voice_time["fing1"]["min_oct"], voice_time["fing1"]["max_oct"]) # clip to the min_oct through max_oct values from the voice_time dictionary
                  octave_array = octave_array * octave_zero # multiply the octaves array by the octave_zero array to restore the zeros that were clipped away
                  logging.info(f'after clipping the octave: {np.max(octave_array) = }')
            notes_features_6[1] = octave_array
            notes_features_6[5] = velocity_array

2.    Try some different instruments in the orchestra 

3.    Use sed to modify the convolve csound orchestra to only run as long as the length of the input wave file.
      Input is ball9c.csd
      Modify this line: 
            i1 0 1600 .0085   1.81124716553287981859410430839 ; enough decimal places you think?
      Set the 1600 to be the number of seconds plus a few in the input wave file. 
      I know the number of seconds in the variable duration, rounded and padded and ready to go.
            sed -i 's/1600/460/' ball9c.csd 
      This worked, but I'll need to save the original so I can make this change uniquely every time. or change it back after I'm finished. I implemented the latter.
            sed -i 's/460/1600/' ball9c.csd

---------------------------------------
5/20/23 To do today:

1.    Work on additional instruments. Copy the current notebook TonicNet_Csound_adaptive_big_ensemble trimmed.ipynb and rename the copy.
      The bowed strings with vibrato seem to have wrong samples. The vibrato is too fast. If I upsample or downsample them it might fix the problem. 

2.    Consider taking a long view of the volume_array. Today it's this:
            volume_array = np.full(chorale.shape[1], 7) # in finger_piano_part
            volume_array = np.full(chorale.shape[1], 6) # in woodwind_part
      This was just a placeholder, but it's been there for months. I think it's time to consider a more sophisticated approach.

3.    I uncovered a real problem with the bowed strings with vibrato. 
      When I choose a note, like for example D in octave 4, I expect it to choose a sample that performs that note. Unfortunately, when upsample is set to 0, it picks sample 934, which is 
            f934 0 0 1 "../../csound/McGill/Partition F/VIOLIN W-VIB/VIOLING#3.aif" 0 0 0
      It should pick 
            f937 0 0 1 "../../csound/McGill/Partition F/VIOLIN W-VIB/VIOLIND4.aif" 0 0 0      
      I need to get those in allignment. This problem explains why the vibrato is too fast. It picks a low sample, then speeds it up.
      The McGill.dat file is an octave too high for the violin. It might be high for the other instruments too. I'll need to change it there, and in the ball9.csd, and new_output.csd. All three.
      from
            f930 0 128 -17 0 934 57 935 59 936 61 937 63 938 65 939 67 940 69 941 71 942 74 943 76 944 78 945 80 946 82 947 84 948 86 949 88 950 90 951 92 952 94 
            f931 0 64 -2 0  56  58  60  62  64  66  68  70  73  75  77  79  81  83  85  87  89  91  93 
      to:
            f930 0 128 -17 0 934 45 935 47 936 49 937 51 938 53 939 55 940 57 941 59 942 62 943 64 944 66 945 68 946 70 947 72 948 74 949 76 950 78 951 80 952 82 
            f931 0 64 -2 0  44  46  48  50  52  54  56  58  61  63  65  67  69  71  73  75  77  79  81 
      So that fixed that instrument. Those were the only changes made. Here is the process:
      a.    Change the McGill.dat file to have the correct octave for the instrument - in my case if the note played is too low, subtract 12 from every note in the sample set.
      b.    Read the ftable 1 from the ball9.csd file. Count up to the instrument number, and look where it points. 
                           1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20   21   22   23   24
            f1 0 64 -2 0 601 630 652 667 683 705 726 742 766 787 807 830 850 872 890 909 930 953 975 999 1030 1070 1104 1131 
      c.    Copy the ftable and the following one pointed to from the newly created csd file over to ball9.csd in the TonicNet directory.

      So I made changes to several of the instruments, and only made things worse. All the changes to McGill.dat and ball9.csd were restored by Dropbox. 
      Something other than the McGill.dat file is wrong. 
      I ask for the flute to play octave 4 d 204 cents, and it chooses the sample for d3. How can I fix this? It's chosing the wrong sample. And it plays the d at octave 3 even though I asked for the d at octave 4. 
      It plays 146 Hz, when it should be 292 Hz.
      
      After changing the McGill.dat octave by subtracting 12 from every note, I have the right results.
      violin vib: f937 0 0 1 "../../csound/McGill/Partition F/VIOLIN W-VIB/VIOLIND4.aif" 0 0 0  292 Hz voice 17 right octave, right sample
      flute:      f876 0 0 1 "../../csound/McGill/Partition B/FLUTE NO-VIB/FLUTENV C3.aif" 0 0 0 146 Hz voice 14 wrong octave, wrong sample

      So we have two problems:
      a.    wrong octave is sounding 
      b.    the wrong sample is chosen

      Which may have two causes. 
      I fixed the octave that sounds in the bowed violin with vibrato voice 17. I subtracted 12 from every note in the McGill.dat file.
      I should probably do the same for all the other strings. Then I'll have to reduce the octaves that I request in the latest piece. 
            vibrato strings - voices: 17, 18, 19 ftables: 930, 953, 975 McGill #: IN W-VIB/VIOLING#3.a, /VIOLA W-VIB/VIOLAV, n A/CELLO W-VIB/ - The viola seems ok. also cello. viola is playing 964, cello plays 992. Those samples are: VIOLAV D4 and CELLOV D#4
                  correct samples, correct pitch. 
            pizz strings - voices 2,3,4 ftables: 630, 652, 667  F/VIOLIN-PIZZ/,  F/VIOLA-PIZZ/V, A/CELLO PIZZ/
            plays 637 660 678 Z/VIOLINPD#4 PIZZ/VIOLAPZD#4 PIZZ/P CELLOE4 all correct samples, correct pitch.
            martele strings: voices 9, 10, 11, ftables 766, 787, 807 McGill names: F/VIOLIN-MART, F/VIOLA-MARTEL, A/CELLOMARTELE
            All an octave low. Fixed them in McGill.dat copied over to ball9.csd and test_output.csd

----------------------
5/21/23 To do today:

1.    Fix the octaves in the finger piano and woodwinds. I made them all like each other, but I ignored the problem with the octaves and samples. Pay attention to the name of the sample and the midi number. They should match. For example if the name of the note ends in c2, that implies that it is midi note 24. If the midi value in the 2nd column is not 24, but is 36, then you need to reduce every note in the midi list by 12. I found one that was off by 24 steps, and I fixed it. 
            B/FLUTE NO-VIB, C/OBOE/OBOE A#, A/B- CLARINET/C, B/FRENCH HORN/F., A/BASSOON/BASSOON
            ✓ woodwinds - voices: 14, 15, 13, 16, 12 ftables: 872, 890, 850, 909, 830
            ✓ finger piano - voice: 1 ftables: 601 I/FingerP/
            ✓ bass finger piano - voice: 24 ftables: 1131 I/Bass FingerP
            ✓ violin pizz - voice 2, ftables 630, McGill name: F/VIOLIN-PIZZ/VIOLINPD#4 PIZZ/
            ✓ 'mari1': 'marimba1','csound_voice': 5, 683, iFtable = 691, MARIMBA/M
            ✓ 'xylp1': 'xylophone1','csound_voice': 6, 705, iFtable = 710, G/XYLOPHONE/X
            ✓ 'vibp1': 'vibraphone1','csound_voice': 7, 726, iFtable = 731, F/VIBRAPHONE/V
            ✓ 'harp1': 'harp1','csound_voice': 8, 742, iFtable = 755, HARP/HARP
            ✓ 'bgui1': 'baritone guitar1','csound_voice': 20, 999, iFtable = 1013, I/Baritone Guitar/H1B
            ✓ 'ebss1': 'Ernie Ball Super Slinky1','csound_voice': 21, 1030, iFtable = 1041, I/ErnieBall-038/2
            ✓ 'long1': 'long string1','csound_voice': 22, 1070, iFtable = 1091, LongString-024/Str
            ✓ 'stri1': 'original string1','csound_voice': 23, 1104, iFtable = 1109,  I/Strings/String
2.    This looks like a bug:
            voice: 2. switched sample from 634 to 634. Total moved so far: 419
      Why is it switching but not switching?
            ;                  ivoice,          iFtableTemp    iFtable             giMoved
            printf_i "voice: %i. switched sample from %i to %i. Total moved so far: %i\n", 1, iVoice, iFtableTemp, iFtable, giMoved 
      printf_i looks like a primitive python print format method. What's that integer 1 doing? It's telling it to always print the line. itrig -- if greater than zero the opcode performs the printing;
      I think the csound csd file is expecting upsample value to be 253, 254, 255, 0, 1, 2, 3, when I switched to -3, -2, -1, 0, 1, 2, 3 in the score. I only have accounted for that change. 
      Fixed it. I made separate print commands for it the move was successful or if was blocked.
      I went back to the csound directory, and updated ball9.mac to include trumpet, trombone, and tuba parts. I copied the samples and metadata around the samples over to the TonicNet directory. I failed to change the sample file names, so they all failed. I had to do a mass change from:
            "./McGill
      to:
            "../../csound/McGill
      That was easy.

3.    I put all the instruments into the mix, and there are a lot of tuning issues. 

✓    I wonder why the notes in the final csound are all floating point. The only value that should be floating point is the starting time and the duration. 
      Numpy converts all data types in an array to float if any single element is float. I could int() all the fields as it's being sent to csound. 

            ;Inst Sta Hold Vel Ton Oct Voi Ste En1 Gls Ups Ren 2gl 3gl Vol
            i 1.0 0.001 5.05 66.0 584.0 2.0 26.0 16.0 16.0 0.0 1.0 16.0 0.0 0.0 6.0 
            i 1.0 0.001 0.758 71.0 584.0 2.0 4.0 9.0 1.0 0.0 0.0 1.0 0.0 0.0 7.0 
            i 1.0 0.001 0.758 71.0 584.0 3.0 23.0 7.0 1.0 0.0 0.0 1.0 0.0 0.0 7.0 
            i 1.0 0.001 2.525 71.0 86.0 6.0 15.0 16.0 16.0 0.0 2.0 16.0 0.0 0.0 6.0 

5.    I could make some of the instruments go quiet using the volume_array. It would have to be carefully planned out. 
      At the start of each of either woodwind_part or finger_piano_part, I have an opportunity to set it to a density_array of sorts.
            volume_array = np.full(chorale.shape[1], 6.0) # replace this with a density array
                              0   32   64   96   128   160   192   224   256
            finger_pianos     7    7    4    0     0     3     2     3     5
            wood_winds        6    4    0    0     0     3     2     3     5
            pizz_strings      0    0    0    4     7     4     4     3     5
            bowed_strings     0    0    4    6     6     3     4     3     5
            brass             0    4    4    0     0     2     2     3     5
            perc_guitar       0    0    4    4     0     2     0     3     5

            density_function = np.array([
                  [7,7,4,0,0,3,2,3,5], # finger_pianos 
                  [6,4,0,0,0,3,2,3,5], # wood_winds
                  [0,0,0,4,7,4,4,3,5], # pizz_strings
                  [0,0,4,6,6,3,4,3,5], # bowed_strings
                  [0,4,4,0,0,2,2,3,5], # brass
                  [0,0,4,4,0,2,0,3,5]])  # perc_guitar 

            I'll need to find a way to turn these values into splines that fade from one value to another over time, across 256 values
            dmu.build_density_function(ydensity, 256)
      I built everything I thought I would need, but only the pizz and vibrato strings are sounding, and the new_output.csd file has the old 7.0 and 6.0 values for volume. It's like it remembers what I had a few hours ago. Time to go for a walk.

-----------------------------
5/22/23 To do today:

✓     Debug the volume_array. trace the heritave of volume_array:
      woodwind_part has the right values
      finger_piano_part has the right values
      piano_roll_to_notes_features has the right values
      send_to_csound_file has the right features, but new_output has the wrong ones. 
            ls -lth *.csd | head
                  -rw-r--r--. 1 prent prent 747K May 21 15:40 new_output.csd <-- yesterday's date! 
            ls -lth | head
                  -rw-r--r--. 1 prent prent 504K May 22 05:51 ball9.log
                  -rw-r--r--. 1 prent prent 2.1M May 22 05:51 testing.log
      The only two files with today's date are ball9 and testing.log. Why does testing.log have today's date. And why is it full of junk from yesterday? Lots of references to material from bass_flute and bridge_creator. Those are from work I did months ago. I reran one of the notebooks from back then when I was searching for the spline creation routine. But not this morning. 
            783.0 - INFO - bass_flute_note_array.shape = (6, 4, 128)
            785.0 - INFO - bass_flute_notes_features.shape = (20, 15)
            786.0 - INFO - back from bridge_creator. current_notes_features.shape = (336, 15), notes_features.shape = (18614, 15)
            787.0 - INFO - ['bf1' 'bf2' 'bf3' 'bf4']
      2.1 MB of this kind of junk. Something in diamond_music_utils.py has logging debug set wrong. And it might also have the wrong output csd file name. Note that the log levels are all INFO, which none of mine are set there. I'm going to try one more run, and see where it creates the output csd file, then reboot. It created the testing.log file as a 2.1mb file just like before, and did not create any csd output file. I'm going to reboot.
      That fixed it. Wierd.

✓     I suddenly realize the catastrophic problem with volume_array changing every 1/16th note. It causes every 1/16th note to be considered significant in piano_roll_to_notes_features. 
      It has a nice ethereal quality. But it's not worth it. I'll need to change the way I create the volume_array so that each element stays the same for at least 20-30 notes. repeat * 3 or more. 
      I ended up keeping the same volume_array value for 4 * 10 1/16th notes when repeats = 10. I could try 8 * 10 1/16th notes. That would be 80 1/16th notes. That's 5 seconds. That's a long time. I'll try it. (last sentence written by copilot. Neat.)

✓    Clip the volume_array to 0 through 10. I don't trust what csound will do with a negative volume level. 

✓     Remember to double up the ending measures.

✓     I'm not hearing any of the strings, violins. I found the reason:
                  density = array([2, 2, 4, 0, 7, 3, 2, 4, 5])
                  volume_array.shape = (170240,)
                  volume_array[: 20] = array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])
      It never gets to the second phase of the density function. I had forgot the parenthesis around the divisor:
            volume_array = dmu.build_density_function(density, chorale.shape[1] // repeats * sustain)
      Fixed it:
            volume_array = dmu.build_density_function(density, chorale.shape[1] // (repeats * sustain))
                  density = array([2, 2, 4, 0, 7, 3, 2, 4, 5])
                  volume_array.shape = (2640,)
                  volume_array[: 20] = array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])


✓     Too much junk in the print output from the dmu modules. feature = 

4.    There are some wrong notes that slip in sometimes. More and more of them. 
      Need to address this, for it compromizes the whole purpose of the just intonation. It's really bad. It seems like it's in the voices that are created by woodwind_part.
      I think the problem is with the bowed strings with vibrato. I might have to abandon that in favor of the ones without vibrato.

-----------------------------
5/23/23 To do today:

1.   I think I'll find a mismatch between midi numbers and note names in either the brass or woodwinds. The bowed strings seem ok.
     So far I've used inton.mac to check the following instruments:
     ✓ 4 woodwinds
     ✓ 3 brass
     ✓ 3 bowed strings with vibrato
     ✓ finger_pianos
     ✓ pizz_strings 
     ✓ perc_guitar = np.array(["xylp1", "mari1", "vibp1", "harp1", "bgui1", "ebss1", "stri1", "long1"])
     All check out with no missing notes. I'm going to go back and do the first 3 sets with all 12 notes to make sure I didn't miss any.
     Found one wrong note in french horn F# 4. Off by one semitone. Found one wrong midi number on the bassoon on C 3.
     Somthing wrong with viola bowed string vibrato on D#5. It's actually an E5

---------------------------------
5/24/23 To do today:

1.    Fix the np.clip octaves to use the name of the voice.
            for voice in voice_names: 
                  octave_array = np.clip(octave_array, voice_time[voice]["min_oct"], voice_time[voice]["max_oct"]) # clip to the min_oct through max_oct values from the voice_time dictionary
      It used to be hard wired to "fing1". Oops.

2.    Regenerate the a,b,c,d,e,f,g versions and listen to them. Find the best. 
      The ones from yesterday suffered from bowed strings with vibrato where the vibrato got so high it cause the vibrato to be too fast.       

3.    Can't figure out how to get the old profile back in code-server serve-local. I have a problem.
      a.    to use code-server serve I have to be logged into the prodgers13 github account to authenticate the tunnel.
      b.    To use copilot I need to be logged into the prentrodgers github account.
      I can't be on both, or copilot finds my prodgers13 account for the expired trial, instead of my prentrodgers account that is paid.      
      To run with copilot I needed to log off prodgers13 and log in as prentrodgers. Not as simple as you might expect.

4.    I'd like to post the current notebook and util library to github. Done.  

------------------------------------------
5/25/23 To do today:

1.    Fix the maximum octaves for the bowed strings with vibrato so they don't go beyond their max in voice_time. 
      Maybe I need to set the max to the highest midi number. Then I could really take it to it's limit. Except I'm only limiting the octaves here. Too coarse an adjustment. I'll just have to accept a combination of an octave at the max plus a note on the high side of the scale.
            #                                                       +--set this to 87 for the highest midi value / 12 = 7             octave_array = np.clip(octave_array, voice_time[voice]["min_oct"] / , voice_time[voice]["max_oct"]) 
      Bug alert. My whole concept of limiting the octaves is based on a faulty assumption. That is that I can clip the octaves to the min_oct and max_oct values in voice_time in the finger_piano_part and woodwind_part without limiting it to one voice at a time. In other words, in the loop:
            for voice in voice_names: # for each voice, "fing1", "fing2", etc.
                  octave_array = np.clip(octave_array, voice_time[voice]["min_oct"], voice_time[voice]["max_oct"]) # clip to the min_oct through max_oct values from the voice_time dictionary
      I am failing to make sure I'm only affecting one voice at a time, not all the octaves in the chorale. Big problem. The effect is that it clips all the octaves to the least max most min value of all the voices. But at this stage I don't know what voice is assocated with each note. The assignment of voice doesn't happen until later. I think I need to place this capability in one of the following:
            dmu.piano_roll_to_notes_features(notes_features_6, volume_array, voice_names, tpq, voice_time)
            dmu.fix_start_times(notes_features_15, voice_time)
            dmu.send_to_csound_file(notes_features_final, voice_time, CSD_FILE, tempos = 't0 ' + str(tempo), limit = limit, tempo = tempo, print_only = 25) 
      That would require changing those functions, which are baked into other github repos. But they have their own copies of that util function. 
      I think the modification of the volume_array is also affecting all voices.
            velocity_array += voice_time[voice]["volume_factor"] # add the voice_time["volume"] to the velocity. Each voice adds a different value based on voice_time dictionary
      This explains why all the voices tend to mush together. I'm not isolating this volume increase just to the voice to which it should apply, but rather all increases are affecting all voices. It's not apparent because only a few of the voices have actual volume increases in voice_time. I haven't gotten around to tuning that parameter yet, and some are increase, some are decreases.
      I'm reluctant to modify dmu.diamond_music_utils.py if I can avoid it. What if I found a spot in the notebook where I have access to the output of a function that added the voice numbers to the array?
      The output of dmu.piano_roll_to_notes_features:
            #                                      0  1                2       3               4              5           6           7
            #                                      1, dur,           hol,    vel,            note,          octv,      voice,      stereo
            notes_features[output_inx] = np.array((1, duration, hold * 1.01, prev_note[5], prev_note[0], prev_note[1], voice_num, stereo, \
                              # 8               9           10          11          12    13    14
                              # env          gls1         upsample      r env       2nd 3rdgl volume
                              prev_note[4], prev_note[2], prev_note[3], prev_note[4], 0, 0, prev_note[6]))
      What I am concerned about is voice, note, octv, and volume. Those are the output array elements [6, 4, 5, 14]
      At this point voice is the time_tracker_number voice, which is not the final voice. And I have 57 separate time_tracker voice numbers. Each of those point to a dictionary entry with a 

--------------------------
5/26/23 To do today:

1.    I implemented the correct clipping of octaves, but now the finger_piano_part is way too slow. 
      Did I shut off some of the options? Not that I can find. I'm suspecting is has something to do with the clip_note_features function. I'm going to comment that out and see. I commented it out, and the arpeggios aren't arpegiating. I bet there were some other lines that I inadvertently removed from the finger_piano_part. Take a look at the one I saved yesterday. 
      The volume_array calculations were based on a flawed assumption. I did not notice that previously because I inadvertently ignored the volume array, and worked on the velocity component of notes_features_6 instead of the volume_array. My error. 
            after repeating each note repeats = 12: chorale.shape = (4, 3216, 2)
            after doubling voices: chorale.shape = (8, 3216, 2)
            chorale.shape = (8, 3216, 2)
            density = array([7, 7, 1, 3, 1, 1, 1, 4, 6])
            volume_array.shape = (33,)
            after repeat & clip: volume_array.shape = (3168,), repeats = 12, sustain = 8
            notes_features_6.shape = (6, 8, 3216)
      Also, there is no reason to try to move the volume_array into the notes_features_6, that already has the velocity_array. But I will have to make sure to make the volume array a little bigger than I'm doing with the integer division operation here:
            volume_array = np.clip(np.repeat(volume_array, repeats * sustain, axis = 0), 0, 10) # 33 * 8 = 264 * 9 = 23763216/
      this computes to 3168. I need to make it 3216. or more. Why doesn't it throw up in:
            notes_features_15 = dmu.piano_roll_to_notes_features(notes_features_6, volume_array, voice_names, tpq, voice_time)
      It must have something to do with the zip operation:
            for note, octv, glx, upx, envx, velx, volx in zip(verse_array, octave_array, gliss_array, upsample_array, env_array, velocity_array, volume_array):

2.    The log file from the print functions in the newly created clip_note_features(notes_features_15, voice_time needs trimming.
      It has 29,000 lines of output. May have to turn that off. 

      Last voice processed:
            inx = 824, short_name = 'celv2'
            [49.0, 898.0, 3.0, 6.0]
            voice_time[short_name]["min_oct"] = 1, voice_time[short_name]["max_oct"] = 5, voice_time[short_name]["volume_factor"] = 0
            before adjusting the volume by voice_time[short_name]["volume_factor"] = 0, round(notes_features_15[inx,14],1) = 6.0]
            after adjusting the volume round(notes_features_15[inx,14],1) = 6.0, before adjusting octave: notes_features_15[inx,5] = 3.0]
            after adjusting octave: notes_features_15[inx,5] = 3.0, cent value of note: notes_features_15[inx,4] = 898.0]
            inx = 824, [49.0, 898.0, 3.0, 6.0]
            density = array([6, 1, 1, 5, 0, 5, 5, 4, 5])

--------------------------
5/27/23 To do today:

1.    Figure out how important the volume field is. 
      a.    Can I include floating point values. yes
      b.    Why are so many of the notes saved with 0 as volume. 
      c.    Couldn't I just cut them out like I do with 0 octave values? Because they are subject to the density_function, deliberately silencing or attenuating some notes as part of the composition process.
      d.    How come they are still there?
      e.    How important is the volume - the difference between zero and one is profound. At zero it's inadable, at 1 it's perceptible. I think if I set the volume to zero it was for a reason, in that I don't want to hear it at all. If it's zero, don't add the voice_time[short_name]["volume_factor"] to the volume field. And somewhere, find a way to drop it before it gets to csound. Modify clip_note_features so that it checks if the note is zero and if so doesn't add to it. Done. Also added this to dmu.send_to_csound_file:
            notes_features = np.array([row for row in notes_features if row[14] > 0]) # only include those with a non-zero volume values  # 14 is the volume field

2.    The problem with always having a one on the downbeat is the predictability of it. Make it:
            density_function = np.concatenate((np.full((voices, 1), rng.choice(2), dtype = int), density_function), axis = 1) # make sure the down beat is always a one, except when it's a zero just to mess with your head. This is before you repeat it so that it's piece long.
      Fixed it.

3.    I messed up the top_notes. 
      I must have deleted the carefully chosen cent values for the 6 notes. I rebuilt it. But when I tried to run the piece again, the end of the piece is whack. Two big chords all by themselves that I've never heard before. To recover, I restored TonicNet_Csound_adaptive_big_ensemble_strings.ipynb to where it was last night. What have I done since then?
      a.    Modify clip_note_features so that it checks if the note is zero and if so doesn't add to it. Done. 
                  if notes_features_15[inx,14] > 0: notes_features_15[inx,14] += voice_time[short_name]["volume_factor"]
      b.    Also added this to dmu.send_to_csound_file:
                  notes_features = np.array([row for row in notes_features if row[14] > 0]) # only include those with a non-zero volume values  # 14 is the volume field
      c.    density_function = np.concatenate((np.full((voices, 1), rng.choice(2), dtype = int), density_function), axis = 1) # make sure the down beat is always a one, 
      That's all I could think of. 
      d.    density_function = np.array([
                  [8,8,0,2,0,0,0,4,6],  # finger_pianos  0
                  [6,0,0,5,0,5,6,4,5],  # wood_winds     1
                  [0,0,5,0,8,6,0,4,7],  # pizz_strings   2   
                  [0,0,0,0,8,0,0,4,6],  # bowed_strings  3
                  [0,6,6,0,0,4,2,4,7],  # brass          4
                  [0,0,5,8,1,1,8,4,8]]) # perc_guitar  5

4.    I really messed up something in the whole notebook. 
      There are two very loud chorus notes at the end that I didn't put there. I think they might be left over from ball9.csd, but I can't be sure. I put a limit=10 to reduce the output, and they were not there. Trying the whole piece now. Wish me luck. I have never had left over notes in the ball.csd file cause interference in the final verion, so I'm skeptical. I just picked that solution because it was easiest. That wasn't what caused it. The two big notes are back. The notes are C. Could it be something to do with the attempt to pad the end of the piece where I padded?
            chorale = np.concatenate((chorale, np.repeat(chorale[:,-1], repeats, axis = 0).reshape(4, repeats)), axis = 1)
      Did I make any change to that? That sent me in the right direction.
            This is what will be added at the end of the chorale. chorale.shape = (4, 257), chorale[:,-1]= array([0, 0, 0, 0])
      There are those extra zeros. Why is the chorale now 257. It used to be 256 I thought. It was the change to one of the dmu modules.
            read_from_corpus(version)
      It's the conversion from piano roll to sample shape. I made a change to this module:
            muspy_to_sample_root_mode(muspy_object)
      I changed this line:
            time_steps = piano_roll.shape[0] // q16
      This was to get the lasso working. I changed it to:
            time_steps = int(np.ceil(piano_roll.shape[0] / q16)) 
      But it made the sample.shape = (4, 257) instead of (4, 256). I added a check on the end of the module to check if the last note was all zeros and if so, cut it off. That fixed it.:
            if np.sum(sample[-1:] == 0):
                  sample = sample[0:-1,:]
                  print(f'{sample.shape = }') # (256, 4)
            if np.sum(sample[-1:] == 0):
                  sample = sample[0:-1,:]
                  print(f'{sample.shape = }') # (256, 4)
      Twice just to be sure.

---------------------------------------------------------
5/28/23 To do today:

1.    I'm not liking a few different things in the latest version:
      a.    There are still some high strings with vibrato too fast. Is there an upsample in the woodwind_part that I forgot about?
            The upsample is causing trouble. Tested it in isolation:
                  Negative upsamples take a lower sample and play it at a higher pitch than expected, resulting in very fast vibrato. 
                  Positive upsamples take a higher sample, if available, and playing at a lower pitch than expected, resulting in a slower vibrato.
                  Recommendation, don't use negative upsamples, positives should work fine, except when they don't. If the pitch is high, csound can't find a higher sample, so I just play the low pitch too fast. There's your trouble. How to fix it? If an octave and a pitch would cause this effect, drop it an octave and it won't happen.
            Hang on, I just noticed that I had commented out the check on octaves in woodwinds_part:
                  notes_features_15 = clip_note_features(notes_features_15, voice_time) # make sure the octaves are in range and the volume adjusted per the voice_time dictionary. Doh!
      b.    The density_function, now renamed as volume_function, does a blend of different finger_piano_part instruments, so for a large amount of time it has two instruments playing at once. That causes the ticky-tacky effect. I'll need to minimize the overlap somehow, or separate the sections with zeros. Or influence the density_function that sets the probability of zero vs one to multiply by the octave_array and create sparseness. 
      I'd like to be able to see a chart with overlapping instruments using matplotlib. Trace how it changes over time:
             volume_fuction = np.array([
                  [8,8,0,2,0,0,0,4,6],  # finger_pianos  0
                  [6,0,0,5,0,5,6,4,5],  # wood_winds     1
                  [0,0,5,0,8,6,0,4,7],  # pizz_strings   2   
                  [0,0,0,0,8,0,0,4,6],  # bowed_strings  3
                  [0,6,6,0,0,4,2,4,7],  # brass          4
                  [0,0,5,8,1,1,8,4,8]]) # perc_guitar    5
      Each one gets passed independently to the finger_piano_part or woodwind_part as volume_fuction[n]. In the function it sets the volume for this instrument to a spline conversion of the passed element of the volume_function. Make it a bit longer than needed and trim it. At this point grows to 33 elements long, when it started out as 9. This allows me to keep the level at a certain value for a longer period, which prevents the effect of having a different value for every note. The variable sustain (8) is how many repeats (12) I want to keep the same value in the spline. I have not yet experimented with higher or lower values of sustain. If sustain is lower, there are more steps in the stair, each one a smaller change. If sustain is higher, then it stays in place longer, and each change is bigger. 
            volume_array = dmu.build_density_function(volume_function, int(np.ceil(chorale.shape[1] / (repeats * sustain)))) 
      This creates a stair step effect when I repeat it next.
            after doubling voices: chorale.shape = (8, 3216, 2)
            volume_function = array([8, 8, 0, 2, 0, 0, 0, 4, 6])
            in fingerpiano_part. volume_array.shape = (34,)
            after repeat & clip: volume_array.shape = (3216,), repeats = 12, sustain = 8
      Now we have the stair step volume_array, as designed. Are the stairs the right shape? What if I made them exactly twice as long as the original volume_function array. It's 9 right now. That could be changed, it's just arbitrary. How long would it have to be to have one stair step between each of the values in the volume_function. That would be 9 * 2 - 1 = 17 steps. That's a terrible number for rhythm. What if it were 5 steps. 5 * 2 - 1 = 9
      I'm going to concentrate on optimizing the value for sustain. 8 causes too many steps, so if I make it higher, there will be fewer, larger steps. Try 12, that makes 23 steps. 
            in finger_piano_part. volume_array.shape = (23,)
            after repeat & clip: volume_array.shape = (3216,), repeats = 12, sustain = 12
      Try 14. That makes 20 steps, looking for 17 as the ideal. Try 15.
            in finger_piano_part. volume_array.shape = (20,)
            after repeat & clip: volume_array.shape = (3216,), repeats = 12, sustain = 14

2.    I remember that the woodwinds end before the finger_piano_part in the whole piece. 
      That was because the volume_array was shorter than it should have been for the woodwind_part. I transfered the changes made to the finger_piano_part to the woodwind_part. That fixed it.

3.    So I could stop the percussion or the woodwinds_part early, just by assigning a subset to itself:
            volume_array = volume_array[:-24] # truncate it to just short of the lenth of the chorale, let the winds finish on their own.
-----------------------------------------
5/29/23 To do today:

1.    Try more of the getting lasso to work. 
      There is something odd about that MIDI file. It doesn't process correctly. It might have some extra data that my processing can't handle.

2.    Try some more chorales. I did versions of # 11, 14, 15. I've done 14 many times. 

3.    Before I do any more, fix a few things that bug me:
      a.    The woodwinds_part should be more sparse. I thought I did that already, but maybe it's not working. There's no space.
      b.    Shuffle some of the arrays, including the following:
            1.    volume_function - make it so the order of the 8,8,0,2 dimension is random, but the other values have to follow it. I think there is a way to do that with the axis, but I don't remember how. Ask my copilot, and he came through. 
                  volume_function = np.array([
                  [8,8,0,2,0,0,0,4,6],  # finger_pianos  0
                  [6,0,0,5,0,5,6,4,5],  # wood_winds     1
                  [0,0,5,0,8,6,0,4,7],  # pizz_strings   2   
                  [0,0,0,0,8,0,0,4,6],  # bowed_strings  3
                  [0,6,6,0,0,4,2,4,7],  # brass          4
                  [0,0,5,8,1,1,8,4,8]]) # perc_guitar  5
                  volume_function = volume_function[:,np.random.permutation(volume_function.shape[1])]
            2.    order of the guev_array in the finger_piano_part. I did it before, but it was wrong. I should have used axis = 1 instead of 2.
                        rng.shuffle(guev_array, axis = 1)
            3.    What else? check that the woodwinds_part build_long_mask has the right odds of picking a zero over a one. print(f'{prob_silence = }'). I set it just a bit too low.

-------------------------------------------------
5/30/23 To do today:

1.    Make the repeats a random value between 8 and 16:
            repeats = rng.integers(8,high=16) # how many times to repeat the chorale, highest can be up to 15, lowest 8

2.    I noticed that I no longer end on the volume function at it's peak. The peak can appear anywhere now. Fixed it:
            end_value = volume_function.T[-1].reshape(-1,1)
            volume_function = volume_function[:,np.random.permutation(volume_function.shape[1] - 1)]
            volume_function = np.concatenate((volume_function, end_value), axis = 1)
            print(f'{[np.sum(vol) for vol in volume_function.T] = }')
                  [np.sum(vol) for vol in volume_function.T] = [16, 16, 15, 17, 24, 16, 14, 14, 39] # <-- last one is the peak value.

3.    I'm wishing for more variety in the rhythms for the finger_piano_part. 
      There are four different rhythms, each determined by the variable probs, passed in by the call to finger_piano_part. The least I could do is mix them up, but I could also change the likelihood odds.
            probs = [[.05, .95],[.03, .97], [.07,  .93], [.2, .8]] # finger_piano_part likelihood of sounding a note - 95% chance of 1, 5% chance of 0
            That's backwards. Then why is the finger piano so sparse? I thought I was making it more sparse, when in fact I was making it more dense. 
            density_function = np.array([rng.choice(2, size = (voices, (repeats // 2) - 1), p = prob) for prob in probs]).reshape(8, -1) # This will be used over and over again throughout the piece.
      I changed it to be just the opposite of what I had, and it made no difference. I'm getting the feeling that it's not using the density_function at all. It's using something left over from a previous run. So I ran it both ways and didn't see any difference in the audio. It's like the octave array isn't actually changing. But it shows a much different sum. Here is the sum when the probs are 
            ball9-tbwv245.28a
            probs = [[.05, .95],[.03, .97], [.07,  .93], [.2, .8]] # mostly ones
                  before masking: np.sum(octave_array) = 60867
                  about to mask the octave array with the density_function: density_function[:, :octave_array.shape[1]].shape = (8, 2385)
                  after masking. np.sum(octave_array) = 54249
            ball9-tbwv245.28b
            probs = [[.95, .05],[.97, .03], [.93,  .07], [.8, .2]] # mostly zeros
                  before masking: np.sum(octave_array) = 101100
                  about to mask the octave array with the density_function: density_function[:, :octave_array.shape[1]].shape = (8, 4065)
                  after masking. np.sum(octave_array) = 13705
            So it's definitely masking more. 
      I think I'm getting a handle on how this works. Because there are so many voices, I can get away with much fewer probabilities for each note individually, since probabalistically, with 24 instruments, playing 16 notes per measure, that's a lot of players and notes. So I should just reduce the probability by 4 from what I would normally expect.
            probs = np.array([(1 - prob, prob) for prob in np.array([.01, .02, .04, .08])]) # how likely is the finger_piano_part to be non-silent
            probs = rng.permutation(probs, axis = 0) # permute it 
            print(*probs)

      Now that I've reduced the finger_piano_part, I need to make the woodwinds_part similarly sparse. 


4.    Vary the tempos.

---------------------------------------------
5/31/23 To do today:

1.    Link the tempo choice with the previously selected variable repeats. 

2.    What's up with the negative cent values in the report?
            240   ['C♮', 'G♮', 'E♭', 'C♮'] [-16 686 300 -16]
      How does that get through? It assumes it's a C♮, which is good. It's all just ephemeral that's generated in the rep[ort, which is just a cell in the ntoebook. Actually, it's stored in chord_1200, which is zipped from chorale_in_cents[:,:end_chord,0].T
      And that in turn comes from:
            chorale_in_cents = atu.midi_to_notes_octaves(chorale, top_notes, tonal_diamond, ratio_factor = ratio_factor, dist_factor = dist_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12)
      And that in turn comes from this:
            improve_chord_rolls(chord, top_notes, chord_number - 1, tonal_diamond_values, dist_factor = dist_factor, ratio_factor = ratio_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12)
      Which in turn comes from either this:
            result = find_intervals(np.roll(best_choice,inx), tonal_diamond_values, ratio_factor = ratio_factor, dist_factor = dist_factor) 
      or this: 
            final_result, best_score = try_permutations(initial_chord, tonal_diamond_values, 70, original_12 = original_12) 
      Both use this method to find the right cent value:
            best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2] * ratio_factor)
      Perhaps I could fix the output of this function so that it would not be zero, best_choice_overall % 1200.
      Like this:
            best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2] * ratio_factor) % 1200
      That was insufficient. It's still creating the -1 cent values.

3.    Try this out on the ipad. https://vscode.dev/tunnel/toolbox - Fails on Edge on the iPad, but works for a while on Safari. But not the jupyter notebook. I can edit files, but not open a notebook. Correction, it just takes a minute longer to open it. But it's very cludgey

-----------------------------------------
6/1/23 To do today:

1.    Find a few of the best pieces from the last three days and post them to ripnread.com as an album.
      a.    ball9-tbwv245.14f.mp3 - 1:30 very short, but sweet nice contrast with the long pieces. [player id='2478']
      b.    ball9-tbwv245.28b.mp3 - nice dancing kind of piece. Call it a Gigue.
      c.    ball9-tbwv245.3b.mp3 - Call it a Sarabande. There's a b version. It's kind of dreamy. Sweet.
      d.    ball9-tbwv245.37d.mp3 - repeats = 14, tempo = 108, 9 minutes - nice opening reverse envelopes.
      e.    ball9-tbwv245.11a.mp3 - fast 6:12
      f.    ball9-tbwv245.5b.mp3 - repeats = 9, tempo = 62, 7:19 smooth slow tango like
      g.    ball9-tbwv245.40b.mp3 - 11:22 - dreamy - lots of phases.
      h.    ball9-tbwv245.26b.mp3 - repeats = 15, tempo = 116 8:47
      i.    ball9-tbwv245.22b.mp3 - 6:40 - repeats = 10, tempo = 76
      j.    ball9-tbwv245.17b - 6:03 repeats = 13, tempo = 102
      k.    ball9-tbwv245.15b - 12:37 repeats = 10, tempo = 56
      l.    ball9-tbwv245.14b.mp3 - 8:07 - fast starts with pizzicato strings, then electric guitars, strings, orchestral
            http://ripnread.com/listen/ball9-tbwv245.14f.mp3 [player id='2478']
            http://ripnread.com/listen/ball9-tbwv245.28b.mp3 [player id='2479']
            http://ripnread.com/listen/ball9-tbwv245.3b.mp3 [player id='2480']
            http://ripnread.com/listen/ball9-tbwv245.37d.mp3 [player id='2481']
            http://ripnread.com/listen/ball9-tbwv245.11a.mp3 [player id='2482']
            http://ripnread.com/listen/ball9-tbwv245.5b.mp3 [player id='2483']
            http://ripnread.com/listen/ball9-tbwv245.40b.mp3 [player id='2484']
            http://ripnread.com/listen/ball9-tbwv245.26b.mp3 [player id='2485']
            http://ripnread.com/listen/ball9-tbwv245.22b.mp3 [player id='2486']
            http://ripnread.com/listen/ball9-tbwv245.17b.mp3 [player id='2487']
            http://ripnread.com/listen/ball9-tbwv245.15b.mp3 [player id='2488']
            http://ripnread.com/listen/ball9-tbwv245.14b.mp3 [player id='2489']

-------------------
6/2/23 To do today:

1.    Update the github with the latest code and links to some examples. Cross link the examples to the github page. Done.

-------------------
6/3/23 To do today:

Long term ideas:
1.    Make it possible to play the keyboard and hear my automatic just intonation code with live performance. 
      a.    MIDI input to csound
      b.    Touch sensitive Bosendorfer piano samples with csound
      c.    Just intonation by python function tailored to live performance rather than a batch of 256 chords.
      
2.    Use the transformer models to predict the next chord using the Bach chorales as the model. Check out this from papers with code:
      https://github.com/microsoft/muzic
      Museformer 2210.10349v2.pdf in the TonicNet directory.
      Interesting concept, but the output is for shit. Dreary MIDI synthesized crapola. 
      Talking dog feel. But they post their code, and I can take their work and use it against the Bach chorpus in Music21. 
      I started to work on it, but immediately ran into a hurdle, could not install the prerequisite MidiProcessor, which is used to take a midi file into tokens of different styles. Opened an issue, but I don't have any real expectations. 
            https://github.com/btyu/MidiProcessor/issues

3.    Take another try at Ave_Regina_coelorum_Lasso.mid or another MIDI file that may be more amenable. 
      Ave Regina coelorum by Orlando di Lasso
      Found a different version here: Ave_Regina_coelorum_Lasso.mid or Ave_Regina_coelorum_Lassus.mid They are the same file different name. I suspect that I'll have the same trouble with both. Try this one from the TonalSoft page: lassus-vicentino.mid. That one has the tuning bends built into the MIDI file. But I was able to use it to generate my own tuning. Sounds good, but of course I killed the comma pump on purpose by anchoring some notes.
      I finished the work, but frankly I don't get the attraction to this piece. 

4.    Try to get a start on item #1 above. What can I accomplish in just one day?
      a.    Try to get midi input to csound.
                  https://csound.com/docs/manual/MidiTop.html
            You can find out the available devices by running Csound with --midi-devices option:
                  csound --midi-devices
                        0dBFS level = 32768.0
                        --Csound version 6.16 (double samples) Jan 19 2023
                        [commit: none]
                        libsndfile-1.1.0
                        rtmidi: ALSA Raw MIDI module enabled
                        rtaudio: pulseaudio module enabled
                        rtalsa: Wrong callback.
                        0 MIDI input devices  <-- that's not a good sign. May have something to do with running in WSL
                        0 MIDI output devices
                        rtalsa: Wrong callback.
            Ran it on the Windows side and it found it: "C:\Program Files\Csound6_x64\bin\csound.exe"
                  csound --midi-devices
                        rtaudio: PortAudio module enabled ...
                        using callback interface
                        rtmidi: PortMIDI module enabled
                        1 MIDI input devices
                        0: 0 (LPK25) <-- That's my keyboard. A good sign. Working on channel 1.
                        3 MIDI output devices
                        0: 0 (Microsoft MIDI Mapper)
                        1: 1 (Microsoft GS Wavetable Synth)
                        2: 2 (LPK25) 
            How about on real Linux?
                  csound --midi-devices
                        libsndfile-1.1.0
                        rtaudio: pulseaudio module enabled
                        rtmidi: ALSA Raw MIDI module enabled
                        rtalsa: Wrong callback.
                        0 MIDI input devices <-- That's not good. I have a MIDI keyboard plugged in.
            More on midi live to csound here: https://www.csounds.com/manual/html/MidiTop.html
                   cat /proc/asound/cards
                        +-- what port is it using. Use this in teh -M hw:n in the call to csound below
                        |                    +-- where is it coming from
                        |                    |           +-- what is the name of the midi keyboard
                        0 [LPK25          ]: USB-Audio - LPK25
                        AKAI professional LLC LPK25 at usb-0000:00:14.0-7.2, full speed
            Then call csound like this:
                          +-- real time midi on linux
                          |             +-- tell me the device that midi is coming from, in this case it's hardware on port 0
                          |             |       +-- supress the real time event messages
                          |             |       |  +-- name of the csound file to process.
                  csound -+rtmidi=alsa -M hw:0 -m0 notnum.csd
            It worked! I can play the keyboard and hear the notes.
--------------

            Install libraries using pip is different on Windows. You have to open a terminal with administrator privilages, or this way:
                  pip install numpy --user
                  python 
                        import numpy as np
                        >>> print(np.__version__)
                        1.24.3
                        >>> quit()
                  If you want to use ctcsound, you need to do it in the command terminal, or restart code to pull in the current environment. Worry about that later.
            Back to the csound-midi interface page.      
            Use the -M0 where 0 is the midi input device number from the midi-devices query. -F read a file. Behaves like -M. csound doesn't know the difference.
            When MIDI input is enabled (with -M or -F), each incoming noteon message will generate a note event for an instrument which has the same number as the channel of the event (This means that MIDI controlled instruments are polyphonic by default, since each note will generate a new instance of the instrument.) If you have 1 instrument only, Csound works in omni mode, ie. it responds to all channels into that single instrument. If you have more than one instrument and instrs 1 - 16 , then by default instr 1 -> chn 1, instr 2 -> chn 2, unless you alter the mapping (see massign and pgmassign to change this behavior). For a single port input, if you have more than one instrument, but instr N in between 1 - 16 is missing, then chn N will be routed by default to the lowest order instrument.
            Tell Csound to run that amount of time by using the dummy f-statement like "f 0 360".
            Need to install some plugins: https://github.com/csound/plugins - this is the code, but not how to use it.
            https://csound-plugins.github.io/csound-plugins/Installation.html has the docs.
            I was able to get the keyboard to interact with virtual.csd, but it's nothing like what I'm looking for.
            For windows the plugins are here: 
                  C:\Users\prent\AppData\Local\csound\6.0\plugins64 
            I had to make those directories, which doesn't give me much confidence that csound will use it.
            The standard plugins included with a csound installation are here:
                  C:\Program Files\Csound6_x64\plugins64
            Where are the python plugins supposed to be installed on windows?

            My windows version is --Csound version 6.18 (double samples) Nov 23 2022
            I installed all the .dll style plugins, but none seem to be related to real time midi or python:
                  dir C:\Users\prent\AppData\Local\csound\6.0\plugins64\*.*
                        Volume in drive C is Windows
                        06/03/2023  02:29 PM            45,568 beosc.dll <-- band enhanced oscillators sine+noise sythesis model
                        06/03/2023  02:29 PM            98,304 else.dll <-- miscellaneous
                        06/03/2023  02:29 PM            60,928 klib.dll <-- create a hashtable
                        06/03/2023  02:29 PM            18,432 pathtools.dll <-- cross platform path handling
                        06/03/2023  02:29 PM            24,576 poly.dll <-- multiple parallel versions of an opcode
            Seem kind of useless. In the else.dll there is zerocrossing, which might help tuning. They say it's a "crude" pitch follower.
            Csound will tell me several things about the MIDI key press:
                  The following opcodes can receive MIDI information:
                  MIDI information for any instruments: aftouch, chanctrl and polyaft, pchbend.
                  MIDI information for MIDI-triggered instruments: veloc, midictrl, midichn and notnum. See also Converters.
                  MIDI Controller input for any instrument: ctrl7, ctrl14 and ctrl21.
                  MIDI Controller input for MIDI-triggered instruments only: midic7, midic14 and midic21.
                  MIDI controller value initialization: initc7, initc14, initc21 and ctrlinit.
                  Generic MIDI input: midiin.
                  massign can be used to specify the csound instrument to be triggered by a particular MIDI channel. pgmassign can be use to assign a csound instrument to a specific MIDI program.
            I also could turn it inside out, have csound call my python modules. That could be done with the python plugin to csound.
            But how do I install it? I think I'll need to do something else to get this working with my live midi keyboard.
            The only reference to installation is in the mailing list, and I can't get access to it at the moment. But the expert Francoise PINOT says: 
                  The py opcodes have been ported to Python 3.x. They are here:
                  https://github.com/csound/plugins. You can clone the repository on your
                  system and build the py plugin following the instructions in the py
                  README.md file. Once the plugin is built, you can copy it into the plugins
                  directory of Csound where it will replace the plugin of the py opcodes for
                  Python 2.7 (both plugins have the same name). This process should be
                  integrated in Csound7.
-----------------------------
Create a virtual python environment on Windows:
            python3.11 -m venv virtual_python3.11
            C:\Users\prent\virtual_python3.11\Scripts\activate.bat
      This is equivalent to linux:
            source virtual_python3.11/bin/activate
----------------------------
6/4/23 To do today:

0.    Duplicate what I learned yesterday. Just a csound csd that can accept MIDI and play music:
            csound -+rtmidi=alsa -M hw:0 -m0 notnum.csd
      Works. Plays for 20 seconds and then goes away.

1.    Get ctcsound loaded by python. First thing to do is find the ctcsound.py module.
      Get python to sucessfully import ctcsound. Right now it's not finding it. 
            python
            Python 3.11.3 (main, May 24 2023, 00:00:00) [GCC 13.1.1 20230511 (Red Hat 13.1.1-2)] on linux
            >>> import ctcsound
            Traceback (most recent call last):
            File "<stdin>", line 1, in <module>
            ModuleNotFoundError: No module named 'ctcsound'
      Where has csound-devel put the ctcsound.py. 
            find / -name ctcsound.py 2>/dev/null
                  /run/host/home/prent/csound/interfaces/ctcsound.py
                  /run/host/usr/lib64/python3.11/site-packages/ctcsound.py
                  /usr/lib64/python3.11/site-packages/ctcsound.py
                  /home/prent/csound/interfaces/ctcsound.py
            locate ctcsound.py
                  /home/prent/csound/interfaces/ctcsound.py
                  /usr/lib64/python3.11/site-packages/ctcsound.py
      What if I point directly to where csound has put it?
            import sys
            sys.path.insert(0, '/home/prent/csound/interfaces')
            import ctcsound
                  failed:
                        File "/usr/lib64/python3.11/ctypes/__init__.py", line 394, in __getitem__
                        func = self._FuncPtr((name_or_ordinal, self))
      or
            import sys
            sys.path.insert(0, '/usr/lib64/python3.11/site-packages')
            import ctcsound
      That worked! Now, we need ctcsound to do something. 

2.    Created read_midi_ctcsound.py
      https://csound.com/docs/ctcsound/ has the docs.
      a.    Created a csd file process_midi_keys.csd that could read midi keyboard input and play it.
      b.    Adapted that csd file so it could be called by ctcsound in a python module called process_midi_keys_ctcsound.py
      c.    create a new csd file called read_midi_ctcsound and python program so that it can use the ctcsound midi keyboard interfaces.
      d.    clone the ctcsound repo and use the notebooks therein. 
                  git clone https://github.com/csound/ctcsound

      e.    ctcsound/cookbook/07-icsound.ipynb is very interesting. It includes a way to plot tables with matplotlib. That would have been handy over the years. Especially when combining multiple glissandi tables on a single note. 
            

3.    Get ctcsound to read the MIDI keyboard as input from a python function.
            midiDevList(isOutput) # <-- this is a good sign
            Returns a list of available input or output midi devices.
      Some more functions that involve midi:
            setExternalMidiErrorStringCallback(function)
                  Sets a callback for converting MIDI error codes to strings.
            setExternalMidiInCloseCallback(function)
                  Sets a callback for closing real time MIDI input.
            setExternalMidiInOpenCallback(function)
                  Sets a callback for opening real-time MIDI input.
            setExternalMidiOutCloseCallback(function)
                  Sets a callback for closing real time MIDI input.
            setExternalMidiOutOpenCallback(function)
                  Sets a callback for opening real-time MIDI input.
            setExternalMidiReadCallback(function)
                  Sets a callback for reading from real time MIDI input.
            setExternalMidiWriteCallback(function)¶
                  Sets a callback for reading from real time MIDI input.
            setFileOpenCallback(function)
                  Sets a callback for receiving notices whenever Csound opens a file.

            Each item in the list is a dictionnary representing a device. The dictionnary keys are device_name, interface_name, device_id, midi_module (value type string), isOutput (value type boolean).

            Must be called after an orchestra has been compiled to get meaningful information.

4.    Outline of the program structure
      a.    Compile the performance csd file and get it ready to play. ball10.csd is what I plan to use.
            Completed today.
      b.    read midi notes from the keyboard using ctcsound python midi functions 
                  setMIDIInput(name)
                        Sets MIDI input device name/number.

                  setMIDIModule(module)
                        Sets the current MIDI IO module.
                  
                  setMidiDevListCallback(function)
                        Sets a callback for obtaining a list of MIDI devices.
                        This should be set by IO plugins and should not be set by hosts


      c.    convert the midi numbers to scale, octave, velocity, and channel (not sure about channel)
            if a note is on, generate one 1/16 note for every time period that the note is on. 
            When it turns off, end the note and start transmitting a zero on that channel
      d.    A tuning function takes those scale, octave, velocity, channel and translates them into cent, octave, velocity, and channel
      e.    An aleatoric algorithm function takes those 1/16th note items and formats them into csound notes with all 15 features
      f.    A csound performance function takes those 15-feature notes and plays them through csound to a dac stereo output channel.
      g.    After a predefined time period, the program ends. 

-----------------------------------
6/5/23 To do today:

1.    Get the a csd file that can read midi running inside ctcsound able to transfer the midi note information to python. 
      Make that out of this: ctcsound-threading.ipynb
      Create a second thread that is ready to accept score events, using the threading notebook as a model. That one exists and works as ctcsound_play_notes.ipynb which reads in ball10.csd with the large ensemble samples ready to play.

----------------------------
6/6/23 To do today:

1.    Why couldn't I have a single csd with multiple instruments: One for midi and the other for performance. Take a look at the other cookbook entries for more efficient ways of communicating between csound and python.

2.    See example 7 through 10 in 08-ctcsoundAPIExamples.ipynb for ways to communicate between csound and python.

--------------------------
6/7/23 To do today:

1.    Since you forgot the keyboard, how about going baack to the TonicNet_Csound_Just.ipynb and making it much more sparse. 
      Listening to it on the train on the Sony headphones, it sounds much more dense than it did on the Marathon headphones. Never mix with cans.
      And the bass is far too dense and muddled. How can I set the density down, and the bass finger piano more sparse. The high notes are fine, it's just the bass that I need to temper. How are the densities set:
            def finger_piano_part(chorale, repeats, voice_names, voice_time, tpq, volume_function, probs = [[.1, .9],[.05, .95], [.15,  .85], [.4, .6]] ):
      probs sets the repeating pattern for each several repeats. Decreasing all these numbers will result in fewer notes.
            octave_alteration_mask = atu.build_octave_alteration_mask(repeats, voices, chorale, octave_reduce = 3) # set the octave alteration. octave_reduce controls the maximum lowering of the octave. I could set this to 2, and it would have less bass, more treble, but maybe just move the muddle up an octave, and it would still be a muddle. 
            def build_octave_alteration_mask(repeats, voices, chorale, \
            octave_stretch = 4, p1 = [.2, .3, .3, .2], octave_reduce = 2, stay = 7, \
                  p2 =  [.1, .1, .2, .2, .2, .1, .1]):
      There is also octave_stretch = 4, which if I increase it to 5 will make the octaves more spread out. If I combine octave_reduce = 2, and octave_stretch = 5, I might get a more sparse bass and just as much high notes, maybe more. But combine this with a reduction in probs. Probs is overridden in the call to finger_piano_part. Make that change first, before changing the woodwinds_part

            def woodwinds_part(chorale, repeats, voice_names, voice_time, tpq, volume_function, mask = True, prob_silence = [.5, .5]):

      I increased octave_reduce in the woodwinds_part to 3 and it made it too low. Changed it back to 2.

2.    The small change to octave_stretch from 4 to 5 has caused a problem. 
      I had tuned the probability to be [.2, .3, .3, .2] which worked well for 4 different octaves. But when we have 5 octaves we need five alternatives that sum to 1.0. And I want it to be slanted towards the middle and not the bottom. What I'd like is [.1, .2, .3, .2, .1] but that doesn't sum to 1.0. So I'll try [.1, .2, .3, .2, .2] and see how that works. 

3.    I'm still amazed that the woodwinds_part has so many notes. I have the prob_silence set to 
            prob_silence = [.995, .005]
      in call to octave_silence_mask = atu.build_long_mask
            p1 = prob_silence
            in build_long_mask. p1 = [0.995, 0.005]
            print(f'{np.mean([rng.choice(2, p = p1) for _ in np.arange(10000)])}')
                  0.0048
            print(f'build_long_mask created {np.mean(octave_silence_mask)}')
            in build_long_mask. p1 = [0.995, 0.005]
            after chopping off mask. np.mean(octave_alteration_mask) = 0.0
            after rolling mask. np.mean(octave_alteration_mask) = 0.0
            build_long_mask created 0.0
      So at the end of build_long_mask the array is full of mostly zeros, as it is supposed to be. 
      Then at the end of woodwinds_part the octave_array is also full of mostly zeros:
            before multiplying by octave_silence_mask: np.mean(octave_array) = 2.9375
            after multiplying by octave_silence_mask: np.mean(octave_array) = 0.0     
      I found the problem. octave_array is never moved to the notes_features_6[] array
            octave_array = octave_array * octave_silence_mask # this is the last we hear of octave_array. It disappears.
            notes_features_15 = dmu.piano_roll_to_notes_features(notes_features_6, volume_array, voice_names, tpq, voice_time)
      Look at what happens at the end of finger_piano_part:
            notes_features_6[1] = octave_array 
      I put that into the woodwinds_part and now we have much reduced long notes. But they are too low. 

4.    Why is the piece so short? I was getting 12-15 minute pieces and now they are less than 3 minutes. 
      May be a good thing, who knows. Now it's up to 4:19:
            brass_section:  ('trmp1', '00:04:19.452')         
      I suppose it could be the #11 is shorter perhaps.

5.    On the train I was able to create a whole new set of pieces, two per chorale. Pick the best of the two (or more) and build a playlist and zip them on Windows and post them to Substack.

-----------------------------------
6/8/23 To do today:

1.    Go for a walk and listen to all the pieces you created last night:
            # bwv245.11 ✓  abcde
            # bwv245.14 ✓  abc
            # bwv245.15 ✓  ab  
            # bwv245.17 ✓  cd
            # bwv245.22 ✓  cd
            # bwv245.26 ✓  cd
            # bwv245.28 ✓  cde
            # bwv245.3 ✓   cd
            # bwv245.37 ✓  ef
            # bwv245.40 ✓  de
            # bwv245.5 ✓   cd
2.    Got vscode on the web working under WSL https://vscode.dev/tunnel/thinkcentre2/c:/Users/prent            
Also have it running through a tunnel to vscode running on debian on Chromebook. Still has that Connecting to thinkcentre2 in the lower right corner. And the web version is toast, except connecting on Edge on Windows 11.

---------------------------------
6/9/23 To do today:

1.    Fix the broken TonicNet_Csound_Just.ipynb. 
      Something happened that deleted one of the cells in the notebook, which made it not work. It was the cell that set the version, mod, loaded the music21 file, and other critical things. I can't imagind what happened. It must have been when I was working on the train. Or sometime after when I was traveling. Regardless, I think I fixed it by going back to Dropbox copies. 

2.    Something is cutting off the wave file prematurely. Again, that wasn't happening on the train ride. 
      But it's happening now. It could be in the sox trim, or in the convolv. The wave file ends in a very conventional way, just stopping the playing. The convolv file has the cutoff at the end. So it's in the convolve process. Somehow the 1600 duration got clobbered, and so the sed routine couldn't find it to replace it with the actual time in cents. I fixed it. 

3.    Change the density to be variable. 
        
      finger_piano_part uses probs
            repeats = 11, tempo = 98
            probs = np.array([(1 - prob, prob) for prob in np.arange(.01, np.array(rng.uniform(low = 0.1, high = 0.3)), .03)])
            probs = array([[0.87, 0.13],
                  [0.99, 0.01],
                  [0.93, 0.07],
                  [0.9 , 0.1 ],
                  [0.96, 0.04]])
      The woodwinds_part uses prob_silence. Now it can be as low as 93% or as high as 97%
            max_silence = rng.uniform(low = 0.93, high = 0.98) # was 0.95
            prob_silence = [max_silence, 1 - max_silence] 
                  prob_silence = [0.9528439041592578, 0.04715609584074221], 

------------------------------
6/10/23 To do today:

1.    Streamline TonicNet_Csound_Just.ipynb. 
      Make it so that I can call it from one place, instead of having to execute mulitiple cells. Consider turning it into a python script. 

------------------------------
6/11/23 To do today:

1.    Figure out the optimum value for quantizer. I've tried 2,4,6. 
      The fact that this changes the sample dimension clarifies the challenges I had last week with all the pieces being shorter than previous attempts. In the intervening time, I was trying to get the Lasso madrigal midi file to process correctly. That resulted in samples with a dimension twice as long, as if I had set repeats set to a much higher value than was using. 
      I need to find a way to choose the value for quantizer that results in the smallest sample dimension, without losing notes. What quanitizer does is affect how many of the piano roll notes are skipped. I derive the q value from the muspy music object. It's typically 24.
            def muspy_to_sample_root_mode(music, quantizer = 4):
                  q = music.resolution # quarter note value in this midi file. Default resolution is 24. 
                  q16 = q  // quantizer # the default is usually too high by some factor and can be reduced. 
      The question is how much (quantizer) to reduce it.
      Some initial test runs:
            # quantizer = 6, q16 = 4, skip 3 out of 4 time steps results in sample.shape = (384,4)
            # quantizer = 4, q16 = 6, skip 5 out of 6 time steps results in sample.shape = (256,4)
            # quantizer = 2, q16 = 8, skip 7 out of 8 time steps results in sample.shape = (128,4)
      My instict tells me that a sample size of 128 compresses out some notes.
      I've isolated the piano roll as a numpy file:   
            np.save('piano_roll.npy', piano_roll) # this is in adaptive_tuning_util.py pull it out after you figure out the quantizer
            piano_roll = np.load('piano_roll.npy') # this is in the notebook so you can experiment with quantizer. Minimize the size without compressing out notes.
      It looks like if I just know how many measures, and how many 1/16th notes in each measure, I can pick the right quantizer. I know that the music object contains a method to get the resolution: q = music.resolution. What else can I obtain from the music object?
      music.beats returns a list of beats. What does that look like? Just a beat for every beat in the 1537 time_steps. beats = [Beat(time=0), Beat(time=24),..., Beat(time=1536)]
      I know the 
            music.time_signatures[0].numerator 
      which allows me to print the 
            time signatures: 4/4
      time_steps / resolution = 64. That's not relevant. 
      What I learned from setting the quantizer to different values:
            quantizer = 1, q16 = 24, time_steps = 65
            quantizer = 2, q16 = 12, time_steps = 129
      There are 16 measures, and each measure has 16 1/16th notes. so that makes 256 time steps to get all the notes. Then why are there some spurious notes in the first measure? I hear a dotted eighth and sixteenth note in the 4th quarter note in the first measure. There are lots of them. If I increase the quantizer, do they go away? No, it just gets slower.
            quantizer = 4, q16 = 6, time_steps = 257 <-- this might be the safest on the choose. 16 * 16 = 256
            quantizer = 6, q16 = 4, time_steps = 385 
            quantizer = 8, q16 = 3, time_steps = 513
            quantizer = 12, q16 = 2, time_steps = 769
            quantizer = 24, q16 = 1, time_steps = 1537

2.    New problem. I set the quantizer to 6 and it produced:
            chorale.shape = (4, 384), root = 3, mode = 'major'
      But when it hit the next cell, it was 257. It's because the corpus is read again in 
            initialize_chorale_and_instruments(version)
      Change it to:
            def initialize_chorale_and_instruments(chorale, root, mode, version, ...)
      That fixed it.
            
3.    Create another album based on the fixes implemented recently - replace the previous set.
            # bwv245.11 ✓  cd
            # bwv245.14 ✓  cd
            # bwv245.15 ✓  cd
            # bwv245.17 ✓  cd
            # bwv245.22 ✓  cd
            # bwv245.26 ✓  cd
            # bwv245.28 ✓  cd
            # bwv245.3 ✓   cd
            # bwv245.37 ✓  cd
            # bwv245.40 ✓  cd
            # bwv245.5 ✓   cd            
      Set the whole thing off with one click. Pretty amazing. Any issues?

4.    The horns are pretty low in octaves. There is a varible called octave_reduce that can affect that. It's currently set to:
                  octave_reduce = 2
            That makes it go down 2 octaves from where it might already be. That could be the problem. I reset it to octave_reduce = 1, and it's still very low. I found the problem. In woodwinds_part I had two separate copies of the same line.  The following line was in there twice, and the first one had the correct octave_reduce = octave_reduce, and the second one did not. And the second one was reset the results of the first one.
                  octave_alteration_mask = atu.build_octave_alteration_mask(repeats, voices, chorale, octave_reduce = octave_reduce, octave_stretch = 4, p1 = [0.1, 0.2, 0.4, 0.3]) 
      New problem. Looking at the woodwinds_part octaves. What a strange trip they take.
            687.0 - INFO - octave_array prior to spread (values, counts): 
            688.0 - INFO - [(array([0, 5, 6]), array([ 234, 1729,  702])), (array([0, 5, 6]), array([ 234, 1729,  702])), (array([4, 5, 6]), array([ 273, 2340,   52])), ...]
            705.0 - INFO - after spread and mask: np.sum(octave_array) = 112983
            705.0 - INFO - octave_array after spread (values, counts): 
            705.0 - INFO - [(array([0, 4, 5, 6, 7, 8]), array([234, 195, 546, 689, 767, 234])), (array([0, 4, 5, 6, 7, 8]), array([234, 182, 546, 689, 780, 234])), (array([3, 4, 5, 6, 7]), array([ 78, 260, 611, 988, 728])), ]
            716.0 - INFO - octave_array after masking (values, counts): 
      This next one is crazy. The primary purpose of masking is to reduce the liklihood of a note being played, by changing the octave to zero. That's in fact what it's doing, changing 2626 notes to zero, and keeping 39 where they were, which just happened to be octave 6, pretty high.
            716.0 - INFO - [(array([0, 6]), array([2626,   39])), (array([0, 6]), array([2626,   39])), (array([0, 6]), array([2626,   39])), (array([0, 6]), array([2626,   39])), (array([0, 5]), array([2626,   39])), (array([0, 5]), array([2626,   39])), (array([0, 5]), array([2626,   39])), (array([0, 5]), array([2626,   39]))]
      That last transition from after spread to after masking is a whopper.
      Then the next one is much more reasonable:
            octave_array after masking (values, counts)
            [(array([0, 4, 5, 6, 7]), array([2366,   39,   13,   91,  156])), (array([0, 4, 5, 6, 7]), array([2353,   39,   26,   91,  156])), (array([0, 4, 5, 6, 7]), array([2301,   91,   52,  182,   39])), (array([0, 4, 5, 6, 7]), array([2301,   91,   52,  182,   39])), (array([0, 3, 4, 5, 6]), array([2301,   39,  104,  169,   52])), (array([0, 3, 4, 5, 6]), array([2301,   39,  104,  169,   52])), (array([0, 2, 3, 4, 5, 6]), array([2301,   39,   52,  104,  143,   26])), (array([0, 2, 3, 4, 5, 6]), array([2301,   39,   52,  117,  130,   26]))]
      And the third one:
            octave_array after masking (values, counts): 
            975.0 - INFO - [(array([0, 5, 7]), array([2574,   65,   26])), (array([0, 5, 6, 7]), array([2574,   52,   13,   26])), (array([0, 4, 5, 6, 7]), array([2522,   52,   13,   65,   13])), (array([0, 4, 5, 6]), array([2522,   52,   13,   78])), (array([0, 4, 5, 6]), array([2522,   52,   13,   78])), (array([0, 4, 5, 6]), array([2522,   52,   13,   78])), (array([0, 4, 5, 6]), array([2522,   65,   52,   26])), (array([0, 4, 5, 6]), array([2522,   65,   52,   26]))]

5.    Change the logging.info to logging.debug, but not yet. It's only 123 lines and it helped me debug the problem with octave_reduce

6.    I need to make the probs and prob variables to be more variable.

-----------------------------------------
6/12/23 To do today:

1.    Figure out why all the pieces have the same tempo, and may have the same repeats.
      Look at new_output.csd ends with t0 112. Run one more and see if it changes. It changed. It's now t0 62. That's good. Sounds right. Try a few others. t0 108. It seems to work now. I don't know why. I'll leave it alone for now.
      But it I put them in a loop, the repeat and tempo stay the same: 
            558.0 - INFO - repeats = 10, tempo = 76
            882.0 - INFO - repeats = 10, tempo = 76
      That should not happen. I think it was because the function is frozen when it's called. I think it's something about being a parameter in the function definition, where it's frozen. I changed it from being a default parameter to just a positional parameter.
            repeats = rng.integers(8,high=16)
      geeksforgeeks says: Using mutable objects as default argument values in python:
            This must be done very carefully. The reason is the default values of the arguments are evaluated only once when the control reaches the function definition for the first time. After that, the same values(or mutable objects) are referenced in the subsequent function calls."
      That explains the behaviour. And also makes me concerned that the other functions that use mutable default objects may have the same problem. I removed all the mutable default objects. That may explain why there was so much comonality between the pieces. On my walk today I wondered if I might be able to include some higher numbers for probs and prob_silence.

2.    Move the start of the log to the main line, not in a cell that is called for each piece.
      Fixed it. 

3.    Zip together the files including a playlist, and put them up on Substack.
            # zip name-of-zip-file.zip ball9-tbwv245.*c.mp3      
            ls -1 ball9-tbwv245.*c.mp3 ball9-tbwv245.*d.mp3 > JustChorales.m3u
            zip JustChorales.zip ball9-tbwv245.*c.mp3 ball9-tbwv245.*d.mp3 JustChorales.m3u
      Delete the ones you don't want to save.
            grep -E "mod = " ball9.log | cut -d " " -f 7-10
                  'bwv245.3', mod = 'c' - fast & exciting
                  'bwv245.3', mod = 'd' - slow, dramatic opening on strings, then guitars
                  'bwv245.5', mod = 'c' - fast, maybe too much bass 2:53
                  'bwv245.5', mod = 'd' - slow, opening oboe, nice decending minor third in guitar 3:50
                  'bwv245.11', mod = 'c' - slow 6:50, odd chord transition at the start.
                  'bwv245.11', mod = 'd' - fast, moves into pizz strings early 6:15
                  'bwv245.14', mod = 'c' - Odd start, 7:30
                  'bwv245.14', mod = 'd' - fast, 9:00
                  'bwv245.15', mod = 'c'
                  'bwv245.15', mod = 'd'
                  'bwv245.17', mod = 'c'
                  'bwv245.17', mod = 'd'
                  'bwv245.22', mod = 'c'
                  'bwv245.22', mod = 'd'
                  'bwv245.26', mod = 'c'
                  'bwv245.26', mod = 'd'
                  'bwv245.28', mod = 'c'
                  'bwv245.28', mod = 'd'
                  'bwv245.37', mod = 'c'
                  'bwv245.37', mod = 'd'
                  'bwv245.40', mod = 'c'
                  'bwv245.40', mod = 'd'
                  
------------------
6/13/23 To do today:

1.    Use the same techniques you employed to increase density on some of the pieces to create a decreased density set of pieces. These are the mod = 'e' versions. 

------------------
6/14/23 To do today:

1.    Take a hard look at what making the finger piano part more sparse has actually created. It's like I need to see what the probs have become. How many are there, what are the values, and why is it so strange. 

            finger_piano_part instruments density: probs = array([[0.95545808, 0.04454192],
            [0.99      , 0.01      ],
            [0.97272904, 0.02727096]])
      If it's only three elements, it quickly starts to sound repetitive. If the probs.shape[0] < 5, then tile to double it.
      But that causes a downstream failure:
            density_function = np.array([rng.choice(2, size = (voices, (repeats // 2) - 1), p = prob) for prob in probs]).reshape(voices, -1) # This will be used over and over again throughout the piece.
            ValueError: a and p must have same size
      There miht be a way to make this operation work more reliably. It's doing an awful lot of work in one line, and depending on the input has failed repeatedly. On the other hand the reason for the failure was just that I didn't tile properly. 
            probs.shape = (4, 2) is too small. Adding more to it.
            583.0 - INFO - finger_piano_part instruments density: start = 0.01, stop = 0.05, step = 0.010440837330727683, probs.shape = (4, 4), np.min(probs[:,1]) = 0.01, np.max(probs[:,1]) = 0.04132251199218306
      It changed (4,2) into (4,4) when what I wanted was (8,2). How can I do that?
            probs = np.tile(probs, (2,1))
      That fixed it.

      Still want to package up the new collection. Best one for sparseness appears to be 5e or 28e

      bwv245.3     c - fast - nice opening buzz guitars, like bees
      bwv245.15    c - moderate tempo, nice use of reverse envelope finger piano
      bwv245.11    d - fast, simmering long held notes - gets repetitive after a while - then seems to recover going back to the opening 
      bwv245.14    f - moderately slow - good transitions
      bwv245.17    d - moderately fast - engaging, then ticky-tacky, then recovers moves into backwards envelopes - marginal
      bwv245.22    d - very fast. Fastest I've heard so far. Could be valuable as a contrast to slower ones. 
      bwv245.5     d - fast but very sparse 
      bwv245.26    f - Western Feel
      bwv245.28    e - One of the best sparse ones.
      bwv245.37    d - nice off rhythm dance moves, like a samba. Has a hard time sustaining the energy.
      bwv245.40    f - Fast. Good to end with.

      ls -1 ball9-tbwv245.3c.mp3 ball9-tbwv245.15c.mp3 ball9-tbwv245.11d.mp3 ball9-tbwv245.14f.mp3 ball9-tbwv245.17d.mp3 ball9-tbwv245.22d.mp3 ball9-tbwv245.5d.mp3 ball9-tbwv245.26f.mp3 ball9-tbwv245.28e.mp3 ball9-tbwv245.37d.mp3 ball9-tbwv245.40f.mp3 > JustChorales.m3u

      Oh dear, I just discovered that all the pieces I realized today were all based on the same wav file. I had forgotten to turn back on the csound routine. So they simply reconvolved all the ones I had done previously. I didn't notice. Fortunately I discovered it before posting my ripnread opus. I'm redoing all the ones that end in f.  All the ones that end in C or D were done a few days ago. So I have to redo 14f, 26f, maybe 28e, and 40f, and I did 22 just for fun.

2.    I fixed that and posted on ripnread and on substack, linked on facebook. Now stand back and be awed.

3.    I noticed that I no longer need to have a jupyter session running for vscode to provide notebook support. 

            toolbox enter tunnel
            source virtual_python3.11/bin/activate

      I can just run the notebook and it finds the toolbox virtual python environment and uses it. I don't know how it does that, but it's a good thing. I'm not sure how that works, but it's a good thing. It's one less step I need to take, no more jupyter password needed. I don't suppose it will continue to work when I reboot...
      It didn't.
-------------------------
6/15/23 To do today:

1.    Somehow vscode now lets me access using a browser again.

2.    On the downside, the browser session doesn't know about the virtual python environment. 

----------------------
6-16-23 To do today:

1.    Get the ctcsound midi input to automatic just intonation working in the most basic manner possible. Where was I?
      Notebooks:
            ls -lth *.ipynb
                  -rw-r--r--. 1 prent prent 127K Jun  7 11:05 08-ctcsoundAPIExamples.ipynb
                  Example 7 - Communicating Continuous Values with Csound's Channel System
                  Example 8 - More Efficient Channel Communications
                  Example 9 - More Flexible and Efficient Channel Communications
                  Example 10 - Even More Flexible and Efficient Channel Communications
      This set of four cells communicate between Python and the csound instance in ctcsound using channels.
      In the csound .csd file, a channel is defined:
            kamp chnget "amp" ; refer to this channel in python as "amp"
            kfreq chnget "freq" ; refer to this channel in python as "freq"
      In the python code, you need to start up a ctcsound instance:
            c = ctcsound.Csound() 
            ret = c.compileCsd("test1.csd")
            if ret == ctcsound.CSOUND_SUCCESS:
                  c.start()
                  c.perform()
            c.reset()
      Then you can keep refering to the ctcsound instance as c.something. In python they have a class RandomLine that functions to handle communication:
            amp = RandomLine(.6, .2)    # create RandomLine for use with Amplitude
            freq = RandomLine(400, 80)  # create RandomLine for use with Frequency 

            c.setControlChannel("amp", amp.getValue())     # Initialize channel value before running Csound
            c.setControlChannel("freq", freq.getValue())   # Initialize channel value before running Csound
            while (c.performKsmps() == 0):
                  c.setControlChannel("amp", amp.getValue())   # update channel value 
                  c.setControlChannel("freq", freq.getValue()) # update channel value 
      Steven says this is inefficient, because every setControlChannel needs to query ctcsound for the value, instaed of directly affecting ctcsound through a pointer accessble to python. Here is the more efficient way:

            ampChannel, _ = c.channelPtr("amp",
            ctcsound.CSOUND_CONTROL_CHANNEL | ctcsound.CSOUND_INPUT_CHANNEL) # or the two values to provide the type_ argument
            freqChannel, _ = c.channelPtr("freq",
            ctcsound.CSOUND_CONTROL_CHANNEL | ctcsound.CSOUND_INPUT_CHANNEL)
      
      from the ctcsound documentation:
            channelPtr(name, type_)
                  Returns a pointer to the specified channel and an error message.

                  If the channel is a control or an audio channel, the pointer is translated to an ndarray of MYFLT. If the channel is a string channel, the pointer is casted to c_char_p. The error message is either an empty string or a string describing the error that occured.

                  The channel is created first if it does not exist yet. type_ must be the bitwise OR of exactly one of the following values,

                  CSOUND_CONTROL_CHANNEL control data (one MYFLT value)
                  CSOUND_AUDIO_CHANNEL audio data (ksmps() MYFLT values)
                  CSOUND_STRING_CHANNEL string data (MYFLT values with enough space to store getChannelDatasize() characters, including the NULL character at the end of the string)
                  and at least one of these:

                  CSOUND_INPUT_CHANNEL # the signal is input to csound - in my case it's the note value to the audio engine.
                  CSOUND_OUTPUT_CHANNEL # the signal is output from csound - in my case it's the midi values from the keyboard

      What I want is:
      1.    ctcsound.CSOUND_CONTROL_CHANNEL | ctcsound.CSOUND_INPUT_CHANNEL sends data from python to csound 
      Looking at example 9: in python you want to send information to csound:
            ampChannel = createChannel("amp") # python function that creates a channel to send data to csound - one way only in this implementation.
            amp = some_object() # create an object with a method getValue that returns a float from a random source
            ampChannel[0] = amp.getValue() # retrieve the current random source value and post it to the ampChannel data tuple
      In the csound file, a channel is defined:
            kamp chnget "amp" ; get the value for the amplitude from the "amp" channel - info here: https://csound.com/docs/manual/chnget.html
      You now have a pointer to the channel in csound and you can load that pointer with a value in a loop:
            while (c.performKsmps() == 0):
                  ampChannel[0] = amp.getValue()
                  freqChannel[0] = freq.getValue()
      2.    ctcsound.CSOUND_CONTROL_CHANNEL | ctcsound.CSOUND_OUTPUT_CHANNEL sends midi data from python to csound
            I was stuck here for about an hour because I had spelled OUTPUT with out the first T. OUPUT.
                  In the csound .csd file, a channel is defined: 
            chn_k Sname, imode; create a channel called "cutoff" as control channel receiving input
                  Sname -- chn_k "cutoff", 1 ; create a channel called "cutoff" 
                  imode -- sum of at least one of 1 for input and 2 for output. 1+2=3 for input and output
            for output to python through ctcsound you have to declare to csound the channel. But how do you write to the channel.
                  chn_k "iNum", 2 ; how to we associate a csound variable with a channel, such that ctcsound can read the value from the channel?
                  chn_k "iVel", 2
                  

      csd files:
            ls -lth *.csd
                  -rw-r--r--. 1 prent prent 1.1K Jun  5 08:12 read_midi_ctcsound.csd
                  -rw-r--r--. 1 prent prent  63K Jun  4 15:19 ball10.csd 
                        modified ball9.csd to use f0 120 ; dummy f-statement to keep it running for 2 minutes
                        Otherwise it just plays notes sent to it from ctcsound

                  -rw-r--r--. 1 prent prent  941 Jun  4 13:31 process_midi_keys.csd # <-- just play the keyboard sine waves
                  -rw-r--r--. 1 prent prent  483 Jun  3 16:24 cs_python.csd # <-- calls pyinit - fails
                  -rw-r--r--. 1 prent prent  63K Jun  3 15:25 midi_output.csd <-- plays sampled notes from midi
                  -rw-r--r--. 1 prent prent  624 Jun  3 15:09 cpsmidi.csd <-- cycles per second from midi
      
      python scripts:
            ls *.py -lth
                  -rw-r--r--. 1 prent prent 58K Jun 12 09:50 adaptive_tuning_util.py
                  -rw-r--r--. 1 prent prent 495 Jun  4 13:51 process_midi_keys_ctcsound.py

      The basic architecture is this:
      a.    One csd file that does it all, called by ctcsound. Call it read_midi_ctcsound.csd 
      b.    Inside the csd file are two instruments:
            i.    One that reads the keyboard notes and opens a channel to python to pass notes to the python instance

            ii.   A second instrument that reads notes from python and plays them to the audio output.


2.    Copilot is no longer active. I had to click the activate button in the lower right.
      The extension had turned off when I clobbered the ~/.vscode directory. 

------------------------------------
6/17/23 To do today:

1.    Get something working using ctcsound reading midi and sending that information to python, and python sending that information to another instrument number in ctcsound to make a note. What can csound read from midi?
      notnum - midi note event
      iamp ampmidi iscal ; midi amplitude between 0 and iscal 
      ival veloc [ilow] [, ihigh] ; ilow, ihigh -- low and hi ranges for mapping

2.    So I have the python notebook reading midi events from the keyboard now. It was a bit of a challenge. How do I stop it?

-------------------------------------
6/18/23 To do today:

1.    Continue to work on getting instrument 1 to provide midi events to ctcsound, python to take them in, and instrument 2 to play them. Some issues:
      a.    Every midi keypress generates lots of notes on the channel. I really only want to do something with the first one, but keep playing as long as it's held down. So could I use note-on, note-off protocol here?
      There is a way to process this information: midiin opcode. 
            kstatus, kchan, kdata1, kdata2 midiin
            kstatus -- the type of MIDI message. Can be:
                  128 (note off)
                  144 (note on)
                  160 (polyphonic aftertouch)
                  176 (control change)
                  192 (program change)
                  208 (channel aftertouch)
                  224 (pitch bend)
                  0 if no MIDI message are pending in the MIDI IN buffer
            kchan -- MIDI channel (1-16)
            kdata1, kdata2 -- message-dependent data values

            midiin has no input arguments, because it reads at the MIDI in port implicitly. It works at k-rate. Normally (i.e., when no messages are pending) kstatus is zero, only when MIDI data are present in the MIDI IN buffer, is kstatus set to the type of the relevant messages.
      b.    I can't have multiple notes on the same channel. So if I have instrument 1 receiving midi notes, it will only receive one, then the next note is from another instance of that note.. I thought I had made a csound instrument that could read and play mulptiple notes on the same channel. process_midi_keys.csd will play multple notes. I thought the trouble was this:
            note = noteChannel[0] # get the note from the channel
      So I changed it to:
            note = noteChannel # then looked at the shape, but it was always note.shape = (1,)
      Even when I played a chord on the keyboard it returned only a single note. The change made no difference.
      I think that the problem is not that instrument 1 doesn't read all notes in a chord, I think it's because it spawns multiple instrument 1 copies and each sends back to ctcsound a single note. But while the first one gets through, it doesn't wait before clobbering the channel with the next note before csound can read it. I think this might be what ctcsound refers to as not being threadsafe.
      This statement doesn't mean anything to me: "See Top/threadsafe.c in the Csound library sources for examples." Optionally, use the channel get/set functions provided below, which are threadsafe by default.
      I guess I could switch back to the set function for channel operations. I did that, but it didn't make a difference. 

----------------------------------
6/19/23 To do today:

1.    I think I've established that the channel from instrument 1 is not letting multiple notes through.
            iNum, c_int  = cs.controlChannel("iNum")
      iNum is never more than one note even when I play a chord. It seems to pick one of the three notes I play. 
      If I start a note like C 5 and hold it, it holds that note while playing the next note I play E 5, and holds both, then plays the next note G5, and holds all three. But it I start with all three at once, it only shows that I'm pressing down one.
      Yet when I look at instrument 1, it shows it's playing three notes:
            csound ch 1. (iNum) note: '67' (iVel) vel: '100' 
            csound ch 1. (iNum) note: '64' (iVel) vel: '105' 
            csound ch 1. (iNum) note: '60' (iVel) vel: '101' 
      And channel 2 only shows receiving one note:
            csound ch 2. (p1) instrument: '2' (p2) start: '1.259683' (p3) dur: '1' (p4) midi: '60', (p5) vel: '101'
      and ctcsound only shows passing one note to csound channel 2. 
            int(iNum) = 60 keys[int(iNum % 12)] = 'C ', oct 5, int(iVel) = 101

2.    Some ideas to get over this significant hurdle:
      a.    Make the input and output channels two separate instance of ctcsound with unique names. I'm doubtful. I've alread established that channel 1 can print three notes of a chord, but it can't send three notes over the channel. The problem isn't on the conflict between instrument 1 and 2, it's more likely a limitation on the way I'm using the channel. I've tried two didfferent ways:
      i.    iNum, error_msg = cs.channelPtr('iNum', ctcsound.CSOUND_CONTROL_CHANNEL | ctcsound.CSOUND_OUTPUT_CHANNEL) which establishes a pointer to the channel, and allows me to read from the channel. But it couldn't read more than one note at a time. It seems to pick one note and ignore the rest. Every time. And it only seems to pick the first one and ignores the rest. If I play each note while holding the previous, four get through, but no more.
      ii.   # iNum = cs.controlChannel("iNum")   # define the channel as a ctcsound python variable
            # iNum, c_int  = cs.controlChannel("iNum") # put this in the performance loop and it will read from the channel. But only one note at a time, no chords.
      Both are unable to respond to these message in instrument 1 in csound:
            iNum notnum ;  Get the MIDI byte value (0 - 127) 
            iVel veloc ; Get the MIDI byte value (0 - 127) 
            ; make these available in csound for reading from python through a pair of channels
            chnset iNum, "iNum"  ; send the data to ctcsound on the output channel called iNum
            chnset iVel, "iVel" ; send the data to ctcsound on the output channel called iVel
      Neither work with chords. I wonder if I insert a pause between the channel messages, the ctcsound instance will be able to read them.
      iii.  Could I cause the instrument 1 to trigger another instrument that would then send the note to ctcsound. I think my problem is with channels not acting.

----------------------
6/20/23 To do today:

1.    Things to try:
      a.    Switch from an ivariable to a kvariable and see if that makes a difference.
      b.    Make sure to look at the error messages that might come out.
      c.    Proceed with your next steps and just never expect a chord to work.
      d.    Follow the directions of this Irish guy: 
            If all notes happen in the same kcycle, the channel will only hold the last note. Maybe the best thing would be to store the notes in a function table and then read however many have been stored in one kcycle. You can keep a global count and pass that in a channel. Clearing the global count every kcycle so you can start again every time.

            Prof. Victor Lazzarini
            Maynooth University
            Ireland
            
            Here is instrument #1 seeing three notes. This is the order of the print commands:
            print giIndex, iNum
                  instr 1:  giIndex = 1.000  iNum = 57.000 # he receives one of the three midi notes in instr 1
            ftprint giMidi, 1, 0, giIndex 
                  ftable 101: 0: 57.0000  # csound loads it into a table #101
            print iNum, iIndex, giIndex
                  instr 1:  iNum = 57.000  iIndex = 0.000  giIndex = 1.000
            chnset iNum, "iNum" ; pass the note to ctcsound - but ctcsound never sees it.
                  instr 1:  iNum = 0.000  iIndex = 1.000  giIndex = 1.000

                  instr 1:  giIndex = 1.000  iNum = 60.000
                  ftable 101:
                  0: 60.0000 
                  instr 1:  iNum = 60.000  iIndex = 0.000  giIndex = 1.000
                  instr 1:  iNum = 0.000  iIndex = 1.000  giIndex = 1.000

                  instr 1:  giIndex = 1.000  iNum = 53.000
                  ftable 101:
                  0: 53.0000 
                  instr 1:  iNum = 53.000  iIndex = 0.000  giIndex = 1.000
                  instr 1:  iNum = 0.000  iIndex = 1.000  giIndex = 1.000
                  iNum = array([0.])
            Nothing gets sent to ctcsound over the channel.
      How can I continue to store in the same kcycle? ; store the notes in a function table and then read however many have been stored in one kcycle. How can I tell I'm in the same kcycle? Is there some way to track that?
                  
      e.    What if I just turn the k value into 1? Doesn't help. 

2.    You've spent five days on this an have nothing to show for it. 
      Started on 6/16, and continued on 17, 18, 19, and now 20 with no positive results. What doesn't work: 
      a. Playing more than one note at a time and using the channel system to passing that to ctcsound, and getting csound to play that midi note on another instrument. Seems like a simple request, but it doesn't work. It plays for 3-4 notes, then stops playing. 
      What if I created two different csound instances and used one for reading and the other for playing?

3.    What about reading raw midi through midiin.csd
            kstatus, kchan, kdata1, kdata2                  midiin
      Then process those messages. Easy peasy.

--------------------------------------------
6/21/23 To do today:

1.    Would using a performance thread help? I already am using such a construct. I'm ready to give up on midi processing through channels to python on ctcsound. I think this is the issue: Example 4 - Using Csound's Performance Thread 
      Using a native thread is important to get the best runtime performance for the audio engine.  It is especially important for languages such as Python that do not have true native threads and that use a Global Interpreter Lock. CsoundPerformanceThread has some convenient methods for handling events, but does not have features for doing regular processing at block boundaries.  In general, use CsoundPerformanceThread when the only kinds of communication you are doing with Csound are through events, and not using channels.  
      Copilot suggested this: If you need to use channels, you should use CsoundPerformanceThread as a base class and override the performKsmps() method to do your processing.  See the example below for an example of this. Of course, there is no example of overriding the performKsmps() method below. CoPilot was halucinating, or wishful thinking, like an overeager intern. 

--------------------------------------------
6/22/23 To do today:

0.    Had to reboot after doing an update. When you connect to the jupyter server, use this URL:
      http://localhost:8888/?token=ed2274fab6a1bed0b32a670de27530fb430015e4370ce804

1.    Continue to explore options for reading midi notes. I can do it successfully with mido. See read_mido.ipynb
      But mido doesn't provide a timing mechanism, and I'd have to build one myself. mido required rtmidi to run, so I looked at that as a possibility. It's in c++, but it includes timing in the messages. Then there is python-rtmidi, which is a python wrapper for rtmidi. I'm going to try that next.
      Documentation:
            python-rtmidi: https://spotlightkid.github.io/python-rtmidi/ 
            mido: https://mido.readthedocs.io/en/latest/messages.html?highlight=time#the-time-attribute
            rtmidi tutorial: http://www.music.mcgill.ca/~gary/rtmidi/
      The mido worked perfectly as shown in notebook: read_mido.ipynb, but messages don't get a timestamp.
      Try python-rtmidi next. Needed to do some installs first:
            sudo dnf install rtmidi
            sudo dnf install rtmidi-devel
            pip install python-rtmidi # required for mido to work.
      github page for python-rtmidi: https://github.com/SpotlightKid/python-rtmidi/tree/master
      Examples of reading in a time_stamp and a message consisting of three values, message_type (144 is note on, 128 is note off), midi note number, velocity
      midiin_poll.py - poll for midi messages and print them.
      midiin_callback.py - callback calls an object and prints the contents of the interaction
      I'm not sure if it gets the time from the message, or uses python to capture time. 
      deltatime is the difference between this message and the prior message. 
      self._wallclock is the time since the start of the program.
      time.time() is the number of seconds since January 1, 1970 00:00:00 UTC 12. details here: https://docs.python.org/3/library/time.html

      To receive the midi clock time see midiclock.py It appears my midi device doesn't send any clock messages. 
      I need a list of midi message numbers. 
      Here is a list of midi messages: https://www.midi.org/specifications-old/item/table-1-summary-of-midi-message
      The only ones I should care about are 144 note on and 128 note off. 176 is a controller midi event. My keyboard send that when I press sustain button. The arpeggio button doesn't send anything to the computer. 
      So it's clear that rtmidi doesn't do any better at reading timing information than mido. 

-----------------------
6/23/23 To do today:

1.    Think about what you want to accomplish. 
      a.    When you get a note on message, you want to start a note playing, add the velocity to the note_array at the note number as index. This could be done using one-hot encoding where the velocity is the non-zero value and the note number is the index. The structure of the array is every tick is a row and every note is a column, and the velocity is the value. 
            ticks = 1000
            note_array = np.zeros((ticks, 128), dtype = int)
      b.    When you get a note off message, you want the note_array to stop playing the note, stop storing the velocity in this position. 
      c.    For every tick you need to increment the index to note_array. 
      d.    At every tick, send the current note_array to a function that converts that moment to a chord:
            chord = np.array([np.where(note_array[i] > 0)[0] for i in np.arange(ticks)]) # generated by copilot, check the intern's work.

2.    Post the link to the page of the most recent album on the Music page.
            http://ripnread.com/sample-page/code/fantasias-on-bach-chorales-from-the-st-john-passion-for-large-ensembles/

-----------------------
7/3/23 To do today:

1.    Figure out a way to take the notes played on the keyboard and tune them.

-----------------------------
7/4/23 To do today:

1.    Do you want to loop over messages or loop over time ticks. 
      a.    If you loop over ticks, you can immediately convert the note_array into a chord, and also send it to the tuning algorithm. There is no delay waiting for another note.
      b.    But you need to not block on waiting for a message. Why?
            get_message() will return None if there are no messages ready to be gotten. Then don't take action.
      c.    There is no reason to save the one-hot encoded note_array. Just save the chord.
      d.    
----------------------
7/5/23 To do today:

1.    We now have a chord in an array with (midi_note, velocity).
      Figure out how to tune it and return everything needed to play it on ctcsound instance.
      Basic structure:
      a.    get the chord from the midi keyboard in an array (midi_note, velocity). It will contain all the keypresses and their velocities that took place during the 1/24th of a second (0.04166667).
      b.    I re-ran the TonicNet_Csound_Just.ipynb notebook and found one bug, and fixed it. But it was almost overwhelming in it's complexity. Here is the module that does most of the work:
            version = "bwv245.26" # this is the chorale that we want to process. 
            quantizer = 2 # default is 2. It works for the chorales in the Music21 corpus.
            chorale, root, mode, s = assign_chorale(version, quantizer = quantizer) # The chorale from the Music21 corpus will we use to build our chorale
            # show_chorale(s) # show the chorale # this shows the muscore image of the sheet music for inspection. 
            mod = "g" # mod is used to distinguish between different versions of the same chorale
            # initialization routine the chorale and the instruments with some of the key variables that influence the way it will sound.
            # +-- the list of notes in the chorale (voices, midi_notes)
            # |      +-- stochasticly chosen number of times to reapeat each note. repeats = rng.integers(8,high=16)
            # |      |        +-- python dictionary containing information about the instruments, and also the current position in the piece
            # |      |        |           +-- list of accidentals, sharps or flats depending on the key
            # |      |        |           |     +-- 12TET tones that should be fixed in location to avoid drift. Each chorale has a unique set
            # |      |        |           |     |          + unused list of slides
            # |      |        |           |     |          |             + short names of the instruments in the finger piano group
            # |      |        |           |     |          |             |              + woodwind instrument names
            # |      |        |           |     |          |             |              |           + strings, bowed, brass, percussion
            chorale, repeats, voice_time, keys, top_notes, stored_gliss, finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, perc_guitar = initialize_chorale_and_instruments(version)
            # tune the chorale in just by optimizing the numerator and denominator of all the ratios in all the intervals of every chord.
            chorale_in_cents, tonal_diamond, ratio_factor = tune_chorale(chorale, top_notes, keys)
            print(f'{chorale_in_cents.shape = }, {tonal_diamond.shape = }, {ratio_factor = }')
            # print a report on the tuning results, showing all the intervals in all the chords in the chorale
            atu.print_interval_cent_report(chorale_in_cents, chorale, top_notes, tonal_diamond, keys, ratio_factor)
            print(f'{version = }') 
            # expand the chorale, send the results to a csound csd file for later processing. 
            duration, volume_function = expand_chorale(repeats, chorale_in_cents, voice_time, finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, perc_guitar)
            # have csound perform the csd file.
            result_of_call = play_csound(csound = True, play = False, ship = False)
            # The next call sometimes fails because it can't find the old 1600 duration that it's trying to sed replace. 
            result_of_call = trim_csound(version, chorale_in_cents, duration, trim = True)
            # show a report of the volume of each of the instruments changing over time.
            display_volumes(volume_function)

-------------------------
7/6/23 To do today:

1.    Include the code required to drive ball10.csd through ctcsound.
      take a look at this notebooks: 
            ctcsound_play_notes.ipynb # <-- crashes the python kernel. I restarted code and it worked now. 
      Next step:
      a.    Send the chord through something like tune_chorale in the TonicNet_Csound_Just.ipynb notebook.
            This is the wrong function to send it through. tune_chorale calls midi_to_notes_octaves, which is designed to process a whole chorale. Look at midi_to_notes_octaves and see where you want to directly send the chord to tune. I'm begining to think I need to code something from scratch. For one thing, all the codes in adaptive_tuning_util.py expect to be working on a chord of four notes. Blows up at 5. 
      b.    I will need to augment tonal_diamond with the other two value sets.

---------------------------------
7/8/23 to do today:

1.    Moving the tuning algorithm into the new notebook, so I can tailor it to a single chord of indeterminant number of notes.
      This means I can make some changes, like using permutations up front instead of only of the score is high. But that means I'll need to keep track of which relative note in the chord I'm at when I'm doing the permutation. I started off with this:
            for first, second in permutations(chord,2): 
      This works fine if you don't plan to change any of the notes in the chord. But if you are, then you should use an index into chord for the permutations, not the note itself.
            for inx1, inx2, first, second in zip(count(0,1), permutations(chord,2))

-----------------------------------
7/9/23 To do today:

1.    Pick the correct list of permutations in the correct order. Use this one as a guide, but make it able to handle more notes in the chord:
      order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]])
      Could I take the permutations and sort it to result in the same? Here is what permutations(np.arange(5, dtype = int),2)
      0       1      2      3      4      5      6      7      8      9      10     11     12     13     14     15     16     17     18     19
      [0, 1] [0, 2] [0, 3] [0, 4] [1, 0] [1, 2] [1, 3] [1, 4] [2, 0] [2, 1] [2, 3] [2, 4] [3, 0] [3, 1] [3, 2] [3, 4] [4, 0] [4, 1] [4, 2] [4, 3] 
      So what I would like to see is this order: 
      0,      5,     10,    15,    16     1      2      3      6      7      4      8      12     9      13     17     14     19    11      18
      [0, 1] [1, 2] [2, 3] [3, 4] [4, 0] [0, 2] [0, 3] [0, 4] [1, 3] [1, 4] [1, 0] [2, 0] [3, 0] [2, 1] [3, 1] [4, 1] [3, 2] [4, 3] [2, 4] [4, 2]

-----------------
7/10/23 To do today:

1.    Is the order important of a permutation? If it is, then you need to specify it. Try without doing that.

2.    Wouldn't it be nice if you could hear the tuning process as it honed in on the right values?
      

----------------------
7/14/23 To do today:

1.    Put together some music to send to my siblings.

2.    Make sure the WSL version works with jupyter notebooks. It does, but only if I create a jupyter session and paste the link http://localhost:8888/?token=87a870f118ac4556d495a4e17560c95d61b183e0baaf7743
And then it doesn't support alsa for midi input. I'll switch back to the T15 for the midi.

3.    Make sure the code tunnel works. It does if I start code, then turn on remote tunnel access.
      https://vscode.dev/tunnel/thinkcentre/c:/Users/prent
      But that only gets to the Windows file system. To get to the wsl file system, you have to start there. To get to the Windows file system:
            dir \\wsl.localhost\Fedora\home\prent\Dropbox\Tutorials\TonicNet
      https://vscode.dev/tunnel/thinkcentre
      Open an explorer window into the WSL file system from WSL command prompt:
            explorer.exe 
      Don't forget the period and extension.
--------------------
7/15/23 To do today

1.    Concentrate on TonicNet_Csound_Just_Album2.ipynb This one does all the chorales in one notebook,
      Changes to make:
      a.    Make the choice of quantizer variable. 2 makes for too short a piece. 4 and 6 should occasionally be used.
      b.    Make sure the repeats value isn't too low.
      c.    Pick the best:
            bwv245.11', mod = 'i'   3:37 ✓ Fast
            bwv245.14', mod = 'i'   5:20 Slow but nice
            bwv245.15', mod = 'i'   5:05 ✓ Fast but calm
            bwv245.17', mod = 'i'   4:15 ✓ slow but nice
            bwv245.22', mod = 'i'   6:02 ✓ Very nice start slow but steady
            bwv245.26', mod = 'i'   7:50 ✓ fast but sparse
            bwv245.28', mod = 'i'   4:11 moderate
            bwv245.3',  mod = 'i'   2:33 low key but short
            bwv245.37', mod = 'i'   5:52 very low key
            bwv245.5',  mod = 'i'   3:20 pretty low key
            bwv245.40', mod = 'i'   7:12 ✓ 

            bwv245.14", mod = 'j'   3:55 moderate speed
            bwv245.28", mod = 'j'   8:36 moderate interesting rhythm
            bwv245.3",  mod = 'j'   3:06 fast but sparse nice late middle
            bwv245.37", mod = 'j'   5:27 fast but sparse
            bwv245.5",  mod = 'j'   6:42 fast well balanced

            bwv245.14", mod = 'k'   3:51 moderate
            bwv245.28", mod = 'k'   11:39 moderate
            bwv245.3",  mod = 'k'   9:24 slow but nice
            bwv245.37", mod = 'k'   14:22 moderate and long
            bwv245.5",  mod = 'k'   9:49 ✓ Some very sweet parts

            bwv245.14", mod = 'l'   10:40 starts out with too much muddled bass. slow.
            bwv245.28", mod = 'l'   14:17 Moderate tempo. Nice string start. Too long.
            bwv245.3",  mod = 'l'   ✓ 5:10 Fast, Lively. 
            bwv245.37", mod = 'l'   7:23 starts with moderate bass. Slow.
      
      d.    Final choices:
            Need one more with very few repeats, very little finger piano.
            bwv245.14m 2:06 ✓ 
            bwv245.22i 6:02 ✓ Very nice start slow but steady
            bwv245.5k  9:49 ✓ Moderate tempo. Some very sweet parts
            bwv245.40i 7:12 ✓ Very fast
            bwv245.17i 4:15 ✓ slow but nice
            bwv245.11i 3:37 ✓ Very fast
            bwv245.28j 8:36 ✓ moderately fast. interesting rhythm
            bwv245.15i 5:05 ✓ Fast but calm
            bwv245.37l 7:23 ✓ starts with moderate bass. Slow.            
            bwv245.26i 7:50 ✓ fast but sparse
            bwv245.3l  5:10 ✓ Fast, Lively. 
      e.    
---------------------------
7/16/23 To do today:

1.    Why is top_notes just one note (9) in the report 
            top_notes.shape = (2, 1)
            top_notes = array([[  9], [900]]). 
      Later it becomes the correct value.
            top_notes.shape = (2, 7), top_notes = array([[   9,    4,    1,   11,    6,    8,    2],[ 900,  402,   86, 1104,  584,  788,  198]])
      It is set in initialize_chorale_and_instruments() and used in tune_chorale(). But why not the right value in the report?
      Why is the ratio_factor and dist_factor not affecting the tuning. It's like they have zero effect. That's not correct. It has a quite large effect, as shown by a comparison of ratio_factor set to 1 and 10. Big differece.

2.    I'm liking the result of ratio_factor = 10, so I'm going to do one more round of all the chorales. 
      The series 'o' has this option set, as does p r & s. 
      
3.    Take a listen to bwv245.14q. It was made with mask = False. But it probably had some midi note mismatches that I did not detect.
      Trash them all, until you get to the s & t ones.

      Sometimes trying to please your critics can cause you to chase bad ideas. I spent about 6 months implementing the most sophisticated masking algorithm, with tons of variety between each set of masks for each piece. I set mask = False for this run, and it actually showcases the beauty of the tuning algorithm when ratio_factor = 10. Setting dist_factor = 0.5 does nothing. 
            ls -lth ~/Music/sflib/ball9-tbwv245.*o.wav
            ball9-tbwv245.11o 8:25 nice but conventional. First few minutes has a wierd chord. 
            ball9-tbwv245.14o 5:21 conventional
            ball9-tbwv245.15o 4:33 fast and conventional
            ball9-tbwv245.17o 10:55 slow
            ball9-tbwv245.22o 6:14 very slow - has some wolf notes that are prominent
            ball9-tbwv245.26o 8:36 fast - Nice rhythms
            ball9-tbwv245.28o 6:11 slow -
            ball9-tbwv245.37o 5:16 moderately fast
            ball9-tbwv245.3o. 6:39 starts without knowing the tempo, then fast 
            ball9-tbwv245.40o 16:27 slow  
            ball9-tbwv245.5o. 9:49 moderate tempo.  
      
4.    I had forgotten that the print_interval_cent_report also looked for mismatches in midi notes. 
      If a conversion to cents rounded to a different midi number than the original it is flagged in the report. It should have halted processing. This is a big problem. I fixed the codes so they would stop processing if the tuned note did not round to the original midi note, which meant that I tuned the note to a different note than the composer intended. I call that unethical.

5.    These were done with ratio_factor = 2 & dist_factor = 0.35, which is more edgy than 1 and 1.

      ls -l ~/Music/sflib/ball9-tbwv245.*s.wav # created on 7/17/23 afternoon after fixing the ratio_factor. On the ThinkCentre they are less than a minute per piece to generate. 
      ls ../../../Music/sflib/ball9-tbwv245.*s.wav -lth
            ball9-tbwv245.40s 18:29
            ball9-tbwv245.5s. 9:05
            ✓ ball9-tbwv245.37s 12:33 Moderate tempo. Vague start. Gets moving after 1:30. Nice finish
            ✓ ball9-tbwv245.3s. 3:53  fast, sparse at start. Then moves by 1:20. great finish
            ✓ ball9-tbwv245.28s 9:06  very fast & rhythmic, samba style. keeper. 
            ball9-tbwv245.26s 4:31
            ball9-tbwv245.22s 3:33
            ball9-tbwv245.17s 3:28
            ball9-tbwv245.14s 14:50
            ✓ ball9-tbwv245.11s 6:14  Some strange opening chords, then suddenly starts up 30 seconds. very fast sometimes random. Great groove at 3:00. It's in either 8 or 16, not sure. A keeper. 
            ball9-tbwv245.15s 16:53
            
      ls -lth ../../../Music/sflib/ball9-tbwv245.*t.wav
            ✓ ball9-tbwv245.40t 7:12  very fast, but subdued. Nice rhythmic patterns. Builds.
            ✓ ball9-tbwv245.5t. 6:28  moderately slow. Very nice brass opening. Great ending.
            ball9-tbwv245.37t 10:41 very fast, no rhythm, not good enough.
            ball9-tbwv245.3t. 9:44  slow. Not bad. Sleepy. 
            ball9-tbwv245.28t 6:58  slow. Not bad. Sleepy.
            ✓ ball9-tbwv245.26t 12:40 fast full of wonderful sonorities
            ✓ ball9-tbwv245.22t 8:05  moderate tempo. Builds.
            ✓ ball9-tbwv245.17t 3:16  moderately fast. Short. Solid.
            ✓ ball9-tbwv245.15t 4:33  fast, lively and very sweet. Just like I enjoy. 
            ✓ ball9-tbwv245.14t 7:50  Very fast. Sweet and slow at the same time. Powerful
            ball9-tbwv245.11t 6:16  fast, starts vague, never finds a groove.
      Print it tomorrow morning. Upload to ripnread and substack. Include the one with just the chorale. Which one was 3that?

-------------------------------
7/18/23 To do today 

1. Post the saved new versions as a zip and the top three. 

      ✓ ball9-tbwv245.11s 6:14  Some strange opening chords, then suddenly starts up 30 seconds. Groove at 3:00. It's in 16
      ✓ ball9-tbwv245.28s 9:06  very fast & rhythmic, samba style. keeper. 
      ✓ ball9-tbwv245.3s. 3:53  fast, sparse at start. Then moves by 1:20. great finish
      ✓ ball9-tbwv245.5t. 6:28  moderately slow. Very nice brass opening. Great ending.
      ✓ ball9-tbwv245.26t 12:40 fast full of wonderful sonorities
      ✓ ball9-tbwv245.22t 8:05  moderate tempo. Builds.
      ✓ ball9-tbwv245.17t 3:16  moderately fast. Short. Solid.
      ✓ ball9-tbwv245.37s 12:33 Moderate tempo. Vague start. Gets moving after 1:30. Nice finish
      ✓ ball9-tbwv245.40t 7:12  very fast, but subdued. Nice rhythmic patterns. Builds. Couldn't fit on the CD.
      ✓ ball9-tbwv245.15t 4:33  fast, lively and very sweet. Just like I enjoy. 
      ✓ ball9-tbwv245.14t 7:50  Very fast. Sweet and slow at the same time. Powerful
      11: O Welt, sieh hier dein Leben
      
      Substack here: https://microtonalnotes.substack.com/p/bach-tuned-and-orchestrated-for-large
      ripnread.com post here: http://ripnread.com/bach-tuned-and-orchestrated-for-large-ensemble/
      Burned 4 CD's to mail if requested.
---------------------------
7/22/23 To do today:

1.    Get back to working on playing the midi keyboard and making chords to play on csound. Check out the Floss manual for python with csound.
      https://flossmanual.csound.com/csound-and-other-programming-languages/python-and-csound

---------------------------
7/27/23 To do today:

Listen to the u, v versions of the pieces.
ls -1 ~/Dropbox/Uploads/ball9-tbwv245.*u.mp3 ~/Dropbox/Uploads/ball9-tbwv245.*v.mp3
      
      ball9-tbwv245.11v - short 
      ball9-tbwv245.14v - corrupt
      ball9-tbwv245.15v
      ball9-tbwv245.17v
      ball9-tbwv245.22v
      ball9-tbwv245.26v
      ball9-tbwv245.28v
      ball9-tbwv245.37v
      ball9-tbwv245.3v.
      ball9-tbwv245.40v 7:30  Long not very interesting. 
      ball9-tbwv245.5v.   

-----------------------------
7/29/23 To do today:

1.    Back to working on the processing of midi keyboard notes. I'm not happy with the results of the choices made so far. 
      It basically takes the last single interval in the combinations and accepts the best ratio for that interval. Here I am working with the chord C E G A# D, a standard just 4, 5, 6, 7, 9/8 chord. Those are in positions 0, 1, 2, 3, 4 in the chord. It looks at the A# and sets it to 16/9 996 cents. I can live with that. I would prefer 7/4, but I may fix that with a different ratio_factor, dist_factor later. Coming back to this again. Why doesn't it pick 7/4 969 for the A#. If it did, the score would be 127, much better than 245. Why didn't pick that one. It was a lower num_dem value. What was it optimizing?
            (173, ('7/4', 969, 11)),  (177, ('16/9', 996, 25))
      When I changed ratio_factor to 2, I got it to pick 1018 for 0 to 3 C to A#. 
      When it came time to pick 3 to 0, the inverse ratio, it was never given the choice to pick 969 at 8/7, since it was outside the range of 6 possible ratios. Perhaps if it had a bigger range, it might have picked it on the reverse interval. I though 6 was big enough, but maybe not. I boosted the range to 9, which then included the 969, but it chose the 1018 9/5 instead, because it was too big a distance from the 12TET note.
      So I cut the distance factor to 0.25, and it chose the 969 7/4 ratio. 
      The success was found with ratio_factor = 2, and dist_factor = 0.25. 
      
      In other news, when I set the ratio_factor to 3, it chose the 7/4. But that big a factor can end up with notes not matching the original 12 TET note. Can't allow that. Let's increase the range and see what happens.
      
      The real problem is that it doesn't stick with that choice. It only sticks with the most recent change.
            starting to evaluate inx1 = 1, inx2 = 3
            Optimizer: ('10/7', 618, 17), cent_deviation = 8.0
            new value for note at index inx2 = 3, chord = array([   0,  386,  702, 1004,  204])
      Next, when evaluating 1 to 3, E to A#, it chooses 10/7, setting 3 to 1004, without regard to whether that is beneficial to the chord overall. If it screws up another interval, like it soon does withan evaluation of 2 to 3, G to A#, it resets the A# to be 6/5 above the G. Again without considering if that is a good idea or not for the chord as a whole.
      I have some choices here. But it does score the note. Does it include all the notes?
      a.    I could either accept or reject the proposed change, based on a score. But that would mean I would pick one of two choices, when a third or fourth alternative might be the best for the chord as a whole. 
      b.    I could pick the top three alternatives for the new note, and evaluate all of them based on the whole chord, and pick the one with the lowest score. That would be the optimum choice for that note, but it might screw up the other notes.
      c.    I could carry forward the top choices for each note for later inclusion in the evaluations of future notes.
      d.    What if I randomize the order of the choices, and then evaluate the best overall out of a few random arrangements. 
      e.    I could bite the bullet and build a reinforcement learning method to tune the chords. Reward for lowest score, and let the computer figure out how to get there. 
      f.    In any case, I will need a score system that can accept up to 10 simultaneous notes.
            I am calling a scoring function before changing a note that has already been changed:
                  prev_score = atu.score_chord_cents(chord, tonal_diamond_values, ratio_factor = ratio_factor)
            I check the score for this potential change and decide not to make the change:
                  score for the chord before changing chord = array([  0, 386, 702, 996, 204]): score = 1218.0
                  proposed new_note = 1004.0
                  score for the chord after making a change to chord = array([   0,  386,  702, 1004,  204]): score = 245.0

      How bad is 1018 as a note. It's a ratio of '9/5' with a num_dem count of only 14.
            starting to evaluate inx1 = 3, inx2 = 0
            Optimizer: ('9/5', 1018, 14), cent_deviation = 0.0
      How does it score the change from 996 to 1004?
            new value for note at index inx2 = 0, chord = array([   0,  386,  702, 1018,  204])
            score for the chord before changing chord = array([  0, 386, 702, 996, 204]): score = 1218.0 
      The high score was a result of not finding the ratio corresponding to 610 cents. We add 1000 to the score in this case.
            proposed new_note = 1004.0
            score for the chord after making a change to chord = array([   0,  386,  702, 1004,  204]): score = 245.0

2.    I tried different shuffles of my test chord, and ended up with different voicings. Some examples:
      prev_score = 186.0, tuned_chord = array([ 204, 1200,  702, 1018,  386])
      prev_score = 1263.0, tuned_chord = array([ 231,  386,  702, 1018, 1200]) # that seems awfully high!
      prev_score = 145.0, tuned_chord = array([1017,  702, 1200,  204,  435])
      prev_score = 127.0, tuned_chord = array([387,   0, 204, 702, 969]) # takes advantage of the +-1 cent manuever
      prev_score = 145.0, tuned_chord = array([1017,  702, 1200,  204,  435])
      prev_score = 186.0, tuned_chord = array([ 702,  204, 1200,  386, 1018])
      prev_score = 127.0, tuned_chord = array([386,   0, 702, 969, 204]) # best so far
      prev_score = 127.0, tuned_chord = array([  0, 386, 702, 969, 204]) # the original arrangements

3.    I remember that I previously hand coded to order of the evaluations in the tuning algorithm. 
            order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]])
      Could I do that if I don't know how many there will be? How can I build that array on the fly?

-------------------------------------------------
7/30/2023 To do today:

1.    What if I sorted the chord by midi note number, then reordered it after tuning to match the input order.
      Instead of trying, and failing, to order the premutations, order the input notes in such a way that provides the best tuning. Try it. They are already sorted: 
            chord = np.array([ [60, 73], [64, 92], [67, 76], [70, 66], [74, 127]])
      Still, when I play them on the keyboard, they are randomly arrayed. So sorting them first has value.

2.    Make more chorales using:
            The success was found with ratio_factor = 2, and dist_factor = 0.25. It was already 0.35, so this won't make much of a difference, except it might lead to midi note mismatches. I had forgotten that I changed that value previously. I regret the error.
      Try the dist_factor with these:
            14
            22
            28
            40
            37 - something is seriously wrong with this wav file. It sounds like a cat fight. 
            use mod = w
      The results were very disappointing. Boring. 

3.    Listen to the results of just the chorale with the new tuning knob settings. 
      It really highlighted the absurd tuning traps I'm getting into. Ugly. I'm going to do some more work to fix the chorale when I set the variables like this:
            show_sheet_music = False # show a png file of the sheet music for the original chorale
            print_report = False # show a report of the tuning of all the intervals
            show_volumes = False # show a graph of the volumes for each of the instrument collections over the time of the piece
            short_repeats = True # Bypass the repeats calculation and just do the minimum number of repeats. 
            mask = False # run the complex algorithm to create complex repeating arpeggios
            fing = False # play the arpggiated instrument collections: finger pianos, guitar strings, percussion, pizzicato strings
            wood = True # play the long held note instrument collections: brass, woodwinds, bowed strings, 
            csound = True # run the generated .csd file through csound to create a .wav file
            convolve = True # run the csound code that adds audio convolution Teatro Alcorcon in Madrid made by Angelo Farina
            ratio_factor = 2
            dist_factor = 0.25
      The volume is still too low. Also, see if you can have more than just the woodwinds, add the brass, but an octave lower?
      I keep increasing the volume_array with no result:
            volume_array +- 4 # increase the volume by 4. Has no effect.
      What is in the volume_array:
            chorale_in_cents.shape = (4, 258, 2), chorale.shape = (4, 258)
            volume_array.shape = (516,), volume_array = array([2., 2...., 2.])
      Why is the shape of volume array 2x the shape of chorale_in_cents? 258 * 2 = 516.

--------------------------
7/31/23 To do today:

1.    I ran a bunch of different values for the ratio_factor and dist_factor and created repprts on each. 
      There were some differences. Nothing major. But it still had some very sour notes regardless of the values for both factors.

2.    I also boosted the volume and included the brass in the mix, so it sounds better now. 
      Try one or two other chorales, see if you can avoid the sour notes.       

---------------------------------------
8/1/23 To do today:

1.    Follow on to the work yesterday making short wind only chorale pieces, I should gradually build up to the final form.
      a.    Vary the tuning for each one, making it a range of values. 
            15', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - some sour notes at the start
            17', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - at 0:30 some sour notes - many more throughout
            22', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4  - some zingers throughout 
            26', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - some sour notes throughoutout I get the feeling that that's true for all of them.
            28', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - a few sour notes, but not many.
            3', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - It seems like the more of these I listen to the more I like the character of the "wrong" notes.
            37', mod = 'x', ratio_factor = 2.0, dist_factor = 0.5 - zingers
            40', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4 - this one is much longer than the others 3:54 
            5', mod = 'x', ratio_factor = 2.0, dist_factor = 0.5 - more of the same
            11', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - sour notes up front
            14', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4
      b.    Before you go any further, see what happens if you clip the top_notes to just four values instead of what they are now.
            15', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4 - starts pretty far out there.
            17', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - gets pretty far out there throughout
            22', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - best so far, still has the zingers.
            26', mod = 'x', ratio_factor = 2.0, dist_factor = 0.5 - also pretty good
            28', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - Mighty fine.
            3', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - Also well done
            37', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - ✓
            40', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - ✓ but 3:39 
            5', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4 - gets pretty far out there.
            11', mod = 'x', ratio_factor = 2.0, dist_factor = 0.5 - mighty strange
            14', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - better than before.
      These are the only ones that are still remaining in the sflib directory.
      b2.   Clip to five top_notes values and see what that does. 
            15', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - much less far out there material
            17', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - much less far out there material
            22', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - very nice, fewer zingers towards the end
            26', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - was better with four top_notes. 
            28', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - Still mighty fine.
            3', mod = 'x', ratio_factor = 2.5, dist_factor = 0.4 - should be far from 12 TET - very mellow, fine
            37', mod = 'x', ratio_factor = 0.25, dist_factor = 4.0 - should be near 12 TET - very nice
            40', mod = 'x', ratio_factor = 2.0, dist_factor = 0.5 - far from 12 TET - very nice but too long
            5', mod = 'x', ratio_factor = 1.0, dist_factor = 1.0 - fine
            11', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - fine
            14', mod = 'x', ratio_factor = 0.5, dist_factor = 2.0 - Not as good as 4 top_note version but still fine. 
      So the conclusion is that the five top_note version, with ratio_factor around 1 and dist_factor inverse of rf, is the best.
                  valid_factors = np.array([0.75, .875, 1.0, 1.125, 1.25])
      c.    Set short_repeats = False
      d.    Add a finger piano function without the mask. Problem: The volume of the woodwinds is way too high. Fixed that:
                  volume_array += woodwinds_volume 
      e.    Add the mask
      f.    Listen to them and they are all crap. What went wrong with the mod = 'z' series?
--------------------------
8/2/23 To do today:

1.    Create a new 'z' series and rate it.
            ls -1 ~/Music/sflib/ball9-tbwv245.*z.wav
            grep 'version = ' save.txt
            15', mod = 'z', ratio_factor = 1.125, dist_factor = 0.89
            17', mod = 'z', ratio_factor = 1.125, dist_factor = 0.89
            22', mod = 'z', ratio_factor = 1.125, dist_factor = 0.89
            26', mod = 'z', ratio_factor = 0.875, dist_factor = 1.143
            28', mod = 'z', ratio_factor = 0.875, dist_factor = 1.143
            3', mod = 'z', ratio_factor = 0.75, dist_factor = 1.33
            37', mod = 'z', ratio_factor = 1.25, dist_factor = 0.8 - 5:34 - fast subtle - Gets exciting nice variety
            40', mod = 'z', ratio_factor = 1.125, dist_factor = 0.89 - 27:23 - long. moderately slow - Way too long
            5', mod = 'z', ratio_factor = 1.0, dist_factor = 1.0 - 3:53 - Slow - Nothing new 
            11', mod = 'z', ratio_factor = 0.75, dist_factor = 1.33 - 3:53 - moderatly fast - Nothing special
            14', mod = 'z', ratio_factor = 0.75, dist_factor = 1.33 - 7:57 - compex rhythm - Nothing original that hasn't been heard before.
------------------------
8/17/23 To do today:

1.    I've been away from here for a while, looking into large language models. 
      But I'd like to come back to music soon. Some ideas I thought of over there:

      Do I think I could make music with a large language model? Most transformer efforts used audio files, which don't permit retuning like midi files.

      What I would really like is a GUI that allows me to enter some notes on a midi keyboard, and then process that chord into just intonation, and then take that array of cents and volume and feed it into a python function that could play it using some of the python algorithmic music packages. I would choose the chord, it would present some options to me on the screen to modify the parameters of the python algorithms.
      Tempo, repeats, sparsity, volume, voices, envelopes, etc. All the things that make music interesting.

      Another thing I want to work on is letting the tuning algorithm include previous chords in it's decision about what cent values to use. Today I consider all the intervals in the chord, then transpose the chord to keep some key notes on the right values, prioritized by some notes over others. But I don't even look at the previous chord. I think that would be a good thing to do. And while I'm at it, maybe look at what future cords might produce. How many forward and backward could I go? 

      One way to do that is to feed the previous chord into the score function. Let this chord optimize across the four notes in this chord plus the 4 notes in the previous one. Then gradually increase the number of previous ones I look at. Prioritize this chord over previous ones, and decrease the priorities for previous ones based on how far away they are. 

      I think the optimization algorithm I am currently using can be adapted to this schema. Or I could explore reinforcement learning instead of optimization. I just heard a lecture by Yan Le Cun
      https://www.youtube.com/watch?v=vyqXLJsmsrk
      In the elcture, he said at one point that we must abandon Generative AI, RL, Probalistic, contrastive, and other approaches. In favor of model-predictive control. 
            https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/
      Objective-Driven AI is Turing Complete, everything is reduced to optimization compared less costly than LMM in computation per token. 

2.    Make a post on Substack that includes some of the y,x,y,z recently completed. 
      Include some that are just the chords without anything else. Just Bach in different tunings. I wrote up a long intro to introducing the examples, and substack didn't save a draft for me. What a drag. I'm so used to vscode saving stuff automatically that I didn't consider than Substack didn't do the same. 

      So I adjusted the notebook to produce four variations of #14:
            aa - ratio_factor = 2.0, dist_factor = 0.5
            ab - ratio_factor = 3.0, dist_factor = 0.33
            ac - ratio_factor = 0.5, dist_factor = 2.0
            ad - ratio_factor = 1.0, dist_factor = 1.0
      In the end of this run, they all sound about the same. The reports are nearly the same, usually differing by one cent on many of the intervals, and only rarely changing ratios.
      Exceptions:
      This is the one with ratio_factor = 0.5
      172 		['E♮', 'B♮', 'G♮', 'F♯']	[ 402 1104  718  606]	(0, 1, 702, '3/2') (0, 2, 316, '6/5') (0, 3, 204, '9/8') (1, 2, 386, '5/4') (1, 3, 498, '4/3') (2, 3, 112, '16/15')		80.0
      And here is ratio_factor = 3.0 
      172 		['E♮', 'B♮', 'G♮', 'F♯']	[ 402 1104  718  553]	(0, 1, 702, '3/2') (0, 2, 316, '6/5') (0, 3, 151, '12/11') (1, 2, 386, '5/4') (1, 3, 551, '11/8') (2, 3, 165, '11/10')		88.0
      One ratio with 11/8 instead of 4/3, and then 11/10 instead of 16/15.

---------------------
8/18/23 To do today:

1.    Isolate the sections of the chorale #14 that have the greatest differences between ratio_factor effects. 
      Choose a sufficient number to make musical sense, but maximize the differences. Run those segments through a tool chain that prints a report and a wav file. The goal is to show how this temperature-like variable controls a tuning's interestingness. What was the term Ivor Darreg used for the characteristic of a tuning? Flavor? 
      These are the chords that show difference from ratio_factor .5 to 3. Some use different cent values but the same ratios. I would not have expected that.
      Here are lines that have some difference: 46, 53, 74, 120, 142, 172, 176, 180, 204, 212, 230, 244, 246
      Of those, these are just one cent on one or more notes, but the same ratios. How can that happen? 
      74, 120
      This one is very strange:
      230 		['D♮', 'F♯', 'A♮', 'C♯']	[198 584 900  86]	(0, 1, 386, '5/4') (0, 2, 702, '3/2') (0, 3, 112, '16/15') (1, 2, 316, '6/5') (1, 3, 498, '4/3') (2, 3, 814, '8/5')		76.0 0.5
      230 		['D♮', 'F♯', 'A♮', 'C♯']	[239 555 941  57]	(0, 1, 316, '6/5') (0, 2, 702, '3/2') (0, 3, 182, '10/9') (1, 2, 386, '5/4') (1, 3, 498, '4/3') (2, 3, 884, '5/3')		59.0 3.0
      There are two notes that I would think would make different 12TET notes. How could I get through with a 5/4 vs 6/5 and a 10/9 vs 16/15 or 8/5 vs 5/3. These are clearly different functional notes.
      I'm not going to spend time researching that now. Instead, I'll just remove 74, 120, and 230 from the mix.
      Here's what remains:
            46, 53,  142,  172, 176, 180, 204, 212, 244, 246
      Let's listen to what measures 172 through 212 sound like. How long is it? About 23 seconds or so, depending on the tempo.
      Here are the results:
            file name                     retio_factor
            ball9-tbwv245.144.wav               4.0
            ball9-tbwv245.143.wav               3.0
            ball9-tbwv245.142.wav               2.0     
            ball9-tbwv245.141.0.wav             1.0
            ball9-tbwv245.140.75.wav            0.75
            ball9-tbwv245.140.5.wav             0.5
            ball9-tbwv245.14-0.125.wav          0.125
            ball9-tbwv245.14-0.0625.wav         0.0625
            ball9-tbwv245.14-0.031.wav          0.031

      From Deep Learning with Python by Francois Chollet, chapter 12:
            In order to control the amount of stochasticity in the sampling process, we'll instroduce a parameter called the softmax tempoerature, which characterizes the entropy of the probability distribution use for sampling: it characterizes how surprising of predictable the choice of the next word will be... Higher temperatures result in sampling distributions of higher entropy that will generate more surprising and unstructured generated data, whereas a lower temperature will result in less randomness and much more predictable generated data.
2.    New album using the z series:
      ls -lth ~/Music/sflib/ball9-tbwv245.??z.wav ~/Music/sflib/ball9-tbwv245.?z.wav
            ball9-tbwv245.14z.wav - slow start 
            ball9-tbwv245.11z.wav - something happened with this one. Very distorted.
            ball9-tbwv245.40z.wav - slow boring
            ball9-tbwv245.37z.wav - nice tempo - good ending.
            ball9-tbwv245.28z.wav - nothing there
            ball9-tbwv245.26z.wav - Interesting rhythm, little else
            ball9-tbwv245.22z.wav - something happened with this one. Very distorted.
            ball9-tbwv245.17z.wav - Better than the others 
            ball9-tbwv245.15z.wav - something happened with this one. Very distorted.
            ball9-tbwv245.5z.wav = something happened with this one. Very distorted.
            ball9-tbwv245.3z.wav - Not much there.
      The y series is all just chords, no music.
      ls -lth ~/Music/sflib/ball9-tbwv245.??y.wav ~/Music/sflib/ball9-tbwv245.?y.wav

-----------------------
8/19/23 To do today:

1.    Make the sample a complete phrase. It starts at the end of a measure and stops before the end of another.
      Include measures 11, 12, 13, 14
      chords = 256, measures = 16, start = 176.0, end = 240.0 - Wrong numbers

2.    Figure out why even with ratio_factor very low, like 0.031, it still produces low number ratios.

3.    Speed up the tempo. I hard set it to tempo = 100 in the code. Put it back the way it was after you are finished. 
      
4.    The convolve csound is totally screwing up the sound. Like it's in a deep tunnel. Fix it.
            util sndinfo:
            /home/prent/Music/sflib/ball9-tbwv245.14-0.031.wav:
                  srate 426, stereo, 32 bit unknown, 19.826 seconds
            util sndinfo:
            /home/prent/Music/sflib/ball9.wav:
                  srate 44100, stereo, 24 bit WAV, 19.838 seconds
      I don't think a srate of 426 is correct. I looked in ball9c.csd and found this:
            <CsInstruments>
            sr = 4replaceme
      That's not right. It should be:
            sr = 44100 
      I wonder how long that has been there like that.

5.    Run the whole set again, and see how it changes over time.
            4.0, 3.0, 2.0, 1.0, 0.75, 0.5, 0.125, 0.0625, 0.031
      In this passage, which is chorale = chorale[:,160:224] there is no difference between the last three values. All identical.
      No difference between 1.0 and 2.0
      How did these two not change through all the different ratio_factor values:
      10 ['D♯', 'A♮', 'F♯', 'G♮']	[ 282  900  584  669]	(0, 1, 618, '10/7') (0, 2, 302, '25/21') (0, 3, 387, '5/4') (1, 2, 316,  '6/5')  (1, 3, 231, '8/7') (2, 3,  85, '21/20') 139.0
      54 ['B♮', 'E♮', 'A♯', 'F♯']	[1104  402 1005  606]	(0, 1, 702, '3/2')  (0, 2,  99, '18/17') (0, 3, 498, '4/3') (1, 2, 603, '17/12') (1, 3, 204, '9/8') (2, 3, 399, '34/27') 154.0 
      All the same as these two rows, they never changed. Very high scores. Why?
      looking at #10, we can see that it's the second half of a movement to another chord. G natural in the bass F# in the tenor, A# in the alto D# in the soprano moving to E minor, then E major
      #54 is also a passing tone from one chord to the destination.
      Take a close look at ratio_factor 4.0. There is a switch of F# from one value to another at around chord #44. It goes from 584 to 553, more than 30 cents away. Noticable. It takes what should be a dotted quarter note, followed by a eighth note, and turns it into a quarter note and two eighth notes.
      40 		['F♯', 'A♮', 'C♮', 'D♮']	[ 584  900   16  198]	(0, 1, 316, '6/5')  (0, 2, 568, '25/18') (0, 3, 386, '5/4')   (1, 2, 884, '5/3')   (1, 3, 702, '3/2') (2, 3, 182, '10/9')		95.0
      44 		['F♯', 'G♮', 'B♮', 'G♮']	[ 553  718 1104  718]	(0, 1, 165, '11/10')(0, 2, 551, '11/8')  (0, 3, 165, '11/10') (1, 2, 386, '5/4')   (1, 3,   0, '1/1') (2, 3, 386, '5/4')		79.0
      Was F# one of the top_notes? Should it have been. I remember at one point I deliberately reduced the number of top_notes
      F#. What would happen if I swapped the B and F#?
      keys[top_notes[0] ay(['A♮', 'E♮', 'C♯', 'B♮', 'F♯'] so it would try to move the first four top_notes before moving the F#. B natural is more important, so it moves instead of the F#
      'bwv245.14': array([[   9,    4,    1,   11,    6,    8,    2],
                          [ 900,  402,   86, 1104,  584,  788,  198]])}
      'bwv245.14': array([[   9,    4,    1,   6,   11,    8,    2],
                          [ 900,  402,   86, 584, 1104,  788,  198]])}
      So I swapped it. Now F# is higher in priorty than the B natural. 
      Look again at chords 40 and 44:
      40 		['F♯', 'A♮', 'C♮', 'D♮']	[584 900  16 198]	(0, 1, 316, '6/5') (0, 2, 568, '25/18') (0, 3, 386, '5/4') (1, 2, 884, '5/3') (1, 3, 702, '3/2') (2, 3, 182, '10/9')		95.0
      44 		['F♯', 'G♮', 'B♮', 'G♮']	[ 584  749 1135  749]	(0, 1, 165, '11/10') (0, 2, 551, '11/8') (0, 3, 165, '11/10') (1, 2, 386, '5/4') (1, 3, 0, '1') (2, 3, 386, '5/4')		79.0
      That now sucks slightly less than before, but now the B is compromised. Previously it was 1104, now it's 1135. That's a big difference. And it sticks out. But only for the ratio_factor = 4, right? Actually, all the others turn the second F# into a different note, just not as different as 4.0. So it's either going to turn the F# from the 584 that I like, into the 553 or 606, neither of which do I care for. with 31 cents flat or 22 cents sharp, if the F# is lower priority than B natural. I should note that B natural is the most common note in the chorale.
      20 most common cent values, midi note, counts with the most common at the bottom:
            (584, 6, 16) F#
            (900, 9, 18) A
            (86, 1, 22)  C#
            (402, 4, 46) E
            (1104, 11, 62) B
      Going back to the original prioroty of F# and B, since B is so common, I find that ratio_factor 2.0 introduces the 606 F#, which is actually very close to the 12TET F#, and the sound is much less jarring than the 553 F# with ratio_factor 3 and 4. Also, note that 606 is a 4/3 away from the B natural, so I does sound harmonious. The previous note only forces the F# to 584 because the A natural takes priority over the F# in top_notes. 
      40 		['F♯', 'A♮', 'C♮', 'D♮']	[ 584 900   16  198]	(0, 1, 316, '6/5') (0, 2, 568, '25/18') (0, 3, 386, '5/4') (1, 2, 884, '5/3') (1, 3, 702, '3/2') (2, 3, 182, '10/9')		95.0
      44 		['F♯', 'G♮', 'B♮', 'G♮']	[ 606 718 1104  718]	(0, 1, 112, '16/15') (0, 2, 498, '4/3') (0, 3, 112, '16/15') (1, 2, 386, '5/4') (1, 3,   0, '1/1') (2, 3, 386, '5/4')		87.0
      Which leads me to think that I might want A lower in priority than F#. Don't put too much stock in those frequency counts, because they are only relevant for this excerpt of 64 out of 256 chords. 25%. 
      Back to the #10 and 54. Why do those end up there and can I do anything about it. They are not audible problems from my viewpoint. Move on.

6.    A bigger problem is why very low ratio_factors still produce low ratios. Should I stop dividing the score by the ratio_factor? I think it is misleading when I do that. 
      I added this on 5/5/23.
            4.    I modified score_chord_cents to return round(score / ratio_factor,1). 
                  That means anywhere I've been doing that bit of arithmetic needs to be changed. 
      Removing this calculation might cause some other trouble. Think about how that score is used. What if it suddenly comes back much higher or lower than before. For example, how would the score change for ratio_factor = 0.0125? or 4.0? It really won't make much difference, because the primary hidden use of the score is to compare to potential intervals, using the same ratio_factor, so the comparison won't change. It will still pick one over the other with no change to the result. 
      Also, how is the score calculated in the report? It calls score_chord_cents, so the change to that function will show up in the report. But remember, the score only reflects the size of the ratios. Consider what the scores will be if we are no longer dividing by the ratio_factor. That's easy, they will be ratio_factor times higher. If score is 154 and the ratio_factor is 0.125, it will now become 19 or so. Something doesn't seem right here. Why are the scores so uniform across different ratio factors if the score is being divided by the ratio_factor before being reported? Here are the average scores for the 64 chords being studied today, when the ratio_factor is 0.125, 0.0625, 0.031, 0.5, 1.0, 2.0, 3.0, 4.0:
            Average score was: 69.2
            Average score was: 69.2
            Average score was: 71.0
            Average score was: 68.2
            Average score was: 69.2
            Average score was: 66.4
      That smells strange to me. I found what was going on. In score_chord_cents I sum the scores across all six of the interval combinations. Here is the end of the function:
                  score += ratio_factor * tonal_diamond_values[index_to_limits, 2] # 2 is max of num_den for this discovered interval
                  logging.debug(f'in score_chord_cents. {round(score / ratio_factor,0) = }') # 8/19/23 should I make this division?
            return round(score / ratio_factor,1)
      It multiplies the ratio_factor times the sum of the numerator and denominator of each interval, and adds that to the accumulated sum. Why do I do that? Because I want to give a higher score to intervals that have larger ratios. But if they are all multiplied by the same amount, that will have no effect. And if it has no effect, the only thing that matters is dist_factor, the inverse of ratio_factor. The goal of having both a ratio_factor and a dist_factor was to provide two levers the control the tuning. So lets see how they would operate with real examples. Would they ever pick one ratio over another and why. Here is the key optimization line in the whole system:
            best_choice_overall = np.argmin(abs(tonal_diamond_values[indeciis_to_tonal_diamond,1] - distance) * dist_factor + tonal_diamond_values[indeciis_to_tonal_diamond,2] * ratio_factor) % 1200
      How does it work? It takes the distance between the current interval and the target interval, and multiplies that by the dist_factor. Then it adds the numerator and denominator of the current interval, multiplied by the ratio_factor. Then it finds the minimum of that sum. So if the distance is 0, then the numerator and denominator of the current interval are the only thing that matters. If the distance is large, then the dist_factor is the only thing that matters. So the ratio_factor is only important when the distance is small. That's why the scores are so uniform across the different ratio_factors. 
      
      Let's do some examples and see if it does what I intended:
      If the scale of the distance and the scale of the numerator plus denominator are the same, then it should work. 
      Distances are in cents. The distance variable above is how far apart in cents is a potential interval. Let's look at the choices made to produce this 154 score:
            54 ['B♮', 'E♮', 'A♯', 'F♯']	[1104  402 1005  606]	(0, 1, 702, '3/2')  (0, 2,  99, '18/17') (0, 3, 498, '4/3') (1, 2, 603, '17/12') (1, 3, 204, '9/8') (2, 3, 399, '34/27') 154.0 
      We start with 0 - 1 as 1100 - 402 = 698 cents. Possible alternative intervals choices are all worse than 702 at '3/2'
      1100 - 702 = 398 cents, so we assign note 1 to 398 
      note 0 is 1100 cents.
      0 - 1 is abs(1100 - 400), 700 cents. The closest interval to 700 cents is '3/2' at 702 cents 1100 - 702 = 398. note 1 is 398
      0 - 2 is abs(1100 - 1000), 100 cents. The closest interval to 100 cents is '18/17' at 99 cents 1100 - 99 = 1001. note 2 is 1001.
      0 - 3 is abs(1100 - 600) = 500 cents. The closest interval to 500 cents is '4/3' at 498 cents. 1100 - 498 = 602. note 3 is 602.
      1 - 2 is abs(402 - 1001) = 599 cents.  The closest interval to 601 cents is '17/12' at 603 cents. 402 - 603 = -201 + 1200 = 999. note 2 might be better as 999 instead of 1001. How do we check? Score them both and pick the best. 
            Score 1100, 398, 1001, 602 score is 154 <-- winner. We don't move note 2. It stays where it is. 
            score 1100, 398, 999, 602 score is 182
      What is the consequence of not moving 2? The interval 1 - 2 is not opbimal. It's 603 cents instead of 600. But the interval 0 - 2 is optimal. It's 99 cents instead of 100. So we have a tradeoff. We can't have both.
      1 - 3 is abs(398 - 602) = 204 cents. The closest interval to 204 cents is '9/8' on the nose. note 3 stays at 602
      2 - 3 is abs(1001 - 602) = 409 cents. The closest interval to 409 cents is '34/27' at 399 cents. 1001 - 399 = 602. note 3 stays at 602
      So if you add the numerators and the denominators you get 3+2+18+17+4+3+17+12+34+27+9+8 = 154 

      Also, why are we not finding mismatches with very high ratio_factors? I used to have to keep it below 3 to avoid having a note drift from the original 12TET note to another. It happened all the time. But not on the bwv245.14? That seems odd. 

7.    Something is weird with try_permutations. It's completely departing from the initial notes. I
      t's like they are pulling chords out of the air. 
      Something goes wrong here: 
            chord_in_1200 = np.array(note_to_1200_edo(initial_chord, original_12))
      Why does it need original_12. It's because try_permutations expects numbers in midi format, not cents. 
      So what have I learned from this? I still have no better than 139 and 154 as scores. They are the right scores. I had no reason to doubt my previous work. I just didn't trust it, and wanted to see if there was something missing. Guess not.
      Hold everything. I found a problem. When I set ratio_factor = 5.0, I got better scores:
            score for chord4 = array([300, 900, 600, 700]) in 12TET: 1001.0
            out of find_intervals chord4: chorale_in_cents = array([300, 892, 599, 727]), score = 264.0
            original 12TET values: [3 9 6 7]
            chord4 = array([300, 892, 599, 727])
            out of try_permutations chord4: final_result = array([305, 888, 572, 691]), score = 127.0
            original 12TET values: [3 9 6 7]

            score for chord5 = array([1100,  400, 1000,  600]) in 12TET: 1001.0
            out of find_intervals chord4: chorale_in_cents = array([1100,  398, 1001,  615]), score = 317.0
            original 12TET values: [11  4 10  6]
            chord5 = array([1100,  398, 1001,  615])
            out of try_permutations chord4: final_result = array([1100,  399,  981,  666]), score = 86.0
            original 12TET values: [11  4 10  7]
      This happened when I explicitly called try_permutations with ratio_factor = ratio_factor. It must not be including that when it's called inside adaptive_tuning_util 
            final_result, best_score = try_permutations(initial_chord, tonal_diamond_values, 70, original_12 = original_12) # this is 
      It's missing the reference to ratio_factor and dist_factor. Fix this!
      I'll have to look into this tomorrow. Time for a walk.

------------------------
8/20/23 To do today:    

1.    Make sure that any function that takes in a keyword argument that has a vital function is always called with the keyword argument value.
      If you don't do that, then the default keyword argument value will take effect, and you may not like what the default is. Especially for ratio_factor and dist_factor. Those are missing in several calls. Check what others might also be missing.
      Example #1: 
            def try_permutations(initial_chord, tonal_diamond_values, ratio_factor = 1, dist_factor = 1,  70, original_12 = np.arange(0, 1200, 100)):
      There is no reason to worry about max_score or original_12. They are useful defaults. That is not the case for ratio_factor and dist_factor.
            look for this: = try_permutations
            final_result, best_score = try_permutations(initial_chord, tonal_diamond_values, ratio_factor = ratio_factor, dist_factor = dist_factor)
      That was it for calls to try_permutations
            def improve_chord_rolls(initial_chord, top_notes, chord_number, tonal_diamond_values, \
            roll = 4, dist_factor = .2, ratio_factor = .2, stop_when = 25, \
            flats = True, min_score_perm = 100, original_12 = np.arange(0, 1200, 100)):
            look for this: = improve_chord_rolls
            chord_1200, score = improve_chord_rolls(previous_chord, top_notes, chord_number, tonal_diamond_values, dist_factor = dist_factor, ratio_factor = ratio_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12) # optimize to cents in the limit_31_values array
            chord_1200, score = improve_chord_rolls(chord, top_notes, chord_number - 1, tonal_diamond_values, dist_factor = dist_factor, ratio_factor = ratio_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12)
            def score_chord_cents(chord_1200, tonal_diamond_values, ratio_factor = 1):
            look for this: = score_chord_cents
            prev_score = score_chord_cents(initial_chord, tonal_diamond_values, ratio_factor = ratio_factor)
            def find_intervals(initial_chord, tonal_diamond_values, dist_factor = 1.0, ratio_factor = 1.0, range = 6): # wrong order! does that matter? No. It's just being a perfectionist. Ha! Mister "work on it until the error message goes away" is calling me a perfectionist.
            look for this: = find_intervals
            result = find_intervals(initial_chord, tonal_diamond_values, ratio_factor = ratio_factor, dist_factor = dist_factor) 
            result = find_intervals(np.roll(best_choice,inx), tonal_diamond_values, ratio_factor = ratio_factor, dist_factor = dist_factor) 
      Notice that this has ratio_factor first and dist_factor second. Fix that. Change the argument in the find_intervals function.
            def find_intervals(initial_chord, tonal_diamond_values, ratio_factor = 1.0, dist_factor = 1.0, range = 6):
      I think I found them all. 

2.    Fix the mismatches that arise after fixing the ratio_factor being missing from the call to try_permutations. 
            mismatch between the original MIDI notes chord_num = 55, midi_notes = array([71, 64, 58, 54]), chord_12_rounded =  array([70, 60, 55, 52])
            Original scale degrees: midi_notes % 12 = array([11,  4, 10,  6])
            Scale degrees derived from the cent values: chord_12_rounded % 12 = array([10,  0,  7,  4])
            keys[midi_notes % 12] = array(['B♮', 'E♮', 'A♯', 'F♯'], dtype='<U2')
            new note: chord_12_rounded[delta] = 60, original note: midi_notes[delta] = 64
            Warning: This mismatch is a serious problem. The algorithm tuned a note to a different midi note than the composer intended.
      Reduce it from 4.0 to 2.0
      Scores make more sense now: for ratio_factor in [2.0, 1.0, 0.75, 0.5, 0.125, 0.0625, 0.031]:
            ratio_factor Average  Total  Maximum
            2.0          68.8    1377.0  127.0
            1.0          71.0    1419.0  154.0
            0.75         81.8    1635.0  154.0
            0.50         121.6   2433.0  192.0
            0.25         163.6   3272.0  237.0
            0.125        166.2   3325.0  237.0  <-- no change between 0.125 and 0.031
            0.0625       166.2   3325.0  237.0
            0.031        166.2   3325.0  237.0
      These are the kind of scores I expected yesterday, but did not see.
            
ratio_factor = 0.25
Maximum score was: 237.0
Total score was 3272.0
Average score was: 163.6
--------------------------
8/21/23 to do today:

1.    Take a look at the ideas from people on Facebook responding to Sunday's Substack post here:
            https://microtonalnotes.substack.com/p/tuning-temperatures
            Paul Erlich
            I suggest an adaptive tuning approach.
            Even Partch admitted that ratios of 25 have no appreciable "justness" -- the ear just gives up. On the other hand, most of them are close to simpler ratios and turn into them when just tuning either of its two pitches by ear in whatever direction reduces roughness/beating and increases clarity/coherence.
      His metric is clear: reduce roughness and beating, while increasing clarity and coherence. How can I measure those? I'm already doing that. 
            Every chord will be consonant or dissonant depending, in part, on how many intervals (a 4-note chord has 6 intervals) are close "enough" to *simple*-integer ratios (and often larger Otonal chords as well as mere dyads) -- and normally the goal of adaptive tuning is to get them closer than any fixed tuning would. Sometimes adaptive JI can do the job but sometimes that's not practicable.
      He is advocation not true just, but getting close to the ideal just, no farther away than necessary, and better than a fixed tuning. He calls that adaptive just. 
            Another goal is to avoid abrupt shifts in the pitch of any note.
      I can do this using my top_notes, which picks notes to stay in place based on priority. It's not perfect, but it's pretty good...

            While retuning motions and/or drifts in strict JI renditions are one or more commas in magnitude, adaptive tuning reduces these to fractions of a comma by spreading the motion among all the chord changes in a progression.
      This seems like an admirable goal. I doubt the result would be audible. Or worth the effort.             
                  http://tonalsoft.com/monzo/vicentino/vicentino.aspx
      I can't follow this article. But at one point I was struck by the idea of approximating the 7:4 ratio, which is 969 cents. Perhaps what I could do is create a range of values for all intervals, and pick the one that would cause the least trauma to other notes in the chord. 

            James Kukula suggests this: https://www.cvxpy.org/examples/basic/mixed_integer_quadratic_program.html
      Could not get it to work. Better than trying to choose a library, first figure out what you are trying to do. 
      
      Picking the example of chords 40 and 44 in the exceprt above:
            40 ['F♯', 'A♮', 'C♮', 'D♮'] [ 584  900   16  198] (0, 1, 316, '6/5')  (0, 2, 568, '25/18') (0, 3, 386, '5/4')   (1, 2, 884, '5/3') (1, 3, 702, '3/2') (2, 3, 182, '10/9') 95.0
            44 ['F♯', 'G♮', 'B♮', 'G♮'] [ 606  718 1104  718] (0, 1, 112, '16/15') (0, 2, 498, '4/3') (0, 3, 112, '16/15') (1, 2, 386, '5/4') (1, 3, 0, '1/1') (2, 3, 386, '5/4') 87.0

      The real trouble is that the F# starts at 584 and is forced up to 606 during a held note. That's the problem that causes the most pain. I can accept most other problems, but that one violates what the composer wanted. Bach clearly wanted the same note to last 3 1/16th notes at that point in the piece. What if I spent those three 1/16th notes taking my time to climb from 584 to 606. Maybe started at 584 for one 1/16th note, then moved for another 1/16th, note then arrived at 606 and stayed there for the third 1/16th note. I bet that would sound good. 

      How could you systemetize that? I could have a function that searched for notes that met a particular pattern.
      Meet all these characteristics:
      1.    adjacent note that are different in cents by any amount
      2.    but they round to the same 12 TET note.
      3.    If you find this, then generate the requisite glide to get from the starting note to the ending note on the right schedule.
      I think that would hit the nail on the head. Let's do a quick inspection of chorale_in_cents (4, 66, 2). 

      How would you like to represent the glide. Maybe an additional dimension in chorale_in_cents that represented the glide. It would be zero in case there is no movement, but would contain a signed integer in cents to move. It would change all the notes that participate in the slide to the same cent value, and the same glide value. That would be necessary to prevent the downstream processes from thinking they are different notes with starting envelopes. But I would also have to make sure that the notes in the set would not be subject to the kind of voids that create new notes, because they would sound like repeated short notes that glide, attracting attention that was no intended. It might require a rule that if a note has a glide it can't be split by a void downstream. It can be repeated any number of times, since that would just make the slide take longer. Perhaps I can tell the woodwinds_part function to respect the glide, and the finger_piano_part to ignore it. Let's start with just the winds and see what happens. 

2.    Fix the trouble connecting to the ThinkCentre virtual python session.
            http://localhost:8888/tree?token=4e9e46c39765685d464242461ee92dd24de31a7a64a76d50
            http://192.168.68.64:8888/tree?token=4e9e46c39765685d464242461ee92dd24de31a7a64a76d50
      
      Refuses to connect from the T15. I can connect to the virtual python on the T15 on the T15 though, and that works. For now.
      I created a toolbox just for vscode, and it seems to be working now.

---------------------------
8/22/23 to do today:

1.    Consider a different solution to the problem of a note changing cents during the course of a held note. 
      Instead of changing chorale_in_cents by adding a glide column, wait until later in the process, like in woodwinds_part, or sooner. I don't need this in finger_piano_part, where it would be nothing but trouble with the arpeggios.  
      I'll have to be very careful about this so that I don't screw up the ability to make real music with this code I already have. 
      Start by just reporting the cases of notes that change cents while still rounding to the same note. Like this:
            Same 12TET note, diff cent: inx = 22, delta_cents = 27, D♯, prev_note = 290, note = 317
            Same 12TET note, diff cent: inx = 44, delta_cents = 22, F♯, prev_note = 584, note = 606
            Same 12TET note, diff cent: inx = 140, delta_cents = -1, E♮, prev_note = 402, note = 401
            Same 12TET note, diff cent: inx = 154, delta_cents = 27, B♮, prev_note = 1104, note = 1131
            Same 12TET note, diff cent: inx = 156, delta_cents = -27, B♮, prev_note = 1131, note = 1104
            Same 12TET note, diff cent: inx = 186, delta_cents = 50, A♯, prev_note = 970, note = 1020
            Same 12TET note, diff cent: inx = 208, delta_cents = 35, G♮, prev_note = 668, note = 703
            Same 12TET note, diff cent: inx = 220, delta_cents = 27, B♮, prev_note = 1104, note = 1131
            Same 12TET note, diff cent: inx = 252, delta_cents = 49, F♯, prev_note = 584, note = 633           
      So I would say I'm surprised at how many fit into this category. I had no idea there were so many, in just four measures there were 9 cases of changing cents when using the same 12 TET note. That note should be made to move. The inx above is counting notes, not chords. So there are 64 chords in the excerpt, and 256 notes. So 9 out of 256 is 3.5%. That's still a lot.

--------------------------
8/23/23 To do today:

1.    Pay attention to the ideas coming from Facebook.
      James Kukula suggest simulated annealing. From Wiki:
      Simulated annealing (SA) is a probabilistic technique for approximating the global optimum of a given function. Specifically, it is a metaheuristic to approximate global optimization in a large search space for an optimization problem. For large numbers of local optima, SA can find the global optima.[1] It is often used when the search space is discrete (for example the traveling salesman problem, the boolean satisfiability problem, protein structure prediction, and job-shop scheduling). For problems where finding an approximate global optimum is more important than finding a precise local optimum in a fixed amount of time, simulated annealing may be preferable to exact algorithms such as gradient descent or branch and bound.

      It relies on a variable called temperature, which starts high, and causes the algorithm to choose options that are non-optimal. As temperature gradually decreases, it searches only the optimum. 

      In general, simulated annealing algorithms work as follows. The temperature progressively decreases from an initial positive value to zero. At each time step, the algorithm randomly selects a solution close to the current one, measures its quality, and moves to it according to the temperature-dependent probabilities of selecting better or worse solutions, which during the search respectively remain at 1 (or positive) and decrease toward zero.

      The main loop for simulated annealing consists of generating neighbor candidates which are just potential solutions which are then randomly accepted based on an ever increasingly more stringent threshold.

      Some implementations in python: https://nathanrooy.github.io/posts/2020-05-14/simulated-annealing-with-python/


2.    I adjusted the reporting of moving notes to include those that are between adjacent notes. Now there are ten notes in seven chords:

      chorale_in_cents.shape = (4, 66, 2) - it's only 66 because that final chord is held longer than specified in the score.
      top notes:
            A♮	E♮	C♯	B♮	F♯
            900	402	86	1104	584
      chord# 3, chord = array([1132,  633,  318,  900]), chord_12 = array([11,  6,  3,  9]), chord_names = array(['B♮', 'F♯', 'D♯', 'A♮'], dtype='<U2')
      chord# 4, chord = array([1104, 1104,  402,  788]), chord_12 = array([11, 11,  4,  8]), chord_names = array(['B♮', 'B♮', 'E♮', 'G♯'] octave = array([0, 5, 5, 4])
      Same 12TET note, diff cent: chord# 4, note# 0, delta_cents = -28, B♮, prev_note = 1132, note = 1104
      chord# 7, chord = array([1104, 1104,  402,  788]), chord_12 = array([11, 11,  4,  8]), chord_names = array(['B♮', 'B♮', 'E♮', 'G♯'], dtype='<U2')
      chord# 8, chord = array([ 86, 900, 401, 668]), chord_12 = array([1, 9, 4, 7]), chord_names = array(['C♯', 'A♮', 'E♮', 'G♮'], dtype='<U2')
      Same 12TET note, diff cent: chord# 8, note# 2, delta_cents = -1, E♮, prev_note = 402, note = 401
      chord# 9, chord = array([ 86, 900, 401, 668]), chord_12 = array([1, 9, 4, 7]), chord_names = array(['C♯', 'A♮', 'E♮', 'G♮'], dtype='<U2')
      chord# 10, chord = array([317, 900, 584, 703]), chord_12 = array([3, 9, 6, 7]), chord_names = array(['D♯', 'A♮', 'F♯', 'G♮'], dtype='<U2')
      Same 12TET note, diff cent: chord# 10, note# 3, delta_cents = 35, G♮, prev_note = 668, note = 703
      chord# 21, chord = array([ 290, 1104, 1104, 1104]), chord_12 = array([ 3, 11, 11, 11]), chord_names = array(['D♯', 'B♮', 'B♮', 'B♮'], dtype='<U2')
      chord# 22, chord = array([ 317,  900, 1131, 1131]), chord_12 = array([ 3,  9, 11, 11]), chord_names = array(['D♯', 'A♮', 'B♮', 'B♮'], dtype='<U2')
      Same 12TET note, diff cent: chord# 22, note# 0, delta_cents = 27, D♯, prev_note = 290, note = 317
      Same 12TET note, diff cent: chord# 22, note# 2, delta_cents = 27, B♮, prev_note = 1104, note = 1131
      Same 12TET note, diff cent: chord# 22, note# 3, delta_cents = 27, B♮, prev_note = 1104, note = 1131
      chord# 23, chord = array([ 317,  900, 1131, 1131]), chord_12 = array([ 3,  9, 11, 11]), chord_names = array(['D♯', 'A♮', 'B♮', 'B♮'], dtype='<U2')
      chord# 24, chord = array([ 402,  788, 1104,  402]), chord_12 = array([ 4,  8, 11,  4]), chord_names = array(['E♮', 'G♯', 'B♮', 'E♮'], dtype='<U2')
      Same 12TET note, diff cent: chord# 24, note# 2, delta_cents = -27, B♮, prev_note = 1131, note = 1104
      chord# 43, chord = array([584, 900,  16, 198]), chord_12 = array([6, 9, 0, 2]), chord_names = array(['F♯', 'A♮', 'C♮', 'D♮'], dtype='<U2')
      chord# 44, chord = array([ 606,  718, 1104,  718]), chord_12 = array([ 6,  7, 11,  7]), chord_names = array(['F♯', 'G♮', 'B♮', 'G♮'], dtype='<U2')
      Same 12TET note, diff cent: chord# 44, note# 0, delta_cents = 22, F♯, prev_note = 584, note = 606
      chord# 53, chord = array([ 86, 402, 970, 584]), chord_12 = array([ 1,  4, 10,  6]), chord_names = array(['C♯', 'E♮', 'A♯', 'F♯'], dtype='<U2')
      chord# 54, chord = array([1104,  402, 1020,  633]), chord_12 = array([11,  4, 10,  6]), chord_names = array(['B♮', 'E♮', 'A♯', 'F♯'], dtype='<U2')
      Same 12TET note, diff cent: chord# 54, note# 2, delta_cents = 50, A♯, prev_note = 970, note = 1020
      Same 12TET note, diff cent: chord# 54, note# 3, delta_cents = 49, F♯, prev_note = 584, note = 633

      The one between chord 3 and 4 shows the movement of one of the top_notes, a B from 1132 to 1104 cents. What would I have to do to mitigate that?
      Chord 3 was transposed to keep the A on 900, moving the B, which is the tonic of that chord. But A is the most common note in the piece. And I can't slide because it's across two different notes. I suggest leaving it as is. I have to go all the way down to 0.125 ratio_factor to have the B not move. But the strangeness persists. It sounds like the chord goes up on the ratio_factor = 1, but stays put for ratio_factor = 0.125. 
      Here is rf = 0.125: [1104  606  303  900]
                          [     1104  402  806]
      and rf = 1.0        [1131  633  317  900]
                          [     1104  402  788]
      It's like there was an octave shift in one of the notes. No, it was a change of timbre caused by the flute going silent on the second chord, and the other instruments going up to take its place. Aural illusion.           
      chord 7 to 8 is one cent movement. Not noticable. Its a movement from one 12 TET note to the same 12 TET, but too small to cause worry.
      chord 9 to 10 G♮ 35 cent movement should be a slide. This would prevent forming two notes when it should be one that slides.
      chord 21 to 22 has three voices in need of a slide, all of which would prevent forming two notes when it should be one slider.
      chord 23, 25 has the B sliding 
      chord 43, 44 F# is the one that started the whole discovery. It should definitely be a slide.
      chord 53, 54 two notes A♯, F♯ both should slide. 
      So out of this set of 64 notes, we have one that will not actually sound due to octave = 0, and the nive that should slide. So slide them all. For now.

      chords 3,4 could stay the way it is, or slide down from 1132 to 1104. Either would be acceptable, in my opinion. The composer wanted separate notes and the notes are separated. The trouble comes in when we make the flute silent on the B in chord 4. If I slide the chord 3 note 0 B it won't get heard because the octave makes it go silent. So even if I slide, it won't cause trouble because it's silent. Now other issues may crop up when I try to add the slides. 
      
      
3.    So where should I put the code to make the slides. 
      My preference is after the finger_piano_part and woodwinds_part split, because then I can only slide the notes going to the woodwinds_part.      
      Here are some of the functions that I will have to use to make the slide:
            dmu.make_ftable_glissando(t_num, gliss_type, ratio): where t_num is a table number I need to keep track of, gliss_type = 'cubic64_64_128', ratio is what you would expect it to be. It returns 
                  fn_array = np.array([t_num, 0, 256, -6, 1, 64, np.average((1, ratio)), 64, ratio, 128, ratio])
            You may decide that that line is all you need because you are only having one type of slide.
            You will have to do something with the fn_array returned. Use the function build_slides as a model. That slides every note in a chord to another chord, which is not what I need. 
            1. call make_ftable_glissando pasing a t_num, gliss_type, and a decimal ratio, returning fn_array, or execute the critical line. 
            2. Check the newly created fn_array against all the others using np.allclose(fn_array, stored_fn_array) - It does some slicing of the array to exclude element 0, which is the table number. 
                  The fn_array format is how the gliss arrays are stored. They are only written out when the csound file is created.
            3. If you found the exact same gliss in thee stored_fn_array, store that one in the array variable gliss, which will be used later.  
                  gliss = stored_fn_array[0] # element 0 is the table number, I think.
               If you did not find it, then it's new and needs to be stored in the variable gliss, and in stored_fn_array, incrementing the table number t_num.
                  4. You have to pad the gliss so that all the gliss arrays are the same size. That may not be necessary for my use case.
                  5. Append the new gliss to the global variable stored_gliss, which I need to create.
            
            thin(arr): if we want to slide across several notes, such as 1,1,1,1,1,2,2,2,2,2,2 this will convert that to 1,2. You will have to keep track of how long the array was before it's thinned out. And we will only send two note values in this use case.

--------------------------
8/24/23 To do today:

1.    Pick up where you left off yesterday implementing slides to fix different cent values for the same consecutive 12 TET note.
      Try to put all the information into a working slide that can be stored in a global array (meybe), and the t_num stored in another array, moved to the gliss array that is part of notes_features_15. Can you do that only in woodwinds_part? You don't want it in finger_piano_part.

2.    Continued examination of alternatives for searching for the optimum, and avoiding local minima.
      a.    Reinforcement learning approach. A few years ago it was the hottest thing, but transformers seem to have driven it out. Is there some combination of RL and LMM that I could use. Or stable baselines. 
      b.    Consider adding some randomness to the permutations method along the lines of simulated annealing.  Plan on multiple trips through the permutations, slowly reducing the randomness as we go, until a final run that has none. Temperature controlled randomness. How many trips? Early stopping if you get a good score? 
      c.    Does python offer a faster way to rearrange the new values after permutations? What do we know after the permutations?
            1.    You have the desired four notes in the chord expressed in cents. Some may have moved away from the original 12 TET value, and we need to catch that earlier in the process. Don't allow an assignement of a cent value that does not round to the original 12 TET value. In fact, don't include it in the range of ratios to even consider. You have the cent values of all the ratios. Calculate if the cent value, when added to the cent value of the first note in the interval, would round to a different 12 TET value.
            2.    You have the original 12 TET values.
            3.    You can round the cent values to 12 TET values for each note. 
            4.    Can you rearrange the cent values so that they line up with the original 12 TET positions in the chord? I think there is a python shortcut to do that.
      d.    What if I pile the whole chorale into a big model that does all of the notes as one big optimization task. Or perhaps one measure at a time in a sliding window.

--------------
8/26/23 To do today:

1.    Figure out why the grand total score is equal to the last score obtained.

2.    Make it optional in try_permutations to include the choices that are excluded today due to combinations.
            if inx in np.array([0, 18, 16, 9]): # skip the ones that were already checked in improve_chord_rolls
                 logging.debug(f'skipping {inx = }, already checked')
      In my case they are not already checked. Make a default argument already_checked = True, that I can set False to permit try_permutations to check them.

3.    See if you can relax the requirement that each chord must contain exactly 4 notes      
      I fixed try_permutations, but it calls find_intervals, which is still hard coded to 4 notes. Fix that.
      It turns out that the order of the compares in find_intervals dramatically affects the performance. The average, total, and max scores all went up. Total to 1800 from 1287. Average to 90 from 64. Max to 237 from 154. How can I make that order work with different numbers of notes in a chord?
            order_of_compares = np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]]) # 12 different compares
            order_of_compares = np.array(list(combinations(np.arange(initial_chord.shape[0]),2)))
                              
      So the hard coded order_of_compares has twice as many checks. It's not the order, it;s the fact that there are more checks. 
      What if I repeated the array, backwards? First one is hand coded, the second one is the combination algorithm. 
                  np.array([[0,1], [1,2], [2,3], [3,0], [0,2], [0,3], [1,3], [1,0], [2,0], [3,1], [2,1], [3,2]]) # 12 different compares
                  np.array([[0,1], [0,2], [0,3], [1,2], [1,3], [2,3]]) # only six compares. 
            order_of_compares = np.concatenate((order_of_compares, np.flip(order_of_compares, axis = 1)),axis = 0) # double them up by reversing the oder of the 1st and 2nd elements
                  array([[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3], [1, 0], [2, 0], [3, 0], [2, 1], [3, 1], [3, 2]]) # 12 different compares
      Each element is in the second slot 3 times, four elements times 3 times is 12, just like the hand coded version, but it still doesn't score as well as the hand coded version. There is something about the order that matters. 
            order_of_compares = order_of_compares[np.lexsort((order_of_compares[:,1], order_of_compares[:,0]))]
                  [0 1] [0 2] [0 3] [1 0] [1 2] [1 3] [2 0] [2 1] [2 3] [3 0] [3 1] [3 2]
            order_of_compares = order_of_compares[order_of_compares[:,0].argsort()] # same as lexsort
      I found that using just the first four of the hand coded choices resulted in the same score as the full hand coded version, when called from try_permutations. The way to have this implemented in the notebook is to skip right to the try_permutations. I think I could do that by only changing these two variables:
            stop_when = 10 # stop the roll process if you get a score this low
            min_score_perm = 10 # this is the minimum score required to accept a chord from improve_chord_rolls. If it's higher than that, we must send it to try_permutations to try different permutations. If you set this very low, it always goes to try_permutations
      Let's compare the scores across all the different ratio_factors for this section of chorale 14. Some increase in the max_score, but average went down, so I call that a win.
      grep -E "ratio_factor|Maximum|Total|Average" score_bwv245.14_all.txt
            ratio_factor = 2.0 Maximum score was: 132.0 Total score was 1295.0 Average score was: 64.8
            ratio_factor = 1.0 Maximum score was: 154.0 Total score was 1419.0 Average score was: 71.0
            ratio_factor = 0.75 Maximum score was: 154.0 Total score was 1828.0 Average score was: 91.4
            ratio_factor = 0.5 Maximum score was: 210.0 Total score was 2611.0 Average score was: 130.6
            ratio_factor = 0.25 Maximum score was: 234.0 Total score was 3365.0 Average score was: 168.2
            ratio_factor = 0.125 Maximum score was: 240.0 Total score was 3404.0 Average score was: 170.2

      grep -E "ratio_factor|Maximum|Total|Average" score-14all.txt
            ratio_factor = 2.0 Maximum score was: 127.0 Total score was 1377.0 Average score was: 68.8
            ratio_factor = 1.0 Maximum score was: 154.0 Total score was 1419.0 Average score was: 71.0
            ratio_factor = 0.75 Maximum score was: 154.0 Total score was 1635.0 Average score was: 81.8
            ratio_factor = 0.5 Maximum score was: 192.0 Total score was 2433.0 Average score was: 121.6
            ratio_factor = 0.25 Maximum score was: 237.0 Total score was 3272.0 Average score was: 163.6
            ratio_factor = 0.125 Maximum score was: 237.0 Total score was 3325.0 Average score was: 166.2

4.    Before I celebrate too much, this is a modest victory. What I really need to do is implement the slides to fix the problem described on 8/23/23.

--------------------------------------
8/27/23 To do today:

1.    But before I do, I'd like to reduce the path length of the tuning algorithm to what I made in the annealing.ipynb. 
      a.    chord = atu.remove_zeros_from_midi(chord) # a zero indicates that the voice is silent. Replace the zero with another note in the chord.
      b.    Check if equal to the previous chord
      c.    If not, chord_in_cents, final_cost = atu.try_permutations(chord, tonal_diamond, ratio_factor = ratio_factor, dist_factor = dist_factor, max_score = 70, range = range, already_checked = False)
      d.    trans_chord_in_cents = atu.transpose_top_notes(chord_in_cents, top_notes, inx, final_cost, chord)
      That's it. Don't mess with the combinations, or the roll. That's all you need. But preserve the ability to go back to the way it used to be. 
      Where are these changes to be made? I made a copy of the current notebook TonicNet_Csound_Just_Album_Thinkcentre.ipynb as TonicNet_Csound_Just_Album_Thinkcentre.ipynb
            def tune_chorale(chorale, keys, dist_factor = 1, ratio_factor = 1) calls:
            chorale_in_cents = atu.midi_to_notes_octaves(chorale, top_notes, tonal_diamond, ratio_factor = ratio_factor, dist_factor = dist_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12, range = 6)
      So I need to control things in atu.midi_to_notes_octaves. I copied the function and made the copy: def midi_to_notes_octaves_trimmed
      def score_chord_cents(chord_1200, tonal_diamond_values, ratio_factor = 1, gap = 1): does the scoring in atu.
      This scores the chords, and allows a gap
      I don't think it needs the ratio factor. It multiplies the ratio by this, but then divides the result by the same thing. It's really not needed.
      What about the cache? Try to get it working without the cache. I never achieved a hit percentage of more than 19% as I recall. I'll ignore it for now. I can go back and implement it again later.

2.    Tolerance implemented. 
      I modified score_chord_cents to remove the ratio_factor, and add tolerance = 1, which dictates how far from the cent value you will tolerate to consider a ratio a match. This might be a very useful parameter. If I make it high, for example 10, then it will allow a lot of slop in the tuning. If I make it low, like 1, then it will be like the way it is now. tolerance = 1 is the default value. 
      The problem is that if I set tolerance to 10, is that it accepts ratios as close even if they are high number ratios. For example (0, 3, 196, '28/25'), instead of 9/8 at 204 or 10/9 at 182. Try 0 to 10 instead of 10
            ratio_factor = 2.0, tolerance = 0 Maximum score was: 1127.0
            ratio_factor = 2.0, tolerance = 1 Maximum score was: 132.0
            ratio_factor = 2.0, tolerance = 2 Maximum score was: 1169.0
            ratio_factor = 2.0, tolerance = 3 Maximum score was: 1160.0
            ratio_factor = 2.0, tolerance = 4 Maximum score was: 142.0
            ratio_factor = 2.0, tolerance = 5 Maximum score was: 154.0  Average score was 74.6
            ratio_factor = 2.0, tolerance = 6 Maximum score was: 1169.0 Average score was 192.4
            ratio_factor = 2.0, tolerance = 7 Maximum score was: 157.0  Average score was 86.5
            ratio_factor = 2.0, tolerance = 8 Maximum score was: 131.0  Average score was 77.5
            ratio_factor = 2.0, tolerance = 9 Maximum score was: 184.0  Average score was 85.0
      Empirically it looks like tolerance = 1 or 5 are the best.
      Here are the scores at different ratio_factors:
      grep -E "tolerance|Maximum|Total|Average" save.txt
            ratio_factor = 2.0, tolerance = 5 Maximum score was: 154.0 Total score was 1491.0 Average score was: 74.6
            ratio_factor = 1.0, tolerance = 5 Maximum score was: 1158.0 Total score was 2513.0 Average score was: 125.6
            ratio_factor = 0.75, tolerance = 5 Maximum score was: 185.0 Total score was 1807.0 Average score was: 90.4
            ratio_factor = 0.5, tolerance = 5 Maximum score was: 256.0 Total score was 2657.0 Average score was: 132.8
            ratio_factor = 0.25, tolerance = 5 Maximum score was: 1156.0 Total score was 5389.0 Average score was: 269.4
            ratio_factor = 0.125, tolerance = 5 Maximum score was: 1156.0 Total score was 5400.0 Average score was: 270.0
      The last two are terrible
      Go back to tolerance = 1:
      grep -E "tolerance|Maximum|Total|Average" save.txt
            ratio_factor = 2.0, tolerance = 1 Maximum score was: 132.0 Total score was 1295.0 Average score was: 64.8
            ratio_factor = 1.0, tolerance = 1 Maximum score was: 154.0 Total score was 1407.0 Average score was: 70.4
            ratio_factor = 0.75, tolerance = 1 Maximum score was: 154.0 Total score was 1773.0 Average score was: 88.6
            ratio_factor = 0.5, tolerance = 1 Maximum score was: 210.0 Total score was 2563.0 Average score was: 128.2
            ratio_factor = 0.25, tolerance = 1 Maximum score was: 232.0 Total score was 3356.0 Average score was: 167.8
            ratio_factor = 0.125, tolerance = 1 Maximum score was: 240.0 Total score was 3395.0 Average score was: 169.8
      
      It looks like tolerance of one cent is the best. Gotta love that grid search methodology. Even if you can't know all the side effects of a decision, you can still find the best decision. Or what feels like the best decision. Compare it with the results yesterday afternoon before I implemented the bypass of the roll:
      grep -E "ratio_factor|Maximum|Total|Average" score_bwv245.14_all.txt
            ratio_factor = 2.0 Maximum score was: 132.0 Total score was 1295.0 Average score was: 64.8
            ratio_factor = 1.0 Maximum score was: 154.0 Total score was 1419.0 Average score was: 71.0
            ratio_factor = 0.75 Maximum score was: 154.0 Total score was 1828.0 Average score was: 91.4
            ratio_factor = 0.5 Maximum score was: 210.0 Total score was 2611.0 Average score was: 130.6
            ratio_factor = 0.25 Maximum score was: 234.0 Total score was 3365.0 Average score was: 168.2
            ratio_factor = 0.125 Maximum score was: 240.0 Total score was 3404.0 Average score was: 170.2
      Today is marginally better than yesterday. I'll take it. And the CPU time is still modest: around 3 seconds for 64 notes. 
      Including the csound create and convolve:
            CPU times: user 22 s, sys: 103 ms, total: 22.1 s 
            Wall time: 22.4 s

3.    In the process of trimming the notebook and atu, I have tried to systematically removed an dependence on a 4-note chord.
      score_chord_cents is independent of the number of notes in the chord sent to it. 

2.    Slides - after a walk. 
      Here is how the midi_to_notes_octaves_trimmed ends:
            return np.stack((chorale_in_cents.T, octave), axis = 2) # I could hstack my gliss into it here, but then all downstream functions would need to be updated, including finger_piano_part and I don't want that function to have any access to the gliss array.
      This is then becomes chorale_in_cents
            chorale_in_cents = atu.midi_to_notes_octaves_trimmed(chorale, top_notes, tonal_diamond, ratio_factor = ratio_factor, dist_factor = dist_factor, stop_when = stop_when, flats = flats, min_score_perm = min_score_perm, original_12 = original_12, range = 6, tolerance = tolerance)
            return(chorale_in_cents, tonal_diamond, ratio_factor, top_notes)
      And is called in the notebook:
            chorale_in_cents, tonal_diamond, ratio_factor, top_notes = tune_chorale(chorale, keys, ratio_factor = ratio_factor, dist_factor = dist_factor, tolerance = tolerance)
            logging.info(f'{chorale_in_cents.shape = }, {tonal_diamond.shape = }, {ratio_factor = }')
      Which stays the same throughout
            chorale_in_cents.shape = (4, 66, 2)
      We combine the choral_in_cents with the guev_array in the function:
            def add_features(voices_notes_features, guev_array):
      Inside the woodwind_part is a tag for where we could insert the gliss array that we will build. It will replace gls[0] 
            if mask:
                  guev_array = np.stack((gls, gls_p, ups, ups_p, env, env_p, vel, vel_p), axis = 0)
                  rng.shuffle(guev_array, axis=2) # we don't want to shuffle the slide array, but we will replace the shuffleed array downstream.
            else: guev_array = np.stack((gls[0], gls_p[0], ups[0], ups_p[0], env[0], env_p[0], vel[0], vel_p[0]), axis = 0).reshape(8,1,2) # no content for these variables if mask is False
            # gliss here
            # this is a good place to insert our gliss array with one slide for every note in every chord in the piece        
            guev_array[some slice goes here] = gliss_array # 
      The gliss_array shape should be (4, 66):
            chorale_in_cents.shape[0:2] = (4, 66) # shape of the dimensions 0 through 1 of the array.
      The slide should take advantage of 
            dmu.thin(array)
      This converts a string of numbers that have duplicates into just the unique numbers. I suppose I could np.uniq and get it done easier. Next time. But thin doesn't look beyond the current note. For example:
            string_of_notes = np.array([598, 597, 598, 598, 606, 606])    
            print(f'{dmu.thin(string_of_notes) = }')
            print(f'{np.unique(string_of_notes) = }')
                  dmu.thin(string_of_notes) = array([598, 597, 598, 606]) # this is what I wanted
                  np.unique(string_of_notes) = array([597, 598, 606]) # not what I wanted
      How can I obtain a string_of_notes to use. Hang on for a bit, it might get clearer.


3.    Cache cent values. Not at this time. 

8/28/23 To do today:

1.    Get the gliss working. 
      a.    ✅ Detect where a slide should take place - when the cent value of a note changes from one chord to the next between two time intervals 
      b.    ✅ Detect when I should start and end the slide - it will be before the gap a certain number of notes, and after the gap a certain number of notes.
      c.    ✅ Call dmu.thin(array) to convert the string of notes into just two notes. preserve the length and starting time interval of the slide.
            Now you have the number of cents. But you need the ratio to slide. ratio = ? times cents. 
                  dmu.cents_to_ratio(cents, limit_denominator = 105): Not accurate enough for one cent

      d.    ✅ Create the slide 
                  ratio = round(np.power(2, delta_cents/1200),6) # can probably get away with fewer decimal places. 1 cent = the ratio 1.0005777895065548
                  fn_array = np.array([t_num, 0, 256, -6, 1, 64, np.average((1, ratio)), 64, ratio, 128, ratio])

      e.    ✅ Check the newly created fn_array against all the others using np.allclose(fn_array, stored_fn_array)
            It does some slicing of the array to exclude element 0, which is the table number, which of course will not be the same as this one.
            The fn_array format is how the gliss arrays are stored. They are only written out when the csound file is created.

      f.    ✅ If you found the exact same gliss in the stored_fn_array, store the array number in the array variable gliss, which will be used later.  
                  gliss = stored_fn_array[0] # element 0 is the table number, I think.
            ✅ If you did not find it, then it's new and needs to be stored in the variable gliss, and in stored_fn_array.
            Increment the table number t_num.

      g.    ✅ You have to pad the gliss so that all the gliss arrays are the same size. That may not be necessary for my use case.
            Append the new gliss to the global variable stored_gliss, which I need to create.

      h.    Find a place to add the glides array to the notes_features_15 array.

2.    That was a great plan, but it encoutered the enemy:
      I fixed this by changing the prior note in save_cents array.
            glides[1, 44:48] = array([5, 5, 7, 7]) # having two different slides means these will be two different notes after downstream processing.
            glides[1, 46:50] = array([7, 7, 7, 7])
      The notes in slot 1 from 44:48 want to slide up, but then so do the ones at 46:50. I can't have two slides in the same slot.
      The problem could be fixed, I hope, if I update the chorale_in_cents for all of the slot 1 notes to the initial value. Then when it encounters 46:48, the notes will be different. I was planning to update those notes to set them to the initial value of the sliding note, but I had not gotten around to it. Let's see what happens when I do that. It sort of worked, but I can't be sure if it did the right thing.
            glides[1, 44:50] = array([7, 7, 7, 7, 7, 7]) - It went back to slot 44 for note 1, and made all of those 705 cents, with a slide of 0.994815 down to 696 from 705. 
      But it looks like we are manipulating one of several notes on the same pitch in the same chord. Here is the chorale_in_cents.
            print(f'{chorale_in_cents[:,40:53,0].T}')
            print(f'{save_cents[:,40:53,0].T}')  
                  [ 598  900 1194  198] [ 598  882 1194  198] 40
                  [ 598  900 1194  198] [ 598  882 1194  198] 41
                  [ 598  900 1194  198] [ 598  882 1194  198] 42
                  [ 598  900 1194  198] [ 598  882 1194  198] 43
                  [ 606  705 1104  705] [ 598  705 1104  705] 44 # here is a split between slots 1 and 3. 
                                                                  slot 3 gets slide 6 going down 4 cents in 4 chords, while slot1 takes longer but goes down 9 cents in 6 chords. Same direction, different speed. I wonder what it sounds like?
                  [ 606  705 1104  705] [ 598  705 1104  705] 45
                  [ 402  701  999  701] [ 402  705  999  705] 46
                  [ 402  701  999  701] [ 402  705  999  705] 47
                  [ 198  696 1104  402] [ 198  705 1104  402] 48
                  [ 198  696 1104  402] [ 198  705 1104  402] 49
                  ---------------------------------------------- This should be the end of the slide from 44:50 starting at 705 ending at 696 9 cents down
                  [ 198  606 1104  402] [ 198  606 1104  402] 50
                  [ 198  606 1104  402] [ 198  606 1104  402] 51
                  [ 108  402 1006  606] [ 108  402 1006  606] 52
      I think this just might work out fine. I'll have to listen to it.

3.    At some point I could tailor this ftable to match the number of notes at each value. current method works for series like this: 695 695 701 701
      what about this one: array([705, 705, 705, 705, 696, 696]). It should hang out for 3 at 705, then take two to reach 696 and stay there for one.
      1/6 of 256 is 42.67 * 3 = 128 2 * 42.67 = 85 1 * 42.67 = 43 128 + 85 + 43 = 256. Deal with that later.
            fn_array = np.array([t_num, 0, 256, -6, 1, 64, np.average((1, ratio)), 128, ratio, 64, ratio]) # 'cubic64_64_128' segments of cubic polynomials,
                  

-----------------------
8/29/23 To do today

1.    Reinforcement Learning state of the art model: https://arxiv.org/pdf/2305.19452.pdf
      Bigger, Better, Faster - a set of unique tweeks to improve RL from the RL podcast 

2.    History of machine learning and music from the Data Skeptic Podcast:
      https://dataskeptic.com/blog/episodes/2023/llms-in-music-composition - terrible interviewer. Really, really stupid trying to be cute. Asked how ML can be better than random, kept interupting. Unlistenable.
      Try this PhD defense here:
            https://www.youtube.com/watch?v=Zi0t7c3Xm3Ahttps://t.co/SESlCJ2FQ6
      
3.    Listen to the results of the somewhat sketchy slide algorithm. Find a place to add the gliss to the notes_features_15 array.
      Some ideas for how to firm it up:
      a.    Don't allow changing prior notes that have already changed. I haven't thought through this yet.
      b.    Reexamine the tuning after the slides have been added.       
      I created this:
            save_cents, glides, t_num = build_glides_array(save_cents, top_notes)
      So now I can put this function where I need it. I need to transform all the print statements to logging.info, then to logging.debug.

4.    I think I'll have to add my gliss values earlier in the process. 
      If I wait until we have notes_features_15, then the 4, 66, 2 structure is replaced by one row for each note, and I won't be able to figure out where the gliss goes.
                                   0  1    2     3    4     5     6      7       8    9      10        11    12     13     14
      notes_features_15 structure: 1, dur, hold, vel, note, octv, voice, stereo, env, glis1, upsample, renv, glis2, glis3, volume 
      So I think it would be better to apply the gliss earlier, when note_6 is being built. 
      This function 
            def initialize_chorale_and_instruments(chorale, root, mode, version, repeats):
      has reference to:
            stored_gliss = dmu.init_stored_gliss() # resets the global glissando array and the global current_gliss_table variable to 800
                                                           V-- this is a returned from initialize_chorale_and_instruments, along with the kitchen sink.
            chorale, repeats, voice_time, keys, top_notes, stored_gliss, finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, perc_guitar = initialize_chorale_and_instruments(chorale, root, mode, version, repeats)
      But it's never used again. I removed the reference to stored_gliss in this function and removed the initialization.  What happens if the woodwinds_part is called several times. I hope what happens is it reuses the reusable gliss tables. I will need to initialize it somewhere. How can I add new values to the stored_gliss?

5.    Tomorrow start here: def woodwinds_part(chorale, glides, repeats, voice_names, voice_time, tpq, volume_function, \
      Figure out the dimensions of gls. If it's possible that it can be 256, 4, then the completion of the slides will be simple. Otherwise, more complicated.

--------------------------
8/30/23 To do today 

1.    Are you storing the ftable array of glisses anywhere? I forgot about that.
      Do the ftables for the gliss actually start at 800? I can't remember. There is no room for them there. Where could I store around 50 or so ftables in the number space for ftables? I think I should start the gliss ftables at somewhere higher. 1500+ looks open. 
            def init_stored_gliss(starting_location = 1500, values_in_ftable = 70):
      I only need 11 positions for now.
            stored_gliss = dmu.init_stored_gliss(values_in_ftable = 11) # resets the global glissando array and the global current_gliss_table variable to the starting location for the ftable, now 1500.
      It looks like I'm doing some foolish things with the gliss table. I have some global variables, but I call functions to update the global variable. This seems wasteful. Just store it in the notebook using passed arguments to where it is needed.
      The key question is how to add one more ftable to the stored_gliss structure, and array of arrays. If I initialize stored_gliss, then I can add another ftable to it with this:
            stored_gliss = np.vstack((stored_gliss, gliss_f_table))
      News flash. diamond_music_utils.py includes some initialization outside of functions.
            stored_gliss = np.empty((0,70), dtype = float) # this is wrong. We should use the function provided to initialize this variable. 
            current_gliss_table = 1500 # raised on 4/28/23 to make more room for samples. Previously, samples occupied 601 - 798 increased it to 1500
      I have a variable t_num that starts at 1. I should probably increase that to 1500, or use the global variable current_gliss_table.
      
2.    https://vscode.dev/tunnel/vscode/home/prent/Dropbox/Tutorials/TonicNet

3.    Something is missing from this in the main line of the notebook. The following line fails:
                  NameError: name 'stored_gliss' is not defined
            logging.info(f'{chorale.shape = }, {len(voice_time) = }, {keys = }, {top_notes = }, {stored_gliss = }, {finger_pianos = }, {wood_winds = }, {pizz_strings = }, {bowed_strings = }, {brass_section = }, {perc_guitar = }')stored_gliss is not declared
      I think I need to pass stored_gliss back into the main line somehow. Could it be done in this function:
            chorale, repeats, voice_time, keys, top_notes, \
            finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, perc_guitar = \
            initialize_chorale_and_instruments(chorale, root, mode, version, repeats)
      No, that one has no exposure to stored_gliss.  How about this one:
            chorale_in_cents, tonal_diamond, ratio_factor, top_notes = \
                  tune_chorale(chorale, keys, ratio_factor = ratio_factor, dist_factor = dist_factor, tolerance = tolerance)
      Again, that one has no exposure to stored_gliss. The only function that does is:
            chorale_in_cents_slides, glides, stored_gliss, t_num = build_glides_array(chorale_in_cents_slides)
      And that is later in the main line. So I moved any reference to after that point.

4.    So I made it to where I left off: in woodwinds_part
            else: guev_array = np.stack((gls[0], gls_p[0], ups[0], ups_p[0], env[0], env_p[0], vel[0], vel_p[0]), axis = 0).reshape(8,1,2) # no content for these variables if mask is False
                  NameError: name 'gls' is not defined      
                  else: guev_array = np.stack((gls[0], gls_p[0], ups[0], ups_p[0], env[0], env_p[0], vel[0], vel_p[0]), axis = 0).reshape(8,1,2) # no content for these variables if mask is False
      Start there.
      I need to make sure that the initialization of stored_gliss only takes place once. It's called in build_glides_array. And that one is only called once per chorale, and each chorale has its own csound .csd file.
      I noticed that I need to force to integer for some of the elements of fn_array:
             INFO - fn_array = array([ 1.502000e+03,  0.000000e+00,  2.560000e+02, -6.000000e+00,
                  1.000000e+00,  6.400000e+01,  9.922625e-01,  1.280000e+02,
                  9.845250e-01,  6.400000e+01,  9.845250e-01])
      I can't do that, because some of the array members are float, and numpy doesn't allow mixed datatypes in an array. I'll have to do it later when writing out the csound file. I could convert it to a string. How do I do it in dmu.build_slides? He keeps them as floating point. So I must have solved this before. 
      I'll have to fix the glides before this happens:
            notes_features_6 = atu.add_features(chorale, guev_array)
      What comes back from that?

5.    Time for a walk. Tomorrow take a look at why ball9.log contains lots of very high number chords. It should be limited to (4,66) and I see some 90+ chord numbers. It's like it is running the build_glides_array after the repeats.       

-----------------------------
8/31/23 To do today:

1.    Figure out what the chords from 54:65 are processed twice. They are ftables, 1506 and 1507
            same 12 TET note, delta_cents = -27, chord# 56, note# 0, B♮, prev_note_cents = 1131, note_cents = 1104
            need a slide from 54 to 65 slide_array = array([1131, 1131, 1104, 1104, 1104, 1104, 1104, 1104, 1104, 1104, 1104]), Why did it stop at 65? It should have gone to 66.
      Take a look at the logic for the loop moving into the future, and see if it stops one element too soon. That's because it refers to the one after the end. 
            while note_cents == chorale_in_cents_slides[note_num, next_chord_num, 0] and next_chord_num < chorale_in_cents_slides.shape[1]: # used to say -1 
                  logging.info(f'{next_chord_num = }, chorale_in_cents_slides[{note_num}, {next_chord_num}, 0]{chorale_in_cents_slides[note_num,next_chord_num, 0]}')
                  next_chord_num += 1
      Flip the order of the tests, so it ends first if it goes too high, and then checks if equal. That fixed it. What a relief.
                  IndexError: index 66 is out of bounds for axis 1 with size 66 - fixed that.
      But I am afraid that it should include the one at 66, and it stops at 65. - Fixed that too:
            if next_chord_num == chorale_in_cents_slides.shape[1]:
                  next_chord_num += 1

2.    We go through the build_glides_array three times. Why?
            948.0 - INFO - In build_glides_array. chorale_in_cents_slides.shape = (4, 66, 2), chorale_in_cents_slides.shape[0:2] = (4, 66)
            59.0 - INFO - In build_glides_array. chorale_in_cents_slides.shape = (8, 132, 2), chorale_in_cents_slides.shape[0:2] = (8, 132)
            279.0 - INFO - In build_glides_array. chorale_in_cents_slides.shape = (8, 132, 2), chorale_in_cents_slides.shape[0:2] = (8, 132)                  
      And especially why once is (4,66) and the second time is (8,132). doubling notes and doubling voices. That should be downsteam. And I really only need to have it run once.  It should not be in woodwinds_part. It should be in the main line. I'll move it there. I had already put it there, but forgot and also put it in woodwinds_part as well, where it didn't belong. This was there, and I removed it:
            logging.info(f'{chorale.shape = }') 
            chorale_in_cents_slides, glides, stored_gliss, t_num = build_glides_array(chorale)
            logging.info(f'{chorale_in_cents_slides.shape = }, {glides.shape = }, {stored_gliss.shape = }, {t_num = }')
      Now we have it in the mainline only.

3.    def add_features builds the notes_features_6 array
                  feature values and counts in this order: notes, octaves, gliss, upsample, envelope, velocity (values, counts)
      This is the content of gliss: 
                  (array([0]), array([1056]))
      This represents the double voice, double notes (8, 132), while my gliss_array still shows (4,66)
      Where could I add the gliss array? 
      
4.    None of the slide numbers made it into new_output.csd 

-----------------------------
9/1/23 To do today:

1.    Pick up where you left off yesterday. Update gls with the glides array before calling add_features.
      I created a new add_features in adaptive_tuning_util.py that is called add_features_glides, and takes in glides just like it takes in chorale_in_cents_slides. It then puts glides into the notes_features_15 array. When printed out later in the log file, I see that the glide numbers make it into the array.
      Next, see if the glides values make it into new_output.csd. I don't see them in new_output.csd. But csound processes the file anyway. How is that possible? It processes the file even though there are errors? In the log:
            INIT ERROR in instr 1 (opcode oscili.kk) line 107: Invalid ftable no. 1500.000000
            INIT ERROR in instr 1 (opcode oscili.kk) line 107: Invalid ftable no. 1501.000000      
            INIT ERROR in instr 1 (opcode oscili.kk) line 107: Invalid ftable no. 1506.000000
      There you have it. It's not including the glide ftable values. Progress!

2.    Ensure that the stored_gliss makes it to the new_output.csd. stored_fn was used instead of fn_array here:
            stored_gliss = np.vstack((stored_gliss, fn_array))
      stored_fn was np.zeros((0,11), dtype = float) 
      I fixed it, but there is still no gliss ftables in new_output. They finally showed up. I was looking for 'f1500' and they are written as 'f 1500'

3.    It's finally writing out the notes with slides. But the slides are so slight that I can't hear them. I guess that's a good sign. 
      There are a few anomolies in the wave output file. I hear several 1/16th notes, and there are none in the input. Those will need to be investigated. That is usually caused by some element in the note that has changed between two of the notes that is a feature other than the note value. So if I look at chorale_in_cents_slides and glides, I might find where that other feature is changing. It could be the gliss value, or the envelope, or any other feature. 

      Another option is to reduce the resolution in the reading of the corpus. Set quantizer to 2 instead of 4, or 6 instead of 2 or 4 and see what happens. It's already at the minimum to capture down to the 1/16th note level. Any less and I would loose the 1/16th notes.

      I tried different ratio_factors, and they all have the subtle 1/16th notes at the same places. Here are some I hear:
            0, 8, 12, 24, 46
      Where should I tap into them to find where they are coming from? 
      I think I might know. Look at the first four notes:
            chord_num = 0, notes.shape = (4,), octaves.shape = (4,) glides.shape = (4,)
            0	1131	5	0
            1	1131	5	0
            2	1131	5	0
            3	1131	5	0
            chord_num = 1, notes.shape = (4,), octaves.shape = (4,) glides.shape = (4,)
            0	1104	0	1500 #<-- why does the slide start on the second 1/16th note. That's odd. Shouldn't it start at the first one?
            1	1104	0	0
            2	1104	0	0
            3	1104	0	0            
      Or should it start at all? I don't see any request for sliding any notes before chord #31. Why are there slides in chord #1 - 8 and 8 - 12? I don't see any of those in the slide_tuning.log. I'm not logging the assignment of gliss numbers to the glides array. That's a mistake.
      I think it doesn't go back far enough:
            prev_chord_num = 1, chorale_in_cents_slides[0, 1, 0]: 1131 # <-- this is chord #1, and I should have gone to chord #0.
      I need to keep looking while prev_chord_num is greater or equal to zero, not just greater than zero. Fixed it.
            while prev_note_cents == chorale_in_cents_slides[note_num, prev_chord_num,0] and prev_chord_num >= 0
      I'm still getting 1/16th notes at 8, 12, 24, 46 and here is why:
                  chord_num = 8,  voice_num = 0	87	6	1500  ['C♯', 'A♮', 'E♮', 'G♮']
                  chord_num = 9,  voice_num = 0	87	6	0           #<-- I should have extended the slide to chord #9? or not extended to #8
                  chord_num = 24, voice_num = 0	402	6	1502  En
                  chord_num = 25, voice_num = 0	402	6	0
                  chord_num = 46, voice_num = 0	402	6	1503  En
                  chord_num = 47, voice_num = 0	402	6	0
                  chord_num = 12, voice_num = 3	606	4	1501  F#
                  chord_num = 13, voice_num = 3	606	4	0
      I think the problem is deeper than that. There is no call for a slide in voice 0 at chord 8. It's that latter value that is wrong.
      It should be from 0 to 7 and it went to 8. Mistake was made. Where? 
      Here are all the slides that I called for. These all look like they are accurate. Were they assigned to the wrong slot in glides?
            grep "same 12 TET" slide_tuning.log
                  595.0 - INFO - same 12 TET note, delta_cents = -27, chord# 4, voice# 0, B♮, prev_note_cents = 1131, note_cents = 1104
                  611.0 - INFO - same 12 TET note, delta_cents = 34, chord# 10, voice# 3, G♮, prev_note_cents = 669, note_cents = 703
                  635.0 - INFO - same 12 TET note, delta_cents = 27, chord# 22, voice# 0, D♯, prev_note_cents = 290, note_cents = 317
                  643.0 - INFO - same 12 TET note, delta_cents = 27, chord# 22, voice# 2, B♮, prev_note_cents = 1104, note_cents = 1131
                  648.0 - INFO - same 12 TET note, delta_cents = 27, chord# 22, voice# 3, B♮, prev_note_cents = 1104, note_cents = 1131
                  685.0 - INFO - same 12 TET note, delta_cents = 21, chord# 44, voice# 0, F♯, prev_note_cents = 585, note_cents = 606
                  706.0 - INFO - same 12 TET note, delta_cents = -27, chord# 56, voice# 0, B♮, prev_note_cents = 1131, note_cents = 1104
      Here's another suspicious assignment:
                  assigning 1500 ftable to glides[0, 0:9] should have been 0:8.
                  glides[note_num, first_chord_num:last_chord_num + 1] = t_num # <-- there's your trouble. It should be last_chord_num
      I fixed that, and now I don't see any 1/16th notes. I'll have to listen to it to see if it sounds right. I think I may have solved the last bug in slide algorithm. We shall see.
-----------------------------------
9/2/23 To do today:

1.    Figure out what you have done with the ability to slide between notes. Then post the substack some examples. 
      Done.
      
-----------------------
9/3/23 To do today:

1.    Consider some comments on facebook:
      a.    Paul Erlich Admin Top contributor
            Curious how your algorithm would handle the basic I-IV-ii-V-I and I-vi-ii-V-I progressions arranged to maximize common tones between consecutive chords. Are there any pitch shifts / glides greater than 6 cents? This is a good set of test cases for any adaptive JI algorithm.
      Open up musescore and enter those chords. Then export as a midi file. Then run it through the slide algorithm. Then listen to it.
      b.    Carl Lumma Group expert
            There's a trick if you have this level of control: you can make note attacks in 12-ET and bend to JI after a few milliseconds. The idea is that attacks are more prominent melodically and sustains are more prominent harmonically -- there's some research to back this up according to Manuel Op de Coul. If so, it should make comma shifts less noticeable. At any rate, it makes sense to me, and tends to be how barbershop and brass enesmbles tend to tune in practice (in my experience).
            Prent Rodgers
            I think I'll stick with what I have. I can't detect the slides as it is.
            Teddy Dunn
            Carl Lumma Hmm interesting. Maybe it's me being part of an amateur wind ensemble, but half the time I forget where I am in the harmony and adjust after the attack
            Paul Erlich
            Teddy Dunn you seem to be agreeing with Carl
            Paul Erlich Indeed! Unless the professional ensembles are more aware of the harmonic context they're in and adjust immediately. But given the fact that auditions for those ensembles are players by themselves with no harmonic intonation involved, it's likely that many of the players adjust in the way Carl described.
            Yahya Abdal-Aziz 
            Carl Lumma would this also work if your attacks were all to a specific flavour of (say) 5-limit JI?
            Prent Rodgers
            Well, I could give it a go and see what it sounds like.
      Or not. I will work on Paul's suggestion.

2,    Fix the bugs that cropped up when I ran a full bwv245.14 chorale with all 256 1/16th note time steps. 
      Notice that there are a lot of odd numbered time steps, which should not be there. They result in some anomolies like 1/16th note repetitions caused by changes in feature, which look to be both the gliss feature the note feature.  Not good.

                  all_notes.shape = (4, 258), all_octaves.shape = (4, 258), all_glides.shape = (4, 258)
                                                      Note  oct   gliss
                  chord_num = 44, voice_num = 0	       86	6	1500 
                  chord_num = 45, voice_num = 0 	 86	6	0

                  chord_num = 56, voice_num = 0	      900	5	1501
                  chord_num = 57, voice_num = 0	      900	5	0

                  chord_num = 110, voice_num = 0	198	6	0 
                  chord_num = 111, voice_num = 0	402	6	0
      Let's start with figuring out why the gliss changed from chord 44 to 45. The first thing that I notice is that there are two slide alterations that are overlapping.
      The first starts at chord# 42. 
      chorale_in_cents_slides[0, 40:44: [198 198 198 198] delta_cents = 21, ratio = 1.012204 store this array as glide 1500 at glides[0, 40:44]
      We are in the loop at chord# 42, and have changed the notes in 40, 41, 42, and 43 to 198 with a slide 1500 1.012. chorale_in_cents_slides[0, 40:44: [198 198 198 198]
      Next we examine the next chord, starting at #43. But notice above that the note at 44 has a glide of 1500. That's not right. It should be 0. 
      Notice this line in the build_glides_array:
                  glides[note_num, first_chord_num:last_chord_num + 1] = t_num # <-- there's your trouble. It should be last_chord_num 
      I thought I had fixed that. I fixed it again just now, and most of the above errors vanished.
      But the note feature is still changing at odd times. I'll have to look at that next.
            all_notes.shape = (4, 258), all_octaves.shape = (4, 258), all_glides.shape = (4, 258)
                  chord_num = 110, voice_num = 0	198	6	0
                  chord_num = 111, voice_num = 0	402	6	0
                  ...
      Take a look at what happens at chord# 110 and 111. Could it be that the chord# 110 voice 0 note at 198 is in error? Or is the 402 in 111 a mistake? Let's look at the report before the slides were processed:
                  108 		['C♯', 'F♯', 'C♯', 'A♯']	[ 86 584  86 970]	
                  110 		['D♮', 'F♯', 'C♯', 'A♯']	[198 584  86 970]	
                  111 		['E♮', 'F♯', 'C♯', 'A♯']	[ 402  633  135 1019]	
                  112 		['D♮', 'F♯', 'C♯', 'B♮']	[ 198  584   86 1082]	
      So before the slides were processed, there was a 1/16th note at time step 111. Correct. There actually is a 1/16th note there. It's not a mistake.
      The only mistake is here:
                  measure 15 beat 4
                  chord_num = 244, voice_num = 1	789	5	0
                  chord_num = 245, voice_num = 1	788	5	0
      It's subtle, but enough to create a new note here. Voice 1 should not have different cent values between chord 244 and 245. Why does it? And why is this the first time I've seen this anomoly?
            INFO - chord# 244, chord_cents = array([1104,  789,  171,  402]),
            INFO - chord# 245, chord_cents = array([1104,  788,   86,  402]),
            INFO - chord# 246, chord_cents = array([1104,  789,  171,  402]),
            INFO - chord# 247, chord_cents = array([1104,  789,  171,  402]),
      The anomoly is chord 245. It should be 789, not 788. Why is it 788? I'll have to look at the code that creates the chorale_in_cents array.
      Of I could listen to it and realize that because of the overlap and legato style, the change is inaudible. Move on.

3.    Made the MIDI file of Paul Erlich's example. It uncovers the nasty problem of the comma. He said I could not move more the 6 cents. I slide 22 cents on the D. I loose.

      I was hung up for hours on a nasty features of the new_output.csd, or rather the ball9.csd, where it constrains the velocity to a range of 50 to 90. I removed the constraint. I put it back in, and just made sure the velocity I choose is between 50 and 90. I'm still getting zero notes in the new_output.csd now. That's surprising. What changed?
      I'm looking here:
                  In send_to_csound_file. stored_gliss.shape = (1, 9), current_gliss_table = 1, notes_features.shape = (62, 15)
      There are 62 notes, and zero get to new_output.csd. Why?
      This looks suspicious:
                  before selecting non-zero hold values. notes_features.shape = (62, 15)
                  In send_to_csound_file after selecting for non-zero hold values. notes_features.shape = (62, 15)
                  after selecting for non-zero octave values. notes_features.shape = (0,) <-- there's your trouble.
      How did the octaves go to zero? I've traced it to send_to_csound_file. Something goes wrong there. And now I can't even read in the MIDI file. Everything is going to ...
      I think there was a failure in the python kernel. When I restarted it the strange errors went away. Except for the one where the octaves suddenly go to zero.
      The problem had nothing to do with octaves. It was this:
            volume_array = np.zeros(16, dtype = int) * 70 # I thought it was ones * 70. Oops. There's your trouble.
      I finally have just the bassoon, and the octaves are really whack. Way too high.
      I'm only getting the first two measures when I set repeats to 2. It's like there is some hardcoded value at 16 steps. It was the volume_array. When it wasn't long enough, it restricted the number of notes to 16. I fixed that:
            volume_array = np.ones(notes_features_6.shape[2], dtype = int) * 60 # it used to be 16, now it's the number of notes in the chorale. notes_features_6.shape[2]

      The bottom line is that my algorithm doesn't meet his requirements. Too bad. Actually, when I set the ratio_factor to 0.25, the larges movement is 4 cents. It sounds like shit, but it meets the requirements. Theory vs Practice.

--------------------------------------
9/4/23 To do today:

1.    Figure out why some of the realizations are bunk.
            ls -lth ~/Music/sflib/ball9-t_*.wav
                  80   Sep  4 07:59 /home/prent/Music/sflib/ball9-t_2.0_.wav Bunk
                  80   Sep  4 07:59 /home/prent/Music/sflib/ball9-t_1.5_.wav Bunk
                  2.0M Sep  4 07:59 /home/prent/Music/sflib/ball9-t_1.0_.wav Half bunk
      
      These are all the higher ratio factors. Interesting. I tried a few things to fix it, but none worked. I'll have to dig more. They all create a complete version when I run the whole notebook from the start. But not when I do the for loop. Weird. Not sure why it happened. There must be something that happens in the loop when the ratio_factor is greater than 0.75.

2.    Look at some of the scores:
                  ratio_factor = 0.25
                  same 12 TET note, delta_cents = 4, chord# 3, voice# 0, D♮, prev_note_cents = 200, note_cents = 204
                  same 12 TET note, delta_cents = 4, chord# 11, voice# 1, D♮, prev_note_cents = 200, note_cents = 204
                  ratio_factor = 0.5
                  same 12 TET note, delta_cents = 18, chord# 2, voice# 1, A♮, prev_note_cents = 884, note_cents = 902
                  same 12 TET note, delta_cents = 4, chord# 3, voice# 0, D♮, prev_note_cents = 200, note_cents = 204
                  same 12 TET note, delta_cents = 4, chord# 11, voice# 1, D♮, prev_note_cents = 200, note_cents = 204
                  ratio_factor = 0.75
                  same 12 TET note, delta_cents = 22, chord# 3, voice# 0, D♮, prev_note_cents = 182, note_cents = 204
                  same 12 TET note, delta_cents = 22, chord# 11, voice# 1, D♮, prev_note_cents = 182, note_cents = 204
      The rest are identical to one of these. I like the sound of 0.75 and above, but that's because I really don't like a major third represented as 24/19. The first one in the list, at 0.25, has the lowest delta_cents slide at 4 cents, where the D moves from 200 to 204 cents. It's able to do that because the D minor chord minor third at chords 2 and 10 is a 19/16 instead of a 6/5 between the D and F. The C and G majors are all 24/19. These are all just intervals, they are higher number ratios, and I prefer lower number ratios. 

3.    New set of goal posts:
            Paul Erlich
            My requirement was that all major and minor triads be pure in the simple 5-odd-limit just sense within themselves. And that there be no drift. And that all pitch shifts be under 6 cents.
            I favor lower number ratios in *vertical* intervals too; that was what I was hoping we'd be going for.
            Also it was stipulated that common tones be held between chords if/when possible.
            Prent Rodgers
            What is the tolerance for cent distance from 5-odd-limit just in each chord? How much can I temper each chord and still be considered just? If I know that, then I can minimize the drift in each chord.
            Paul Erlich
            let's say ~0.1 cents like Partch if that helps? No. 
            Paul Erlich
            Again there should be zero drift (beginning and ending chords should be the same) but the pitch *shifts* of notes held across chords should be minimized.      
      I am stumped. Time for a walk. 

4.    Trying to come to grips with Paul's statements:
      I can't visualize how I have to keep each chord at a 5-lmit just chord, and still hit every note in the chain of chords. Where is the flex? What can I change if I can't change anything. Asking seriously here. I just don't understand. In the case of the I-IV-ii-V-I progression, once I get to ii, in my case D minor, what can I change to enable me to keep the D or F from moving from where they were before, or need to go next? The F was at 498 cents, A at 902 cents and C at 0 cents just 4:5:6/8. How can I build a D minor at this point? I have to keep the F and A in place, to hold common tones in place. The D needs to be where it is next needed in the G major chord at 204 cents. That leaves the root of the D minor stuck at 204 because it needs to be 204 in the next chord, G major. If you ask that notes note move when they are in common across notes, and all chords be just, then nothing can move. So my only choice is to slide from one mandatory note to another mandatory note.

      So he has held out one bit of flexibility: the pitch shifts of notes held across chords be minimized. That means they are allowed to move the minimum amount possible. But every arrival has to be a 5-limit just chord.
      
      So the only solution is to pitch shift notes across chords by as little as possible. But I've already shown that the best I could do was a shift of 22 cents. What if I did a grid search of all possible top_notes? Keep the ratio_factor at 0.75, but change the anchor notes. I cound one that only needed 20 cents.

5.    Try permutations of the top_notes - 120 4 note permutations of the top six notes. 
            grep -E "max_delta_cents =|top_notes =" slide_tuning.log | cut -b 40-42 | sort | uniq
                  22    
      Try 3 note permutations and got several 20 cent maxes 
      Try 2 also got several 20 cent maxes 
      Try 1 also got several 20 cent maxes. 5, 4, 7, 0. It doesn't make any difference which one you pick, they all resolve to the same cent values throughout. 
      So it looks like I can reduce the cent movements if I just don't stress the top_notes. Let them move.

9/5/23 To do today:

1.    Get back to figuring out which velocity slice controls which instrument. It could be in the order of voice_time, or in wood_winds. Try both.
      And when you listen to the results, listen to ball9.wav. And even better, look in the erlich_cadence.log file for print_only = 
      I think I've sorted out how to find the velocity to instrument relationship. I discovered two problems:
      a.    Clarinets an octave too high at chod #16. Here's why:
                  15.99	2.02	55.0	1198.0	5.0	13.0	5.0	1.0	0.0	0.0	1.0	0.0	0.0	60.0
                  15.99	2.02	55.0	1198.0	5.0	15.0	1.0	1.0	0.0	0.0	1.0	0.0	0.0	60.0
            If the cent value is close to 1200, I need to decrease the octave. Another way to think about it: if the cent value rounds to a midi note and the delta between the cent value of the 12TET midi note is much different from the cent value of the note, decrease the octave by one. 
                  midi_to_notes_octaves_trimmed
            I fixed that. Sort of. I have to test it. I can't because now it's failing the mismatch_check. See below item #2.
      b.    The bassoon has beating in low G. try the whole voice using inton.mac in the csound directory. 
            I noticed a beating in the clarinet as well. That's odd. Is there a upsample involved?

2.    A new problem cropped up. I made a few changes to several different functions in adaptive_tuning_util.py. 
      Including one that was in mismatch_check that should have been caught long ago. keys was undefined. Once I fixed that, I suddenly got mismatch errors. Lots of them. Why now? Why was that missing variable keys not discovered earlier, and why now? Take a look at the mismatch. 
                  mismatch between the original MIDI notes chord_num = 8, midi_notes = array([79, 76, 72, 48]), chord_12_rounded =  array([79, 76, 60, 36])
                  Original scale degrees: midi_notes % 12 = array([7, 4, 0, 0])
                  Scale degrees derived from the cent values: chord_12_rounded % 12 = array([7, 4, 0, 0])
                  midi_notes % 12 = array([7, 4, 0, 0])
                  new note: chord_12_rounded[delta] = 60, original note: midi_notes[delta] = 72
      I see what happened. When I changed the octave on that cent value of 1198, I changed the midi number as well, from 72 to 60. But those are the same 12TET scale degree. Why would that matter. I'm comparing scale degrees, right? Maybe not. Notice that two of the chord_12_rounded values are lower by an octave. I can't see that being a coincidence. Remember, mismatch is done in the print_report function. Or used to be. I'm really worried about that 48 changing to 36. That was not expected. Maybe it was one of the cents over 1150? No, it's right. There are two C's in that chord, one in the clarinet, one in the bassoon. 
      So in reality it's not a mismatch. The function mismatch_check is designed to surface notes that moved from one midi note to the adjacent one in the scale degrees, not that moved by an octave. I say, if the mismatch is an octave, just ignore it. In fact, you should not even be looking at octaves in the mismatch_check or in the print_report. They are irrelevant. I fixed that. 

3.    Investigate the beating in the notes G notes:
                  Sta	Hold	Vel	Ton	Oct	Voi	Ste	En1	Gls	Ups	Ren	2gl	3gl	Vol
                   5.99	10.1	55.0	698.0	4.0	13.0	5.0	1.0	1500	0.0	1.0	0.0	0.0	60.0
                  6.0	10.1	55.0	698.0	4.0	15.0	7.0	1.0	1500	0.0	1.0	0.0	0.0	60.0
                  21.99	10.1	55.0	700.0	4.0	15.0	6.0	1.0	1501	0.0	1.0	0.0	0.0	60.0
                  22.01	10.1	55.0	700.0	4.0	13.0	2.0	1.0	1501	0.0	1.0	0.0	0.0	60.0
      But I still have beatings that are not explained. Are the beatings in the original samples? Or is it something to do with the glides on those notes. 
      
      Here are the notes played on the clarinet:                        
            instr 1:  p5 = 698.000  ioct = 4.000  iMIDInumber = 55.000  iFtable = 899.000  iSampleType = 2.000  iloop = 1.000
            instr 1:  p5 = 698.000  ioct = 4.000  iMIDInumber = 55.000  iFtable = 862.000  iSampleType = 2.000  iloop = 1.000
            instr 1:  p5 = 700.000  ioct = 4.000  iMIDInumber = 55.000  iFtable = 862.000  iSampleType = 2.000  iloop = 1.000
            instr 1:  p5 = 700.000  ioct = 4.000  iMIDInumber = 55.000  iFtable = 899.000  iSampleType = 2.000  iloop = 1.000
      Speaking of anomaies, look at all those different octaves. I need to blank out the zero velocities like I blank our the 0 volumes. What is the index of the velocity values? 2 is hold, 5 is octave. What is velocity? 3
      So I can confirm that each of the held G notes use two different samples. But I can't figure out why. What are the samples used:
      ftable sample 
      899   Partition C/OBOE/OBOE G#4-f.aif
      862   Partition A/B- CLARINET/CLARBB G#4-f.aif
      Oh. They are two different instruments. I think it's because the range is below the french horn so it gets silent. Don't know for certain. The bottom line, I have misaligned the instruments. I changed it to this, which I thought it was originally:
            voice_names = np.array(['flut1', 'clar1', 'oboe1', 'oboe2', 'fnrh1', 'fnrh2', 'basn1', 'basn2']
      I discovered that what was being passed to woodwinds_part was the variable wood_winds, which had the old wrong arrangements of instruments. I spent an hour trying to figure this out. Fixed it.

--------------------------------------
9/6/23 To do today:

1.    Redo the full chorale with the new voicings at 0.5, 0.75, 1.0, and 1.25 and post them to Substack. 
      Find the one chorale that is longer than all the others first.
            grep -E "In mainline" slide_tuning.txt
                  'bwv245.15', chorale.shape = (4, 272)
                  'bwv245.17', chorale.shape = (4, 176)
                  'bwv245.22', chorale.shape = (4, 192)
                  'bwv245.26', chorale.shape = (4, 256)
                  'bwv245.28', chorale.shape = (4, 256)
                  'bwv245.3',  chorale.shape = (4, 176)
                  'bwv245.37', chorale.shape = (4, 272)
                  'bwv245.40', chorale.shape = (4, 448)
                  'bwv245.5',  chorale.shape = (4, 192)
                  'bwv245.11', chorale.shape = (4, 192)
                  'bwv245.14', chorale.shape = (4, 256)
      I had no idea there were this diverse. Could I reduce the quantization by 2 and not loose information? What is the greatest common denominator of those values.
            print(np.gcd.reduce([272,176,192,256,256,176,272,448,192,192,256]))
                  16
      How can I confirm that there are no 1/16th notes in the result of a certain quanitation. 
      I think I will add this to the dictionary for version. Most are ideal at quanitization of 4, but the following could go down to 2: 37, 15, 26.

2,    We have a wild one, folks.  3, 40, 26
      a.    Random octave switches, probably due to the recent change where if a note had a cent value of > 1150, I would reduce the octaves. Starts out the piece with a bank.
      b.    Some slides of size of an octave. Probably due to the same change. Really whack. 
      
      Some nice ones too: 14, 11, 5, 37, 28, 22, 17, 5
      
      Take a look at the outliers starting with 40, 26, 3. Time for a walk now.

---------------------
9/7/23 To do today:

1.    Fix the wild ones:  3, 40, 26
      a.    Start with the octave shifts. I though I fixed that, but maybe not. I set the tempo to 60 and now the wave file has the same seconds as the new_output.csd and the slide_tuning.log, where this came from:
                  1	2	3	4	      5	6	7	8	9	0	11	12	13	14
                  Sta	Hold	Vel	Ton	      Oct	Voi	Ste	En1	Gls	Ups	Ren	2gl	3gl	Vol
                  4.01	0.5	64.0	1184.0	4.0	25.0	9.0	16.0	0.0	2.0	16.0	0.0	0.0	9.0
                  4.01	0.5	64.0	1184.0	4.0	13.0	9.0	16.0	0.0	1.0	16.0	0.0	0.0	8.0
                  4.01	0.5	64.0	1184.0	4.0	14.0	11.0	1.0	0.0	1.0	1.0	0.0	0.0	11.0
      There is a cent value > 1150 with an octave change. Question: what is the conversion from 1/16th note to seconds? Quarter note = 1 second. Eighth note = .5 seconds.
      So these are not 1/16th notes. They are 1/8th notes. Regardless, who is telling them to switch octaves? I can confirm there are no slides in this section.
            max_delta_cents = 0
      The section under study is chorale = chorale[:,:16]. And the C does not change octave. I kind of wish I had the ability mask out one or more instruments, like I did in the erlich_cadence notebook. Doesn't work here. velocity is for all the notes.
      Here is the chord that goes whack in the following chord:
            8 		['C♮', 'G♮', 'E♭', 'C♮']	[1184  686  300 1184]
      Here are the before and after going through blud_glides_array:
      chord# 8, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([5, 5, 5, 4])
      chord# 8, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([5, 5, 5, 4])
      chord# 9, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      chord# 9, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      chord# 10, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      chord# 10, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      chord# 11, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      chord# 11, chord_cents = array([1184,  686,  300, 1184]), chord_12 = array([0, 7, 3, 0]), note_names = array(['C♮', 'G♮', 'E♭', 'C♮'] octave = array([6, 5, 5, 5])
      No change to the octave. Perhaps it's changed later. Or I might change it twice by mistake. I figured out a way to just get individual voices:
            notes_features = dmu.send_to_csound_file(notes_features_final, voice_time, CSD_FILE, tempos = 't0 ' + str(tempo), limit = limit, tempo = tempo, print_only = 1000, include_instruments = np.array([13])) 
      And these are the instruments that may have goofy octaves. 
                  ; 12, 13, 14, 25, 27 
                  ; 830, 850, 872, 1156, 1192
                  ; bassoon, clarinet, flute, trumet, trombone, tuba
                              fpno vlnp vlap celp mrba xylp vibe harp vlnm vlam celm bssn  clar flut oboe frnh vln  vla  cel  barg ebal long stng bfin trum trom tuba
                                1    2    3    4    5    6    7    8    9   10    11   12   13   14   15   16   17   18   19   20    21   22   23   24   25   26   27
                  f1 0 64 -2 0 60 1 630  652  667  683  705  726  742  766  787  807  830  850  872  890  909  930  953  975  999  1030 1070 1104 1130 1156 1177 1192 
      Now I have isolated just the clarinet, and it exhibits the octave jump on the second 1184 note.
                  1	2	3	4	      5	6	7	8	9	0	11	12	13	14
                  Sta	Hold	Vel	Ton	      Oct	Voi	Ste	En1	Gls	Ups	Ren	2gl	3gl	Vol
                  0.01	2.02	66.0	300.0	      5.0	13.0	2.0	1.0	0.0	2.0	1.0	0.0	0.0	8.0
                  2.0	2.02	66.0	188.0	      5.0	13.0	8.0	1.0	0.0	2.0	1.0	0.0	0.0	8.0
                  4.0	0.5	64.0	1184.0	4.0	13.0	1.0	1.0	0.0	2.0	1.0	0.0	0.0	8.0
                  4.49	1.52	64.0	1184.0	5.0	13.0	3.0	1.0	0.0	2.0	1.0	0.0	0.0	8.0
                  6.01	3.03	66.0	1002.0	4.0	13.0	3.0	16.0	0.0	1.0	16.0	0.0	0.0	8.0
      Where else could the octave be increased. It's like I increased octave once, then when I encounter the 1150 or greater cent value I do it again. Is it done twice?
      Where is 1150 in the code?
            in transpose_top_notes, it is checking if a note rounds to 1200, then transpose up to 1200, instead of down to 0.
            in midi_to_notes_octaves_trimmed it is checking if a note is greater than 1150, then reduce the octave by one. It did so twice.
                  octave[note_num, inx] = 6
                  found note = 1184 greater than 1150, need to reduce the octave for that note at octave[0, 8] to
                  octave[note_num, inx] = 5

                  octave[note_num, inx] = 5
                  found note = 1184 greater than 1150, need to reduce the octave for that note at octave[3, 8] to
                  octave[note_num, inx] = 4
      How did the octave get to 6? And why is the order wrong. In the new_output.csd file is 4.0 followed by 5.0. In the log file it's 5 followed by 4. Why? I think I see the problem. Just before the cents report, is the print line: in midi_to_notes_octaves.  That should never appear. I commented out that function. Here is the chain of print statement outputs:
                  In mainline: version = 'bwv245.40', mod = '40_0.75', ratio_factor = 0.75, chorale.shape = (4, 448), quantizer = 4, repeats = 2, result = True
                  chorale.shape = (4, 16)
                  in midi_to_notes_octaves. octave.shape = (4, 18) - I had forgotten to change the print statement in midi_to_notes_octaves_trimmed. I fixed that.
      We still haven't found where the octave gets increased to 6, so that it can be reduced to 5.
      In midi_to_notes_octaves_trimmed it has this: octave[note_num, inx] = 6, then reduced to 5. Why is it 6?  
      In the main line, I need to repeated print out the octave values. They are in chorale_in_cents on what dimension? chorale_in_cents[:,8:16,1]
      I tracked them throughout the mainline. Where did the soprano part go to 6? Here we see the chord #8, 9, 10, 11 all at 6. 
                  octave[:,8:16] = array([[6, 6, 6, 6, 5, 5, 5, 5],
                  1	2	3	4	5	6	7	8	9	0	11	12	13	14
                  Sta	Hold	Vel	Ton	      Oct	Voi	Ste	En1	Gls	Ups	Ren	2gl	3gl	Vol
                  0.0	2.02	66.0	300.0	      3.0	12.0	15.0	16.0	0.0	2.0	16.0	0.0	0.0	10.0  E
                  0.01	2.02	64.0	300.0	      3.0	12.0	6.0	16.0	0.0	1.0	16.0	0.0	0.0	10.0
                  0.01	2.02	66.0	300.0	      5.0	13.0	7.0	1.0	0.0	2.0	1.0	0.0	0.0	8.0   E

                  2.0	2.02	66.0	188.0	      5.0	13.0	11.0	16.0	0.0	2.0	16.0	0.0	0.0	8.0   D
                  1.99	2.02	66.0	1002.0	3.0	12.0	1.0	1.0	0.0	1.0	1.0	0.0	0.0	10.0
                  2.01	2.02	64.0	1002.0	3.0	12.0	12.0	1.0	0.0	2.0	1.0	0.0	0.0	10.0  B

                  3.99	0.5	64.0	1184.0	3.0	12.0	6.0	1.0	0.0	2.0	1.0	0.0	0.0	10.0  C
                  3.99	0.5	66.0	1184.0	4.0	13.0	12.0	16.0	0.0	2.0	16.0	0.0	0.0	8.0   C
                  3.99	0.5	64.0	1184.0	3.0	12.0	10.0	16.0	0.0	1.0	16.0	0.0	0.0	10.0  C
      The next note is not in the score. It's an articact of some feature changing on its own. Maybe the envelope? Or the octave? Got to be octave. But Why?
      And why did it jump 2 octaves? 
                  4.49	1.52	66.0	1184.0	5.0	13.0	16.0	16.0	0.0	2.0	16.0	0.0	0.0	8.0   C jumped by 2 octaves
                  4.49	1.52	64.0	1184.0	4.0	12.0	16.0	16.0	0.0	1.0	16.0	0.0	0.0	10.0  C
                  4.5	1.52	64.0	1184.0	4.0	12.0	4.0	1.0	0.0	2.0	1.0	0.0	0.0	10.0  C up an octave 

                  5.99	3.03	66.0	686.0	3.0	12.0	3.0	1.0	0.0	2.0	1.0	0.0	0.0	10.0
                  5.99	3.03	64.0	1002.0	4.0	13.0	8.0	16.0	0.0	2.0	16.0	0.0	0.0	8.0
                  6.0	3.03	64.0	686.0	3.0	12.0	2.0	1.0	0.0	1.0	1.0	0.0	0.0	10.0          
      Here's another idea. Look at chorale_in_cents[:,4:12,1] which is the octaves for measures 4 - 12. See that note #12 has octave down to 5 but note #13 is still at 6. 
      Could this be the problem that has kept me in a struggle all day? I think so. I think I have to change the octave of the note that is greater than 1150, but I have to change it in the next chord as well. If it's the same as the previous chord, it's not touched.
                  about to call mismatch_check with chorale_in_cents[:,4:12,1] = array([[6, 6, 6, 6, 5, 6, 6, 6],
      What function precedes mismatch_check. 
            tune_chorale, which calls chorale_in_cents = atu.midi_to_notes_octaves_trimmed. There's your trouble spot. I moved the check if it's over 1150 outside the if prev chord section, so every chord would check every note.
      This fixed the wild glissandi and the octave switches in the middle of notes. Almost all of them. One more exists at 81 seconds to 84 seconds in chorale #40. A real whoop. Tempo is 120, so that should be wihin this section:
            chorale = chorale[:,288:304]
      Time to help around the house. Company coming tomorrow.
                  

2.    While you are at it, fix this: 
            woodwinds_part instruments density: prob_silence = [0.9796739450953895, 0.02032605490461048]      
      There is no reason when mask = False to have any prob_silence. Not sure if this is the right formula:
            if mask: prob_silence = [max_silence, 1 - max_silence] 
            else: prob_silence = [1, 0] # if mask is False, then there is no silence - should it be [0,1] or [1,0]? I think I fixed it, but there are still missing notes.

------------------------------
9/8/23 To do today:

1.    Work on the whoops at 288 through 304

                  1	2	3	4	      5	6	7	8	9	      0	11	12	13	14
                  Sta	Hold	Vel	Ton	      Oct	Voi	Ste	En1	Gls	      Ups	Ren	2gl	3gl	Vol
                  3.99	3.03	64.0	1184.0	4.0	15.0	10.0	16.0	1501.0	2.0	16.0	0.0	0.0	9.0
                  3.99	3.03	66.0	1184.0	4.0	15.0	5.0	16.0	1501.0	1.0	16.0	0.0	0.0	9.0
                  4.02	1.01	64.0	1184.0	3.0	12.0	2.0	1.0	0.0	      2.0	1.0	0.0	0.0	10.0
                  4.02	1.01	64.0	1184.0	3.0	12.0	15.0	1.0	0.0	      2.0	1.0	0.0	0.0	10.0
                  5.0	1.01	64.0	1002.0	3.0	12.0	5.0	1.0	0.0	      1.0	1.0	0.0	0.0	10.0
                  5.01	1.01	64.0	1002.0	3.0	12.0	9.0	1.0	0.0	      1.0	1.0	0.0	0.0	10.0
                  5.98	1.01	66.0	798.0	      3.0	12.0	6.0	16.0	0.0	      2.0	16.0	0.0	0.0	10.0
                  6.0	3.03	66.0	482.0	      4.0	16.0	4.0	1.0	1500.0	2.0	1.0	0.0	0.0	10.0
                  6.0	3.03	64.0	482.0	      5.0	13.0	10.0	1.0	1500.0	1.0	1.0	0.0	0.0	8.0
                  6.01	1.01	66.0	798.0	      3.0	12.0	14.0	16.0	0.0	      2.0	16.0	0.0	0.0	10.0
                  6.01	3.03	64.0	482.0	      5.0	14.0	2.0	1.0	1500.0	2.0	1.0	0.0	0.0	11.0
                  6.01	3.03	64.0	482.0	      4.0	16.0	8.0	16.0	1500.0	2.0	16.0	0.0	0.0	10.0
                  6.99	2.02	64.0	1002.0	3.0	12.0	11.0	1.0	0.0	      2.0	1.0	0.0	0.0	10.0
                  7.01	2.02	64.0	1002.0	3.0	12.0	8.0	16.0	0.0	      1.0	16.0	0.0	0.0	10.0
                  7.01	2.02	64.0	1184.0	5.0	15.0	16.0	16.0	1501.0	2.0	16.0	0.0	0.0	9.0
                  7.02	2.02	66.0	1184.0	5.0	15.0	8.0	16.0	1501.0	1.0	16.0	0.0	0.0	9.0

                  f1500.0 0.0 256.0 -6.0 1.0 128.0 1.0063944999999999 128.0 1.012789 
                  f1501.0 0.0 256.0 -6.0 1.0 128.0 2.4747455 128.0 3.949491 <-- There's your trouble. That's a rather large gliss. Almost 4x
      Looking at the logs we see this, with 2 errors in it:
                        need a slide from 8 to 19 slide_array = array([1184, 1184, 1184, 1184, 1184, 1184,    6,    6,    6,    6]), slide_array.shape = (10,), np.unique(slide_array) = array([   6, 1184])
                        09-08,05:45:56.384 - delta_cents = 2378, ratio = 3.949491
      a.    The slide is from 1184 to 6, and the slide array after unique is 6, 1184. That's not right. It should be 1184, 6. Try this:
                        slide = np.array([1184, 1184, 1184, 1184, 1184, 1184,    6,    6,    6,    6])
                        u, ind = np.unique(slide, return_index=True)
                        slide_unique_order_preserved = u[np.argsort(ind)]
                        print(f'{slide_unique_order_preserved = }')
            Actually, I don't use the value that was printed. That was just for the log. The actual failure is up at the top, where delta_cents is determined.
      b.    The slide is enormous.
                        voice_num = 1, note_cents = 6, prev_note_cents = 1184, delta_cents = -1178,
            It then compounds the problem with this:
                  # need to normalize first:
                  if notes_cents > 1150: notes_cents = notes_cents - 1200
                  if prev_notes_cents > 1150: prev_notes_cents = prev_notes_cents - 1200
                  # now calculate the delta between notes_cents at 6 and prev_notes_cents at 1178 - 1200 = -22
                  delta_cents = note_cents - prev_note_cents # -22
                  # I don't need the following line
                        if abs(delta_cents) > 1150: delta_cents = 1200 - delta_cents # this causes the problem

                              max_delta_cents = 2378, delta_cents = 2378

            What I need to do is normalize the prev_notes_cents and the notes_cents (both) so that the arithmetic comes out right. 
      Fixed them all. I think.

2.    Now run the wild ones through all the different ratio_factors. 3, 40, 26 
      26 is still crazy. Not as much as before, but needs work.
      40 has a few spurious octaves at 1:12 to 1:18 chorale = chorale[:,288:320] # measures 19 & 20 288:296 296:320
      Here is how it emerges from assign_chorale. which calls atu.read_from_corpus. It has zeros in the soprano part, because that's what the chorpus has. If that were the case, wouldn't you see that in the sheet music image file? But you don't. I wonder if it was something in the atu.muspy_to_sample_root_mode function.
                        0: [79 70 63 51], ['G♮', 'B♭', 'E♭', 'E♭']
                        1: [79 70 63 51], ['G♮', 'B♭', 'E♭', 'E♭']
                        2: [79 70 63 51], ['G♮', 'B♭', 'E♭', 'E♭']
                        3: [79 70 63 51], ['G♮', 'B♭', 'E♭', 'E♭']
                        4: [ 0 79 70 63], [      'G♮', 'B♭', 'E♭'] <-- why is the soprano part zero?
                        5: [ 0 79 70 63], [      'G♮', 'B♭', 'E♭']
                        6: [79 70 63 62], ['G♮', 'B♭', 'E♭', 'D♮']
                        7: [79 70 63 62], ['G♮', 'B♭', 'E♭', 'D♮']
                        8: [79 72 63 60], ['G♮', 'C♮', 'E♭', 'C♮']
      How is the conversion from the above chorale to the chorale_in_cents done. What are the steps.
                        
                        chord# 0, chord_cents = array([ 686, 1002,  300,  300]), chord_12 = array([ 7, 10,  3,  3]), note_names = array(['G♮', 'B♭', 'E♭', 'E♭'], dtype='<U2'), octave = array([6, 5, 5, 4])
                        chord# 1, chord_cents = array([ 686, 1002,  300,  300]), chord_12 = array([ 7, 10,  3,  3]), note_names = array(['G♮', 'B♭', 'E♭', 'E♭'], dtype='<U2'), octave = array([6, 5, 5, 4])
                        chord# 2, chord_cents = array([ 686, 1002,  300,  300]), chord_12 = array([ 7, 10,  3,  3]), note_names = array(['G♮', 'B♭', 'E♭', 'E♭'], dtype='<U2'), octave = array([6, 5, 5, 4])
                        chord# 3, chord_cents = array([ 686, 1002,  300,  300]), chord_12 = array([ 7, 10,  3,  3]), note_names = array(['G♮', 'B♭', 'E♭', 'E♭'], dtype='<U2'), octave = array([6, 5, 5, 4])

                        chord# 4, chord_cents = array([ 686,  686, 1002,  300]), chord_12 = array([ 7,  7, 10,  3]), note_names = array(['G♮', 'G♮', 'B♭', 'E♭'], dtype='<U2'), octave = array([0, 6, 5, 5])
                        chord# 5, chord_cents = array([ 686,  686, 1002,  300]), chord_12 = array([ 7,  7, 10,  3]), note_names = array(['G♮', 'G♮', 'B♭', 'E♭'], dtype='<U2'), octave = array([0, 6, 5, 5])
                        chord# 6, chord_cents = array([ 686, 1002,  300,  188]), chord_12 = array([ 7, 10,  3,  2]), note_names = array(['G♮', 'B♭', 'E♭', 'D♮'], dtype='<U2'), octave = array([6, 5, 5, 5])
                        chord# 7, chord_cents = array([ 686, 1002,  300,  188]), chord_12 = array([ 7, 10,  3,  2]), note_names = array(['G♮', 'B♭', 'E♭', 'D♮'], dtype='<U2'), octave = array([6, 5, 5, 5])
      How is the conversion from these chords with the octave 0 to the notes_features_15 carried out. Time for a break.
                        Sta	Hold	Vel	Ton	Oct	Voi	Ste	En1	Gls	Ups	Ren	2gl	3gl	Vol
                        0.00	2.02	66.0	686.0	5.0	14.0	6.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0 chord 0, 1, 2, 3
                        2.00	1.01	66.0	686.0	3.0	14.0	3.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0 <-- why octave 3, causes the hold to drop
                        3.00	3.03	66.0	686.0	5.0	14.0	3.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0 <-- why at 3 seconds and not 4, why not held
                        6.00	2.02	66.0	482.0	5.0	14.0	2.0	1.0	1500	1.0	1.0	0.0	0.0	11.0
                        8.00	2.02	64.0	300.0	5.0	14.0	14.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0
                        10.00	2.02	64.0	300.0	3.0	14.0	2.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0 <-- why octave 3
                        12.00	2.02	64.0	188.0	5.0	14.0	12.0	16.0	0.0	2.0	16.0	0.0	0.0	11.0
                        14.00	3.03	66.0	300.0	5.0	14.0	1.0	1.0	0.0	1.0	1.0	0.0	0.0	11.0
      Something is causing the voice 0 to play two octaves lower, What is it about chord 4 that causes trouble. It's because the voice 0 has a zero in the octave. It should be silent, since voice 2 & 3 share the E♭ in voice 3. That causes voice 1 to play G♮, and voice 0 to have octave 0. But it still plays the octave 3 G♮. 
      Then in chord 6 the arrangement of voices goes back to where it belongs. The error is playing voice 0 octave 3 G♮. Focus on the error. Kill the bug. Same thing happens in the flute and clarinet. As to be expected.

      Why is build_glides_array called four times? Because you looped on four ratio_factor values, dummy.

                        18 		['E♭', 'A♭', 'F♮', 'A♭']

-----------------------
9/9/23 To do today:

1.    Figure out if there isn't some weirdness in the atu.muspy_to_sample_root_mode, or perhaps in the music21 to muspy API.
      a.    See if there is a zero on chord 4 & 5 in the muspy music object. There definitely is in the piano_roll. 
      b.    See if there is a way to create my chorale array directly from music21, bypassing muspy.
      c.    Does changing the quantizer have any effect? Nope.

------------------------
9/10/23 To do today:

1.    Consider how I can use the transformer model to tune a chorale.

2.    What if I were to score based not just on the chord, but all the chords within some number of chords previously generated. 
      a.    Rank the scores by their distance into the past, with the current chord having the most influence, and prior chords having less and less influence going into the past. 
      b.    I have been summing scores across all the chords, which is not the same thing, since there is no penalty to creating a chord with a low score within itstelf, but which would have a low score when part of a progression. 
      c.    Allow going into the past to revise a chord that is creating trouble in the present. This would have to be recursive, since changing a chord in the past would affect other chords into the present. 
      d.    This is going to be a big job.

3.    Spend some time on this: Music Autobot:
            /home/prent/Dropbox/Tutorials/musicautobot/MusicAudobot.txt
      I git cloned the repo into that directory. I found it when doing a search for music21 into numpy array. He has a few functions that I could examine. 
      A problem was discovered. In his parsing of the midi file at measure 19:
            chords_from_score[start:end].shape = (19, 4)
            0	1	2	3	[('G♮', 6), ('B♭', 5), ('E♭', 5), ('E♭', 4)]
            4	5	6	7	[('G♮', 6), ('B♭', 5), ('E♭', 5), ('E♭', 5)]
            8	9	[('C♮', 0), ('C♮', 0), ('C♮', 0), ('D♮', 5)]
            10	11	[('G♮', 6), ('C♮', 6), ('E♭', 5), ('C♮', 5)]
            12	13	[('C♮', 0), ('C♮', 0), ('C♮', 0), ('B♭', 4)]
            14	15	[('F♮', 6), ('C♮', 6), ('F♮', 5), ('A♭', 4)]
            16	17	[('C♮', 0), ('C♮', 0), ('C♮', 0), ('B♭', 4)]
            18	valid_notes = 7, zero_notes = 12
      Two problems: at chord 9 we have three zeros, and then the D♮
      at chord 7 we have an E♭ at octave 5, when it should be at 4. Weird

4.    Maybe mido has a midi reading function. See read_mido.ipynb
            mid = mido.MidiFile('song.mid')
                  for msg in mid.play():
                  port.send(msg)

5.    An implementation here on a medium post:
            https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c
      Uses this github gist:
            https://gist.github.com/HuangWeiKulish/cda8ac2d29b3976d2dd15cbf6a85a3c9
            https://gist.github.com/HuangWeiKulish/daba05a2f1292298f1b77865b5082f83#file-midi2numpy-mido-7-py
      It creates a numpy array of the midi file, but I can't make heads or tails of it. It's an 
            result_array.shape = (114687, 88) # 114k steps with several notes each.
      
--------------------
9/11/23 To do today:

1.    Figure out some way to reliably read a midi file.
      If I take my time, I can figure out what's going on. 
      First, add 21 to the note number so that middle C is 60
      There are 1024 steps to each quarter note. That seems a bit excessive. But regardless, I can make it work:
            0000, [(54, 'E♭', 6), (49, 'B♭', 5), (46, 'G♮', 5), (30, 'E♭', 4)]
            1024, [(53, 'D♮', 6), (49, 'B♭', 5), (44, 'F♮', 5), (37, 'B♭', 4)]
            1024, [(51, 'C♮', 6), (46, 'G♮', 5), (42, 'E♭', 5), (39, 'C♮', 5)]
            1024, [(49, 'B♭', 5), (46, 'G♮', 5), (41, 'D♮', 5), (34, 'G♮', 4)]
            1024, [(47, 'A♭', 5), (44, 'F♮', 5), (40, 'D♭', 5), (37, 'B♭', 4)]
            512, [(46, 'G♮', 5), (42, 'E♭', 5), (40, 'D♭', 5), (37, 'B♭', 4)]
            512, [(51, 'C♮', 6), (42, 'E♭', 5), (39, 'C♮', 5), (35, 'A♭', 4)]
      The leading value is the time before the chord is to be played. The chord is a list of four tuples, each tuple containing the note number, the note name, and the octave. If I save each chord on the 256 step boundary, I should be able to create the chorale array. 
            
2.    So I now have two new ways to process a midi file into a chorale array. 
      One is by reading the music21 stream, based on the module created by Andrew Shaw, bearpelican on github: https://github.com/bearpelican/musicautobot/tree/master
      The second is based on a Medium post by Huangwei Wieniawska here:   https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c
      Both will take some work, but not more than a couple of hours. The first one produces chords only if all the notes move at the same time. If there is one 1/8th note, it puts zeros in all the other voices. I will need some code to fix that. If I don't, my code will just turn the zeros into the other note in the chord, but that's not what I want. We want to evaluate the chord with all the notes that are sounding at that point in time. I'll have to turn the zeros into the notes from the previous chord. That's won't be too hard. Then I'll have to figure out how many chords to create for each time-step.
      The second method may be easier, just take one out of every 256 time-steps.
      
---------------------
9/12/23 To do today:

1.    Imagine you are attempting to get a Large language Model to code your ideal tuning algorithm in python. What would you use as the prompt?
      a.    You will be supplied with a numpy array of midi notes with a dimension of (4,512), where the first dimension is the voices and the second is the midi notes to be played by that voice, in a time-step sequence from the start of the piece to the end.
      b.    Your task is to tune those notes to the optimal just intonation tuning possible. 
      c.    The midi notes have 12 tones to each octave from 0 to 127, where 60 is middle C, and 72 is an octave higher C. 
      d.    Transform the midi note numbers into cent value in a 1200 equal steps per octave.
                  cent_value = 100 * (midi_note % 12)
      e.    The optimal tuning is one that chooses cent values that minimize the numerator and denominator of the ratio of all the intervals in the chord that is playing at each time-step. 
      f.    There are six intervals in a four note chord. The number of intervals in a chord is expressed with the following formula:
                  num_intervals = (num_notes * (num_notes - 1)) // 2
            All the intervals have equal importance.
            
      g.    The formula for converting cents to ratio is:
                  import numpy as np
                  ratio = np.power(2, cents/1200))
      h.    The formula for converting ratio to cents is: 
                  cents = 1200 * np.log(ratio)/np.log(2)
      i.    To determine the numerator and denominator of a ratio, this formula will do that:
                  from fractions import Fraction
                  limit_denominator = 105
                  f = Fraction(np.power(2, cents/1200)).limit_denominator(limit_denominator)
                  return f.numerator, f.denominator
      j.    The importance of low number ratios has to be balanced with other requirements:
            a.    The highest priority is low number ratios for the notes occuring at the same time, which are the four notes in the same time step.
            b.    The next highest priority is limiting the distance from the original 12 tone equal temperament note so that when rounded, the cent value will round to the same note as the original midi number.
            c.    The next highest priority is limiting the movement of notes from one time-step to the next, giving priority to adjacent notes, and less priority to notes two or more time steps from the current note.  
            
2.    The mido method does the same thing as the music21 to muspy method. Look at the notes in the chorale[288:304] measure 19.
      I added 21 to all the values before loading it into chorale array:
            chorale[:,chord_num] = chord + 21
      And this is the result:
                  288	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 4)
                  289	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 4)
                  290	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 4)
                  291	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 4)
      21 was 0 -> 292	(21, 'A♮', 1)	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5) 
      21 was 0 -> 293	(21, 'A♮', 1)	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)
                  294	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(62, 'D♮', 5)
                  295	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(62, 'D♮', 5)
      I was hoping that it would keep the G♮ in the soprano part, but it didn't. It's still a zero, converted to a 21.
      I suppose I could force the soprano note at 292 and 293 to be the same note as the alto note. Actually what I would like is to have 292 and 293 look like the actual notes in the score I see in musescore: 
                  292	(79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 5)
                  293   (79, 'G♮', 6)	(70, 'B♭', 5)	(63, 'E♭', 5)	(51, 'E♭', 5)
      It's like when it sees two voices playing the same note, it can't handle it, and it moves the notes down a voice. I would have to determine how to fix every one of these flaws. There's another one in measure 20, where tenor and bass both have a B♭ for the second quarter note. 
                  308	(21, 'A♮', 1)	(75, 'E♭', 6)	(67, 'G♮', 5)	(58, 'B♭', 4)
                  309	(21, 'A♮', 1)	(75, 'E♭', 6)	(67, 'G♮', 5)	(58, 'B♭', 4)
                  310	(21, 'A♮', 1)	(75, 'E♭', 6)	(67, 'G♮', 5)	(58, 'B♭', 4)
                  311	(21, 'A♮', 1)	(75, 'E♭', 6)	(67, 'G♮', 5)	(58, 'B♭', 4)
      If I see the 21, I need to move all the notes up a voice and double up the bass B♭
                  308   (75, 'E♭', 6)	(67, 'G♮', 5)	(58, 'B♭', 4)	(58, 'B♭', 4)
      How can I know when to do this? And which move to make? Find where all the 21's are in the chole chorale. Where are the 21'S
                  found a 21 in chord 70 at voice 0
                  found a 21 in chord 71 at voice 0
                  ...
                  found a 21 in chord 394 at voice 0
                  found a 21 in chord 395 at voice 0
      They are all at voice 0. That's a good thing. I can just move the notes up a voice and double the bass. Or should I double a different voice?
                  found a 21 in measure 5 1.5 chord 70 at voice 0
                  68	(72, 'C♮', 6)	(68, 'A♭', 5)	(63, 'E♭', 5)	(56, 'A♭', 4)
                  69	(72, 'C♮', 6)	(68, 'A♭', 5)	(63, 'E♭', 5)	(56, 'A♭', 4)
                  70	(21, 'A♮', 1)	(72, 'C♮', 6)	(68, 'A♭', 5)	(56, 'A♭', 4)
      Here is the second quarter note in measure 5. What should I change this to?
                  70    (72, 'C♮', 6)	(72, 'C♮', 6)	(63, 'A♭', 5)	(56, 'A♭', 4)
                  71    (72, 'C♮', 6)	(72, 'C♮', 6)	(63, 'A♭', 5)	(56, 'A♭', 4)
      How will I recognize this in the chorale? It's not the same alteration as the one at chord 310 shown above. 

Time for a walk with the dogs to think.

--------------------------------
9/13/23 To do today:

1.    The problem with the missing notes and the zero notes are due to the conversion to a piano roll.
      Think about it. When there is only one place where the note number can be stored, there will only one voice that gets to play that note. It was never a problem when you were messing around with the arpeggios and other modifications. But when you are trying to track a voice through the chorale, the problem surfaces. The only way to solve it is to skip the filter of the piano roll step. It's needed for deep learning, but it ruins the voice consistency. 
      Go back to the mido process and figure it out.

2.    what is python-rtmidi? It's a python wrapper for the rtmidi C++ library. 
      It's a cross-platform library for realtime MIDI input. does it read midi files? 
            https://www.cs.cmu.edu/~music/cmsip/readings/davids-midi-spec.htm 
      Don't need it. Mido is all I think I need.

3.    I was stuck for an hour trying to figure out how to differentiate between a 1/4 and 1/8th note. 
      It turns out the note-off message contains information on time that I can use.
      Here is the opening of bwv245.40:
                  note on:  msg_num = 3,  track_num = 1, msg.time =    0, 75, E♭, 6
                  note off: msg_num = 4,  track_num = 1, msg.time = 1024, 75, E♭, 6
                  note on:  msg_num = 5,  track_num = 1, msg.time =    0, 74, D♮, 6
                  note off: msg_num = 6,  track_num = 1, msg.time = 1024, 74, D♮, 6
                  note on:  msg_num = 7,  track_num = 1, msg.time =    0, 72, C♮, 6
                  note off: msg_num = 8,  track_num = 1, msg.time = 1024, 72, C♮, 6
                  note on:  msg_num = 9,  track_num = 1, msg.time =    0, 70, B♭, 5
                  note off: msg_num = 10, track_num = 1, msg.time = 1024, 70, B♭, 5
                  note on:  msg_num = 11, track_num = 1, msg.time =    0, 68, A♭, 5
                  note off: msg_num = 12, track_num = 1, msg.time =  512, 68, A♭, 5
                  note on:  msg_num = 13, track_num = 1, msg.time =    0, 67, G♮, 5
                  note off: msg_num = 14, track_num = 1, msg.time =  512, 67, G♮, 5
      So when I encounter a note-off message, I can look at the time value and see if it's 1024 or 512. If it's 1024, it's a quarter note. If it's 512, it's an eighth note. 256 for a 1/16th note.
      I accomplished loading a chorale. It solves the problems caused by the piano roll. 
      But now it creates a chorale array with all the same chord throughout.

4.    Found another problem with the octaves. 
      In measure 19, the alto part (oboe), there is a slide ftable 1500. 
      In the middle of the slide it jumps an octave. This is one of those slighly flat C naturals. Cent value of 1184 to 6, and the octave jump is not correct. It should have been octave 5, not 6. Where would that be discovered?
                        Sta	Hold	Vel	Ton	      Oct	Voi	Ste	En1	Gls	
                        0.0	4.04	64.0	1002.0	4.0	15.0	4.0	1.0	0.0	
                        0.01	4.04	66.0	1002.0	4.0	15.0	2.0	16.0	0.0	
                        4.0	3.03	64.0	1184.0	4.0	15.0	6.0	1.0	1500.0
                        4.01	3.03	64.0	1184.0	4.0	15.0	5.0	16.0	1500.0
                        6.98	1.01	64.0	1184.0	5.0	15.0	11.0	16.0	1500.0
                        7.02	1.01	64.0	1184.0	5.0	15.0	16.0	1.0	1500.0
                        7.99	2.02	64.0	798.0	      4.0	15.0	13.0	16.0	0.0	
                        8.01	2.02	64.0	798.0	      4.0	15.0	12.0	16.0	0.0	
                        f1500.0 0.0 256.0 -6.0 1.0 128.0 1.0063944999999999 128.0 1.012789 
      I suggest that the best fix is to assign a single value to all the octaves at the same time I am assigning a single value to all the notes. 
            chorale_in_cents_slides[note_num, first_chord_num:last_chord_num, 0] = prev_note_cents # set the cents in all the identified time slots to the initial cent value 
      It's at this point in adaptive_tuning_util.py that I should assign the same octave to all the notes in this chain. I did kind of a hack fix for this. It may come back to bite me on the keister:
            logging.info(f'about to fix the octaves across the slide. {chorale_in_cents_slides[note_num, first_chord_num:last_chord_num, 1] = }, {prev_note_cents = }')
            if prev_note_cents > 1150: 
                  chorale_in_cents_slides[note_num, first_chord_num:last_chord_num, 1] = chorale_in_cents_slides[note_num, first_chord_num, 1]
                  logging.info(f'after the fix octaves across the slide. {chorale_in_cents_slides[note_num, first_chord_num:last_chord_num, 1] = }')
      A few problems with this:
      a.    I assume that the first octave in the chain has the proper octave if I subtract one from it. It fits this case because we start at cent 1184 in octave 5, and the end at cent 6 octave 6. So if I assign the 5 to all the notes in the chain I'll be ok. We shall see if that holds. What I should have done is evaluate all the conditions that could possibly happen, and then include all those in the analysis and fix. Maybe later.

----------------------
9/14/23 To do today:

1.    Should I try to read the music21 stream instance as I did with the mido music structure? 
      I was thinking about that last night. It might shave a few milliseconds off the processing time. If so, here's an example that I have not checked out from Googld Colab:
            https://colab.research.google.com/github/cpmpercussion/creative-prediction/blob/master/notebooks/3-zeldic-musical-RNN.ipynb
      I downloaded it as 3_zeldic_musical_RNN.ipynb in the TonicNet directory.

2.    Imagine you are attempting to get a Large language Model to code your ideal tuning algorithm in python. 
      What would you use as the prompt?
      a.    You will be supplied with a numpy array of midi notes with a dimension of (4,512), where the first dimension is the voices and the second is the midi notes to be played by that voice, in a time-step sequence from the start of the piece to the end.
      b.    Your task is to tune those notes to the optimal just intonation tuning possible. 
      c.    The midi notes have 12 tones to each octave from 0 to 127, where 60 is middle C, and 72 is an octave higher C. 
      d.    Transform the midi note numbers into cent value in a 1200 equal steps per octave.
                  cent_value = 100 * (midi_note % 12)
      e.    The optimal tuning is one that chooses cent values that minimize the numerator and denominator of the ratio of all the intervals in the chord that is playing at each time-step. 
      f.    There are six intervals in a four note chord. The number of intervals in a chord is expressed with the following formula:
                  num_intervals = (num_notes * (num_notes - 1)) // 2
            All the intervals have equal importance.
            
      g.    The formula for converting cents to ratio is:
                  import numpy as np
                  ratio = np.power(2, cents/1200))
      h.    The formula for converting ratio to cents is: 
                  cents = 1200 * np.log(ratio)/np.log(2)
      i.    To determine the numerator and denominator of a ratio, this formula will do that:
                  from fractions import Fraction
                  limit_denominator = 105
                  f = Fraction(np.power(2, cents/1200)).limit_denominator(limit_denominator)
                  return f.numerator, f.denominator
      j.    The importance of low number ratios has to be balanced with other requirements:
            a.    The highest priority is low number ratios for the notes occuring at the same time, which are the four notes in the same time step.
            b.    The next highest priority is limiting cent value distance of notes from the original 12 tone equal temperament note so that when rounded, the cent value will round to the same note as the original midi number.
            c.    The next highest priority is limiting the ratio of notes from one time-step to the next, giving priority to adjacent notes, and less priority to notes two or more time steps from the current note. 
      What else did Paul Erlich say were the requirements?
      -     all major and minor triads be made of 5-limit ratios
      -     no drift of the same note over time
      -     all pitch shifts be under 6 cents. I presume he means glides 
      -     lower number ratios in *vertical* intervals too. Does he actually mean horizonatal here?
      -     common tones be held between chords if/when possible.
      -     tolerance for cent distance from 5-limit just is ~0.1 cents. 
      -     Since my precision is one cent, this is basically no tolerance at all.

3.    Finish the complete set of chorales with ratio factors [0.75, 1.0, 1.5]
      We have a problem with bwv245.28. Really whack. It was fine with I just ran 1.0. Try 1.5 and see if it goes to Kansas. All were perfect. Weird.
      Maybe it was 26. That one was fine too. Maybe doing several at once? 3, 40, 26. I've done them all and none show any problems. I may have just inadvertently started two at the same time in two instances of Audacity.

4.    See what happens when I combine the finger_piano_part with the existing woodwinds_part. It still works. Amazing.
      I had to get rid of all references to quantization, since that's not needed any more. I don't notice the glides. Nor any disturbances between the glides in the winds and the lack of glides in the arpeggios. 

5.    Consider scoring based on all the notes within 16 1/16 notes of each chord. 
      Consider using that to optimize the current chord or transposition.      

------------------------
9/15/23 To do today:

1.    What if I let the arpeggios use chorale_in_cents_slides? I can't hear the difference. 
      It's because finger_piano_part doesn't pay attention to the gliss. I'd have to rework it. I had to create a new function just so I could avoid ruining the old one:
            def finger_piano_part_glides(chorale, glides, stored_gliss, repeats, voice_names, voice_time, tpq, volume_function, probs = None):
      Notice that two new arguments are being passed, glides and stored_gliss. I will have to update the calling to pass those arguments. Having trouble with the dimensions of notes = notes_octaves[:,:,0] # the 0th feature is the note # (4, 256)
      In atu.add_features_glides. I'm getting this error:
                  IndexError: too many indices for array: array is 2-dimensional, but 3 were indexed
      How is finger_piano_part different from woodwinds_part in the dimension of the array passed to atu.add_features_glides?
                  in finger_piano_part. chorale.shape = (4, 46, 2) <-- this at the start of finger_piano_part. 3 dimensions.
      Then soon after that:
                  after repeating each note repeats = 14: chorale.shape = (4, 644) <-- its down to 2 dimensions 
      Here is the transformation up close:
                  before repeating: chorale.shape = (4, 42, 2), glides.shape = (4, 42)
      What happens here: 
                  after repeating: chorale.shape = (4, 420), glides.shape = (4, 420)
      I found this:
            glides = chorale = np.repeat(glides, repeats, axis = 1) # make each glide repeats times as long # <-- there's your trouble.
      I have no idea what that does, but it's not what I wanted. 
      I'm still not seeing any glides in the new_output.csd. There is an ftable, but none of the gliss values are 1500 or 1501. and the only ftable in the file is 1500, because the 1501 is actually the same shape as 1500, and not needed. But why are none of them in new_output.csd?
      The stored_gliss results are written to new_outout.csd. But the notes_features_15 doesn't seem to have them. The only explanation I can come up with is a bug in the finger_piano_part_glides function, failing to store the glide values in the notes_features_6 or _15 arrays.
      I see the glides array with a lot of 1500's:
                  glides = array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   0, 1500, 1500, 1500, 1500,...
      I think I have it all working now. But I can't say that I can hear any of the arpeggios having a detectable slide. They are clearing in the new_output.csd file now. The biggest is 49 cents, which isn't large enough to be audible to these old ears. My fear about whoop, whoop, whoop glissandi was unfounded. 

2.    Before you do anything, take a look at the most recent slide_tunning_output.txt. 
      It contains the cent report for all the chorales in the three primary tunings. I really want to implement that measure of the justness that takes 8 1/16 notes either side of every chord. Once I have that data, then I need a way to optimize it.

3.    See if you can add more slow chorales. Without the quantize factor, all the chorales are fast. 
      Actually, I had hard coded tempo to 120 and not removed the tempo = 120 line. Oops. Ran them all again. 

-------------------------
9/16/23 to do today:

1.    Figure out why vscode sometimes slows down in accepting key strokes. It's getting really bad.
      I'm using Chrome now, and will see if the problems I was experiencing were due to Edge browser. The same thing happened on Chrome, so switching only solved the problem temporarily.

2.    Pick the best onese to use in a new CD.    
            find ~/Music/sflib/ball9-t??_*.wav  -printf "%f\n"
                  ball9-t11_0.75.wav      slow
                  ball9-t11_1.0.wav       slow
                  ball9-t11_1.5.wav       moderate spped
                  ball9-t14_0.75.wav      slow
                  ball9-t14_1.0.wav       moderately slow. Some weird tuning at the start
                  ball9-t14_1.5.wav       slow
                  ball9-t15_0.75.wav      moderate speed
                  ball9-t15_1.0.wav       fast, decent harmonies
                  ball9-t17_1.0.wav       slow   
                  ball9-t17_1.5.wav       fast
                  ball9-t22_0.75.wav      fast
                  ball9-t22_1.5.wav       slow
                  ball9-t26_0.75.wav      moderately fast
                  ball9-t26_1.0.wav       moderate speed
                  ball9-t26_1.5.wav       moderately fast
                  ball9-t28_0.75.wav      slow   
                  ball9-t28_1.0.wav       moderately fast
                  ball9-t28_1.5.wav       moderately fast
                  ball9-t.3_1.0.wav       fast 
                  ball9-t.3_1.5.wav       slow
                  ball9-t37_0.75.wav      moderate speed
                  ball9-t37_1.0.wav       moderately fast. monotonous rhythm. ticky tacky
                  ball9-t37_1.5.wav       slow and ponderous
                  ball9-t40_0.75.wav      moderately fast
                  ball9-t40_1.0.wav       fast
                  ball9-t.5_0.75.wav      fast
                  ball9-t.5_1.5.wav       slow

            Best so far:
                  ball9-t.3_0.75.wav      sweet morning harmonies slow and fast at the same time. 
                  ball9-t40_1.5.wav       fast - best of the 40's
                  ball9-t22_1.0.wav       moderate tempo nice harmonies - listen for the bends
                  ball9-t15_1.5.wav       slow & regal
                  ball9-t.5_1.0.wav       moderately fast. nice rhythm
                  ball9-t17_0.75.wav      moderate speed nice start
                  ball9-t11_1.5.wav       fast. Some weird slides in finger piano at the start
                  ball9-t14_1.0.wav      
                  ball9-t37_1.5.wav
                  ball9-t.3_1.5.wav
                  ball9-t28_1.5.wav

---------------
9/17/23 To do today:

1.    Consider passing a few more chords into the scoring function. 

2.    Clean up the logging.info in the code, replacing with debug where possible, to reduce the size of the log files.

3.    Look at Stable Audio results: 
            https://stability.ai/research/stable-audio-efficient-timing-latent-diffusion

4.    Run a few more looking for the diamond in the rough.
            find ~/Music/sflib/ball9-t??_*.wav  -printf "%f\n"
                  ball9-t11_0.75.wav      slow. Some funny slides in guitar at 2:46
                  ball9-t11_1.0.wav       moderately slow. Nothing out of the ordinary.
                  ball9-t14_0.75.wav
                  ball9-t14_1.5.wav
                  ball9-t26_0.75.wav
                  ball9-t26_1.0.wav
                  ball9-t26_1.5.wav
                  ball9-t28_0.75.wav
                  ball9-t28_1.0.wav
                  ball9-t28_1.5.wav
                  ball9-t.3_0.75.wav
                  ball9-t.3_1.0.wav
                  ball9-t37_0.75.wav
                  ball9-t37_1.0.wav


--------------------------
9/18/23 To do today:

1.    I have two ideas for further development:
      a.    Resurrect the previously used code in diamond_music_utils to evaluate chords based on having notes not in the root key.
            Stretch those out so they are the primary component of the piece. Take one of the tonicnet synthetic chorale that has the most pitch entropy from the thousands that I created last year, and make it much longer using the techniques I developed previously: tile, reverse, reverse and tile, invert, all combinations of those.
      b.    Find a way to score the chorales based on the justness of the chords within 16 1/16 notes of each chord. 
            Then based on the score, repeat sections (how long?) where the score is high (or low?). This will provide the start on a method to optimize the tuning of the chorale horizontally.
      c.    Set the quanitization value very high, then trim away the chords that stay static too long. 
      d.    Consider an option that eliminates the glides in the arpeggios. They aren't necessary and sometimes sound weird. 
      e.    Get a better understanding of the quanitize variable. I get consitent results now on an example that includes 1/16th notes: bwv245.3. With 2 and 3, it displays an error message that indicates increasing the quantization value is recommended. At 2, it simply drops the one 1/6th note completely, but plays the rest straight. At 3, it's kind of randomly dropping notes in a strange way. At 4, all is well. With 5, it does similar weird things to the timing of voices. Some are delayed from where they should be, but in interesting ways. Same with 7. Clearly if I don't want voices to be staggered, I need to use multiples of 4, like 4, 8, 16, 32, etc. For example, 12 staggers voices, just not all of them. 

----------------------
9/19/23 To do today:

1.    Make the tempo contingent not only on repeats, but also quantization. Done. I'm getting good results for quantization = 
            64, 32, 13 for long pieces 
            3, 4, 5 for short ones
            Some were done on the ThinkCentre and some on the T15. Those marked as saved are in the saved directory on the T15

                  ball9-t14_1.5     10:13       ⍣ fast, evocative - saved
                  ball9-t11_1.5     7:13        ⍣  - saved
                  ball9-t.5_1.0     5:11        ⍣ Short, Fast movement through the changes. Really nice ending. ThinkCentre
                  ball9-t40_1.5     7:38        ⍣  - saved              
                  ball9-t37_1.0     7:16        ⍣ Terrific polyrhythms - must have been on the ThinkCentre
                  ball9-t28_1.5     15:26       ⍣  - saved                
                  ball9-t26_1.0     4:03        ⍣ Nice fast movement staggered voices. ThinkCentre
                  ball9-t22_1.5     7:13        ⍣ - saved    
                  ball9-t17_1.5     8:59        ⍣ - saved            
                  ball9-t15_1.25    6:45        ⍣ slow and short-ish. Some sour notes at 4:45        
                  ball9-t.3_1.5     14:35       ⍣ - saved    

Some of these are on the ThinkCentre and some are on the T15. I need to get them all in the same place. Where I have a working CD burner application. Brasero on the T15 doesn't seem to generate good CD's that can be read in the car, and Brasero on ThinkCentre thinks all the audio files are invalid. 
----------------------------
9/20/21     To do today:

1.    Create new versions with a different quanitization than 64 for those that didn't get stars (⍣)from yesterday.
      include: 11, 5, 37, 26, and now 15.
      Try shorter versions of 5, 37, 26, 15
      #3 at 9:30 has those short glides very prominent. I like them. They are so fast that they become timbre, not tuning.

2.    Find a way to reduce the clipping, which has been under the radar for a while, but seems to be more and more prevalent.
                  end of score.		   overall amps:  42749.5  40259.8
                  overall samples out of range:      250      261     
      Where am I setting the volume levels?
            volume_function = np.array([
                              [8,8,0,2,0,0,0,4,6],  # finger_pianos  0
                              [6,0,0,5,0,4,6,4,6],  # wood_winds     1
                              [0,0,4,0,8,6,0,4,7],  # pizz_strings   2   
                              [0,0,0,0,8,0,0,4,6],  # bowed_strings  3
                              [0,6,6,0,0,4,2,4,7],  # brass          4
                              [0,0,4,8,1,1,8,4,8]]) # perc_guitar  5 
      That fixed it.

3.    Endings are a problem. Cut off for now reason. Something wrong with ball9c.csd? Yes. There's your trouble.
            i1 0 819.0 .0085   1.81124716553287981859410430839
      It should be:
            i1 0 replaceme .0085   1.81124716553287981859410430839
      I must have halted the kernel after it had updated the time, but before it reset it to the default value.

4.    Make the quantization a choice:
            quantization = rng.choice([64, 32, 13, 3, 4, 5], p = [.25, .07, .08, .2, .2, .2]) # pick
      Make sure you put that inside the loop for each chorale.

----------------------------                  
9/21/23 To do today:

1.    Listen to the pieces described in save.txt, where the duration, chorale #, ratio_factor, repeats, and quantization are shown for the latest productions.
      grep -E "duration: | quantization = | - version = " slide_tuning.log > save.txt
            09-21,07:59:15.414 - version = 'bwv245.5', mod = '.5_1.0'
            09-21,07:59:16.955 - repeats = 12, quantization = 5 tempo = 92
            09-21,07:59:18.260 - duration: 00:08:01.000

2.    Fix the duration logging.info so it is shorter. Done. 

----------------------------------
9/22/23 To do today 

1.    Listen to yesterday's production 

2.    Create a report that matches the file save.txt, providing a list of created works, with key information: name, ratio_factor, duration, tempo, quantization, & repeats. What else? 
      max_score, count_score, and average_score from atu.print_interval_cent_report
      count of unique notes in cents.  unique_cent_values which is len(value)

3.    How exactly does it work when I choose a quantization that is not a multiple of 4? For example, 5. 
      In load_from_midi_file(file_name, quantization = 4), we have this calculation:
            ticks_per_beat = mid.ticks_per_beat # 10080
            slots_per_quarter = ticks_per_beat // quantization # 10080 // 4 = 2520, 10080 // 5 = 2016, 10080 // 3 = 3360, 10080 // 7 = 1440
      In the current batch of midi files, ticks_per_beat = 10080. A 1/4 note is the beat, so 10,080 clicks represent a 1/4 note, 2520 represent a 1/16th note.
      While it's reading the midi file, it encounters one of the meta information messages resets the ticks_per_beat to 8.
            ticks_per_beat = msg.notated_32nd_notes_per_beat # <-- 8 1/32 notes per beat, 4 1/16th notes per beat
      Then it starts reading the note-on and note-off messages
      
      When we encounter a note_off message, we decide how many slots in chorale will be assigned the current note. Normally, ticks_per_beat is 8, and quantization is 4, so we would assign slots_per_quarter the value of 2. 
      The variable msg.time in the midi note-off message is how many midi clicks have passed since the note_on message was received. 
                  msg.time = 10080
                  msg.time = 5040,
                  msg.time = 5040,
                  ...
                  msg.time = 2520,
                  msg.time = 2520,
                  msg.time = 10080
      spq is then used here:
            slots = msg.time // slots_per_quarter # 10080 // 2520 = 4, 5040 // 2520 = 2, 2520 // 2520 = 1
      So this is how we load the chorale file under normal circumstances with sensible quantization numbers. If they are multiples of 4, you get what you expect, a faithful rendition of the midi file of a chorale. 
      What happens if quantization is 3, 5, 7, 13, 17, etc?
            slots_per_quarter = 3360
      First two voices in chorale bwv245.5:
            msg.time = 10080, note info: 69, 5, slots = 3, chorale_num = 0
            msg.time = 5040, note info: 69, 5, slots = 1, chorale_num = 3
            msg.time = 5040, note info: 67, 5, slots = 1, chorale_num = 4
            msg.time = 10080, note info: 65, 5, slots = 3, chorale_num = 5
            msg.time = 10080, note info: 67, 5, slots = 3, chorale_num = 8
            msg.time = 5040, note info: 69, 5, slots = 1, chorale_num = 11

            msg.time = 10080, note info: 62, 5, slots = 3, chorale_num = 0
            msg.time = 10080, note info: 57, 4, slots = 3, chorale_num = 3
            msg.time = 10080, note info: 57, 4, slots = 3, chorale_num = 6
            msg.time = 10080, note info: 55, 4, slots = 3, chorale_num = 9
            msg.time = 5040, note info: 58, 4, slots = 1, chorale_num = 12
      Things get staggered. What about 7:
            msg.time = 10080, note info: 69, 5, slots = 7, chorale_num = 0
            msg.time = 5040, note info: 69, 5, slots = 3, chorale_num = 7
            msg.time = 5040, note info: 67, 5, slots = 3, chorale_num = 10
            msg.time = 10080, note info: 65, 5, slots = 7, chorale_num = 13
            msg.time = 10080, note info: 67, 5, slots = 7, chorale_num = 20

            msg.time = 10080, note info: 65, 5, slots = 7, chorale_num = 0
            msg.time = 10080, note info: 64, 5, slots = 7, chorale_num = 7
            msg.time = 5040, note info: 64, 5, slots = 3, chorale_num = 14
            msg.time = 5040, note info: 62, 5, slots = 3, chorale_num = 17
      1/8th notes get turned into 1/16th notes or dotted 1/8th notes. And max and average scores go up:
                  Maximum score was: 201.0 Average score was: 68.0

-------------------------------
9/23/23 To do today:

1.    I now have what I think is a working Dropbox on the Chromebook Debian. 
      See if I can run the whole notebook. It works!

2.    Figure out what is the maximum quantization value. 
      I'm thinking at a certain point it will go whack on me. Test out the limits.
      slots = 8, chorale_num = 384, chorale.shape = (4, 384), quantization = 8, slots_per_quarter = 128
      slots = 16, chorale_num = 768, chorale.shape = (4, 512), quantization = 16, slots_per_quarter = 64 <-- shape should be 768
      slots = 32, chorale_num = 1536, chorale.shape = (4, 512), quantization = 32, slots_per_quarter = 32
      slots = 64, chorale_num = 3072, chorale.shape = (4, 512), quantization = 64, slots_per_quarter = 16
      slots = 128, chorale_num = 6144, chorale.shape = (4, 512), quantization = 128, slots_per_quarter = 8
      I think I found the limit. Notice how the chorale.shape doesn't increase beyond 512. I wonder why. 
            chorale = np.zeros((4, 512), dtype = int)
      There's your trouble. You hard coded the array size. Wrong move. I should have made it dependent on the quantization in some way. What are some of the variables available just before that definition of chorale. Here they are:
            ticks_per_beat = 1024
            tempo = 500,000
            time_sig_num = 4, time_sig_den = 4, time_sig_clocks = 24, ticks_per_beat = 8
            mid.length = 24.5 # total length of the midi file in seconds.
      Here are the first few note_off messages, which show the quarter notes as 1024.
            note off: voice = 0, msg.time = 1024,
            note off: voice = 0, msg.time = 512, 
            note off: voice = 0, msg.time = 512, 
      And here are the variable values at the end:
            slots = 4, chorale_num = 192, chorale.shape = (4, 192), quantization = 4, slots_per_quarter = 256
            chorale.shape = (4, 192), root = 2, mode = 'min', time_sig = '4/4', version = 'bwv245.5'
      I would need 192 slots for this quantization value of 4. 
            slots = 4, chorale_num = 192, chorale.shape = (4, 192), quantization = 4, slots_per_quarter = 256
            slots = 8, chorale_num = 384, chorale.shape = (4, 384), quantization = 8, slots_per_quarter = 128
            slots = 16, chorale_num = 768, chorale.shape = (4, 768), quantization = 16, slots_per_quarter = 64
            slots = 32, chorale_num = 1536, chorale.shape = (4, 1536), quantization = 32, slots_per_quarter = 32
            slots = 64, chorale_num = 3072, chorale.shape = (4, 3072), quantization = 64, slots_per_quarter = 16
            slots = 128, chorale_num = 6144, chorale.shape = (4, 6144), quantization = 128, slots_per_quarter = 8
      That's more like it. What about odd values for quantization:
            slots = 31, chorale_num = 1479, chorale.shape = (4, 1479), quantization = 31, slots_per_quarter = 33 tempo = 112

------------------------
9/24/23 To do today:

1.    Create a save2.txt like the one I made yesterday for the files created on the ThinkCentre.
      chorale quan     version mod repeat tempo duration notes 
       232       5   ball9-t22_1.5      6    76    04:48 ✔ 
       538       5   ball9-t40_1.0     12   108    08:46 ✔ 
        48       2   ball9-t.3_1.5     10    58    02:36 ✔
       176       4   ball9-t17_1.0     18   116    07:38 ✔
       232       5   ball9-t22_1.5      6    76    04:48 ✔
      1024      16   ball9-t28_1.5     12   132    23:39 ✔
        96       2   ball9-t11_1.5     14    84    02:41 ✔
        96       2   ball9-t.5_1.5     16    76    03:28 ✔
       768      16   ball9-t11_1.0      6   102    11:29 ✔
       314       3   ball9-t40_1.5      6    62    02:51 ✔
       135       3   ball9-t.5_1.0     14    98    04:27 ✔
      4096      64   ball9-t14_1.0     10   144    11:23 ✔ I wish this was just a tad slower

------------------------
9/28/23 To do today:

1.    Review this video on LMM and Audio
      https://youtu.be/dRjT6AYsj7E?si=i4zVs8f-fXBFLMaq
      Generative AI for Music and Audio (IIS, Academia Sinica)
      Hao-Wen (Herman) Dong 董皓文 PhD student at UCSD. Quite a heritage there. Lots of internships at top tech companies.
      Slides: https://salu133445.github.io/pdf/seminar_20230918_generative_ai_for_music_and_audio.pdf
      
      Bio: https://salu133445.github.io/
      He reviews some fields of research into audio production:
            Music & sound effect generation 
            text to music, image to sound effects
            Music Information Research (MIR) Analysis, Retrieval, Creation (I didn't know that creation was one of the pillars here)
            Automatic Composition, thematic accompaniament, style transfer, audio sythesis
            MIR is a cross disciplinary field, Electical Engineering, Musicology and Theory, Computer Science, deep learning.
      His research: MultiTrack Music Generation: MuseGAN 2018, Multitrack Music Transformer 2023
            MusicGAN featured in Amazon AWS DeepComposer.
            MultiTrack Music Transformer - ICASSP 2023
                  Large Ensemble - Orchestral Instrumentation of more than 10 instruments. 
                  Compact representation
                  Multi-dimensional transformer
                  Related work: Lists several other models: REMI, MMM, CP, MusicBERT, FIGARO
                  Music is a sequence of events, analagous to words in LLM. Each event x is encoded as 
                        type, beat, position, pitch, duration, instrument 
                        Where type is structural or data
                        He includes position, which I think is very important, and something I do not use yet. Also beat, which I imagine is the position in the measure, with stress on the first beat. I do that, but over very long measures of 20+ beats. 
                  What this offers in an enhancement to MIDI is beat and position. But what is position?
                  He is looking for a transformer friendly representation, pack the required information for every note into a row of features, with the music made up of many rows. Sounds familiar.
                  the transformer is a multi-dimensional decoder-only transformer model. Predicts 6 features at the same time.
                  An embedding layer for each feature, which is concatenated and fed into the N layer masked multi-head self-attention and feed forward decoder blocks, 
                  Then into 6 dense layers softmaxed to the 6 features.
                  Trained auto-regressively to predict the next event given past events.
                  He plays and example of music continuation: Mozart's Eine Kleine Nacchtmusik from the first 4 beats. 
                  His comment is that Music Genearation is not just creating new stuff, it's also morphing or transformative creation. Who knew?
                  He compares his algorithm to MMM and REMI+, and finds his quality between those two, but much longer and faster, 100 seconds, and 11.79 tokens per second. 
                  He is proud that his model attends to 4N beats away from the next beat, while also attending to the same position as the current note. Which beat in the measure I guess. 
                  The current note will attend to other notes that are consonant to the previous notes, octave, third, etc.
                  His paper: http://arxiv.org/abs/2207.06983
                  demo: http://salu133445.github.io/mmt/
                  Code: http://github.com/salu133445/mmt 
      Assisting humans to create and perform music: Arranger (2018), Deep Performer (2022)
      Learning sound separation and synthesis from videos: ClipSep (2023), ClipSonic (2023)
            Multi-Modal Learning for Audio and Music
            Very effective noise removal. Amazing results.
      This guy is all over the place. Clearly a genius, No composer or musician, but tied into the folks at Sony, Amazon, Dolby, UCSD, Tiawan universities, Adademia Sinica, Yamaha, Adobe, Nvidia.

2.    A few small fixes to slide_tuning.ipynb   
      a.    Lower the maximum tempo from 144 to something slower. I thought I had done this, but it needs doing again. ✔
      b.    Check the min and max octaves in the voice array for the pizzicato strings. ✔
      c.    Consider longer repeats, shorter quantization. The value of the quantization is to mess with the voice sync. 
            Repeats on the other hand, controls the masking. It's done at the size of the repeats. That means that if you have very long repeats, the repetition of the rhythms will be harder to detect. There are good things and bad things about that. Try out some different settings for both.
      d.    Figure out a way to create another album without destroying the existing one. Create a different mod = 
                  mod = version[-2:] + '_b' + str(ratio_factor) ✔
      e.    Now I'm wondering if there isn't some way to prevent the combination of factors that leads to realizations like this one:
                  ball9-t.5_b_16_18_1.0.wav - it's very long and very slow. How could that happen. Perhaps it's the sparsity?
            How is the tempo set. Here is the assignment:
                  if repeats * quantization > 100:
                        tempo = rng.choice([120, 132, 144])
                  elif repeats * quantization > 50:
                        tempo = rng.choice([102, 108, 112, 116])
                  elif repeats * quantization > 25:
                        tempo = rng.choice([76, 84, 92, 98, 100])
                  else: tempo = rng.choice([56, 58, 62, 76])
            In the latest case: 
                        repeats = 18, quantization = 16 tempo = 132, repeats * quantization = 288

----------------------
9/26/23 To do today:

1.    Review the mistakes noobs make with python you tube video. 
      YouTube here: https://youtu.be/qUeud6DvOWI?si=YDf5PUW2ieSWerk5
      Index to all his videos, and there are a ton and they are all great:
      https://github.com/mCodingLLC/VideosSampleCode
      
      I do several of these:
      a.    Mutable default arguments: def foo(bar=[]): bar.append("baz"); return bar
            I should note that that code snippet was written by copilot, and it perfectly captures the essence of mutable default arguments. Neat. The problem arrises when you have a variable that you create and use in a function, and eventually decide that you would like a default value for that variable. You can't just turn it into a default argument. You have to remember that it changes behavior when it becomes a default argument. It cam still be changed, but the proper way to handle it is to set the default value in the argument to null, then check if None in the code for the function. 
            I think I fixed all of these, but basic idea is that default arguments are evaluated once, when the function is defined, not each time the function is called. That last sentence was also by copilot.
            
      b.    Use f strings more often. I use them in print and logging.info, but not in other places. 
            For example, rewrite this as an f string:
                  mod = version[-2:] + '_d_' + str(quantization) + '_' + str(repeats) + '_' + str(ratio_factor)
                  mod = f'{version[-2:]}_d_{quantization}_{repeats}_{ratio_factor}'
            That last rewrite was also by copilot. Excellent.

      c.    Comprehensions are your friends. 
            Learn to use list, dictionary, sets, and generator comprehensions. <-- I don't typically use generator comprehensions 
            Example of a python gnerator function:
                  # print the first 10 odd numbers
                  gen_comp = (2 * x + 5 for x in np.arange(10))
                  print(f'{[current for current in gen_comp] = }')
                        [current for current in gen_comp] = [5, 7, 9, 11, 13, 15, 17, 19, 21, 23]

      d.    Don't test using == for singletons like True, False, None. Use "is" instead. 
                  if x is None:
            rather than if x == None:

      e.    Don't use len() to test for empty containers. Use if not x: instead. 
                  if not x:

      f.    for i in range(len(x)): is not pythonic. Use 
                  for i, item in enumerate(x): 
            instead.
            I made my own enumerate with for i, item in zip(count(0,1), x):
            Enumerate is much cleaner.      

      g.    Don't loop over the keys in a dictionary with the keys() method. 
            Just loop over the dictionary itself. I do this all the time. Except, it's ok when you are making changes to the contents of the dictionary. Even then, it's not really needed. 

      h.    Don't test for types using type(x) == tuple. Instead use if isinstance(x, tuple) 

      i.    tuple unpacking can be simplified:
                  mytuple = 1,2 
                  x = mytuple[0] 
                  y = mytuple[1] 
            This can be replaced by:
                  x, y = mytuple
            I do that somewhere when I need to separate the octaves from the notes. It's in adaptive_tuning_util.py:
                  notes = notes_octaves[:,:,0] # the 0th feature is the note # (4, 256)
                  octaves = notes_octaves[:,:,1] # the 1th feature is the octave # (4, 256)
                  logging.info(f'consider simplifying this tuple unpacking here. {notes_octaces[:,:] = }, {notes = }, {octaves = }')
            Maybe I can get away with it. Check the log after the next run.

2.    Keep adjusting the ratio of repeats and quantization to understand how they work. 
      Try some where you have repeats = large value and quantization = small value and see if that makes the perception of repeats more esthetically pleasing. Some facts determined by listening.
      a.    For a long piece, having a repeats less than 12 results in far too repetitive result 
      b.    To prevent that, for repeats as low as 8 have low quantization: quantization = 4, repeats = 8.
            quantization  repeats duration tempo
                  4         8      5:44         70
                  8         4      6:43         66 
      c.    Create an if, then, elif clause that based on the repeats, assigns a quantization. Quant high if the repeats are high. Quant low if the repeats are low. 
      But if the repeats are over 10, then max the quantization at 20.

Some additional videos:
      a.    Cache decorator:
            Put it in front of a function definition and it cached the results of the function based on the input arguments.
---------------------
9/27/23 To do today:

1.    Check for a relationship between the sparsity measure and the sound of the output. Here's an example            
            - In mainline: version = 'bwv245.17', mod = '17_e_9_22_1.5', ratio_factor = 1.5, chorale.shape[1] = 362, repeats = 22, quantization = 9
            - control density of arpeggiated voice: [(0.5905, 0.4095), (0.5905, 0.4095), (0.999, 0.001), (0.999, 0.001), (0.1821, 0.8179), (0.1821, 0.8179)]. round(start, 4) = 0.001, round(stop, 4) = 1.0, round(step,4) = 0.4085
            - control density of winds: round(max_silence, 4) = 0.7809
            - duration: 00:18:18.000, tempo = 116            
      The wind max_silence number is lower than the other pieces at .7809. The arpeggiated voice seems odd. 
      a.    It repeats, which is normal if there aren't enough, I tile it.
            if probs.shape[0] < 5: 

------------------------------
9/28/23     To do today:

1.    Take some time to isloate the issues with both the wind and arpeggio sparsity methods.
      One at a time, pick a small section of maybe two measures, and try the edge cases. What is the highest and lowest values that might occur, and see what they sound like. The purpose of this settings was to make it possible to create a set of dranatically different pieces, that only hang together by virtue of the original Bach. I'm getting closer, but I need to focus on what I'm targeting, not just creating another album with the current settings. Do the same with the quantization. Odd quantizations should be as common as 4, 8, 16, 32, so that suggests rng.choice([]) instead of a range. Again, isolate the edgee cases, see if they make sense, a and change them if they don't.

2.    I'm really enjoying the way MusicBox does a fade from one piece to another. 
      THat gives me the idea that maybe I could do the same programatically. That implies that I need to step from short to long pieces, otherwize the long ones will dominate the perception. Here are some things I will need to do:
      a.    Create a new notebook based off slide_tuning.ipynb.
      b.    I need to identify when I'm reseting voice_

3.    Bug in quantization assignment. The quant_choices array is ending up empty when needed to choose the value.
            quantization = rng.choice(quant_choices)
                  version = 'bwv245.22', quant_choices = array([9]), quantization = 3, repeats = 15, ratio_factor = 1.5
                  quant_choices = array([], dtype=int64)
                  version = 'bwv245.22', quant_choices = array([], dtype=int64), quantization = 3, repeats = 15, ratio_factor = 1.5      
      It was because I changed the choices from a range to specific, and forgot to change nop.arange to np.array([])

4.    Now all the chorale shapes are (4,192) regardless of which chorale I set. That's impossible. 
      40 has 28 measures and 22 as 12 measures. They can't all have 192 1/16th notes. 192 is correct for 12 measures though. It's just not for 28 measures. How long has this bug existed? Was I always using the same 192 note chorale all this time?
            grep -E "version = " save.txt
                  version = 'bwv245.15', chorale.shape = (4, 192), keys[root] = 'A♮', mode = 'minor', time_sig = '4/4'
                  version = 'bwv245.17', chorale.shape = (4, 176), keys[root] = 'A♮', mode = 'minor', time_sig = '4/4'
                  version = 'bwv245.22', chorale.shape = (4, 192), keys[root] = 'E♮', mode = 'major', time_sig = '4/4'
                  version = 'bwv245.26', chorale.shape = (4, 192), keys[root] = 'D♯', mode = 'major', time_sig = '4/4'
                  ...
      I had a bug in the code a while back where it was assigning an array of zeros, then loading it. It might not have been large enough. Did that bug just come back to bite me? I thought I had fixed it with this change to adaptive_tuning_util.py
            chorale = np.zeros((4, ticks_per_beat // slots_per_quarter * quantization * 12), dtype = int)
      Since this doesn't include the mid.length value, it's wrong. 
            version     mid.len  measures  shape 
            'bwv245.15' 34.5        17    272 
            'bwv245.17' 22.5        11    176
            'bwv245.22' 24.5        12    192
            'bwv245.26' 32.5        16    256
            'bwv245.28' 32.5        16    256
            'bwv245.3'  22.5        11    176
            'bwv245.37' 34.5        17    272
            'bwv245.40' 56.5        28    448
            'bwv245.5'  24.5        12    192
            'bwv245.11' 24.5        12    192
            'bwv245.14' 32.5        16    256
      So it looks to me like I can determine the number of measures from the mid.len 
            measures = int(mid.len)    
            grep -E "version = | chorale.shape = | mid.len" save.txt
                  'bwv245.15', chorale.shape = (4, 272)
                  'bwv245.17', chorale.shape = (4, 176)
                  'bwv245.22', chorale.shape = (4, 192)
                  'bwv245.26', chorale.shape = (4, 256)
                  'bwv245.28', chorale.shape = (4, 256)
                  'bwv245.3',  chorale.shape = (4, 176)
                  'bwv245.37', chorale.shape = (4, 272)
                  'bwv245.40', chorale.shape = (4, 448)
                  'bwv245.5',  chorale.shape = (4, 192)
                  'bwv245.11', chorale.shape = (4, 192)
                  'bwv245.14', chorale.shape = (4, 256)
      Fixed it. I think.

-------------------------
9/29/23 To do today:

1.    Try out some of the Jupyter notebook magics: 
      %%ipytest - tests the cells - more here: https://pypi.org/project/ipytest/
            pip install ipytest
      Then after installing, include these two import statements:            
            import ipytest
            ipytest.autoconfig()

2.    Continue with systematic testing of different probabilities. What are the limits?

--------------------------
9/30/23 To do today:

1.    Based on the results of testing, I think I have the correct probability varieties in the arpeggios and winds. 
      I made a few minor changes in the assignments, but they seem fine now. 

2.    Create a copy of slide_tuning.ipynb as slide_tuning_long.ipynb. Then implement the crossfade capability.
      a.    Find a way to fade from one piece to the next with an overlap of perhaps 10 seconds. MusicBox is set to 6 seconds, and that may be a better duration.

      b.    One possible way to do this is to eliminate this initial assignment of notes_features_15:
            notes_features_15 = np.empty((0,15), dtype = int) # start with an empty array you can concatenate onto.
      This is done in
            def expand_chorale()
      to start the piece. I'll have to move that somewhere else.

      c.    The following will have to wait until all are completed.
            This one sets voice time, and notes_features_final which will be used in the send_to_csound_file function.
            notes_features_final, voice_time = dmu.fix_start_times(notes_features_15, voice_time)
            _ = dmu.send_to_csound_file(notes_features_final, voice_time, CSD_FILE, tempos = 't0 ' + str(tempo), limit = limit, tempo = tempo, print_only = print_only, include_instruments = include_instruments) 

      d.    Tempo is going to be a challenge, since it's currently set once for the whole piece. I'll have to make a more complex tempo string that reflects a chain of tempi over the course of several chorales. I did that once before, but I had a gap between each chorale, and I'm trying to get them to crossfade instead. 

      e.    Figure out how you are going to implement the crossfade. Some requirements:
            1.    Make the end of now change tempo prior to the beginning of the crossfasde, so that when it happens, they will be at the same tempo.
            2.    Perhaps the dmu.fix_start_times will have to adjust voice_time, so that all voices will start earlier.

      f.    Notice that the different instruments have different durations. This isn't a problem when they go silent. But the voice_time array will have to be adjusted for each instrument so that they all end at the same time. Then changes to reflect the crossfade time.

-------------------
10/2/23     To do today

1.    Keep working on the Chollet book. 

2.    Listen to the latest creations, my overall impression is that they are all a little too long. 
      How can I tighten them up just a bit. The tempos are fine. Take a look at the log file to determine if you are getting a representative sample of your favorite combinations. It makes sense that they are longer than you would like, because you are now listening to them on MusicBox with a 6 second crossfade. You want more of those, and less of the repetitive long pieces. Some suggestions for the next run:
      a.    Make the choice of ratio factor more random:
                  ratio_factor = rng.choice([0.75, 1.0, 1.25, 1.5])
      b.    The tempi are all either slow or very fast. What happened to the moderately slow and moderately fast?
                  chosen tempO: 58  74  58 132  54  54  62  70  74 128  74
            There is a jump from 74 to 128. Why?
      c.    I would like to see a quantization of 5, 9, & 16. But if it's 16 then the repeats must be low. 
                  chosen q:   3     4      8     7    3      4    7     3     8     7     8
      d.    Repeats:     r:   3     8      6    15    8     11    4     8     2    17     3  
      e.    Durations: dur: 02:40 05:04 10:11 13:10 07:26 09:37 07:44 09:18 02:42 11:33 05:19
      f.    So what needs to change? The logic for choosing the tempo and quantization. The quantization depends on the repeats chosen, and the tempo depends on repeats times quantization. 

-------------
10/3/23 To do today:

1.    Keep working on the Chollet book. Chapter 5 pag 78.

2.    Find a way to add more information to mod. Now it's this:
            mod = f'{version[-2:]}_{mod_letter}_{quantization}_{repeats}_{ratio_factor}'
      Why not pass it into and out of functions that determine the values of the most important variables.
      Keep the ones you have, but add a description letter to each:
            mod = f'{version[-2:]}_{mod_letter}_q_{quantization}_f_{repeats}_rf_{ratio_factor}'
      Just append the wind (w) and arp (a) probability measure, like average value. Also tempo (t). 
      What else matters? Duration. (d). And number of chords (c).
            mod = f'{version[-2:]}_{mod_letter}_q_{quantization}_f_{repeats}_rf_{ratio_factor}_w_{wind_prob}_a_{arp_prob}_t_{tempo}_d_{duration}_c_{num_chords}'
            
      But I have to delay making that happen until the values are available. 
      a.    probs are set in 
            def expand_chorale(repeats, chorale_in_cents_slides, glides, stored_gliss, voice_time, \
                  finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, mod, \
            So in the call to expand_chorale, I need to pass in the mod string as it exists.
                  duration, volume_function = expand_chorale(repeats, chorale_in_cents, chorale_in_cents_slides, glides, \
                        stored_gliss, voice_time, finger_pianos, wood_winds, pizz_strings, bowed_strings, brass_section, mod, perc_guitar, \
                        mask = mask, fing = fing, wood = wood, octave_reduce = 1, woodwinds_volume = woodwinds_volume, \
                        include_instruments = include_instruments, print_only = print_only, quantization = quantization)
      b.    duration is set in the mainline.
      c.    chorale.shape[1] is set in the mainline. c{chorale.shape[1]}
      c.    But now it's way too long: mod = '40_g_q_8_r_14_rf_1.25_a_0.09_w_0.04_d_00:24:59.000_t_128'
            How is this: mod = '40g_q3_r17_f0.75_a0.09_w0.07_d12:53_t110'

3.    What else bothered you about the g collection? What did you like?
      a.    I liked the long fast ones, and the very short moderate tempo one.
      b.    The ones that were slow and long were too long. These should be shorter.       

4.    Make a list in save_g.txt that includes all those values of the g collection.

5.    Run a batch on the h collection:
            ls -lth ~/Music/sflib/ball9-t??h* | head -n 15
                  ball9-t14h_q6_r7_f1.5_c384_a0.09_w0.1_d07:53_t88.wav
                  ball9-t11h_q16_r6_f1.25_c768_a0.08_w0.06_d11:29_t102.wav
                  ball9-t.5h_q4_r7_f1.0_c192_a0.02_w0.07_d04:15_t84.wav
                  ball9-t40h_q4_r6_f1.0_c448_a0.09_w0.02_d09:34_t72.wav
                  ball9-t37h_q4_r4_f0.75_c272_a0.02_w0.05_d04:42_t60.wav
                  ball9-t.3h_q4_r2_f1.5_c176_a0.07_w0.03_d01:20_t72.wav
                  ball9-t28h_q4_r7_f0.75_c256_a0.1_w0.01_d04:54_t96.wav
                  ball9-t26h_q4_r8_f1.25_c256_a0.07_w0.09_d05:50_t92.wav
                  ball9-t22h_q4_r5_f1.5_c192_a0.08_w0.09_d03:20_t76.wav
                  ball9-t17h_q8_r14_f0.75_c352_a0.38_w0.09_d10:06_t128.wav
                  ball9-t15h_q8_r12_f1.25_c544_a0.08_w0.05_d15:16_t110.wav
                  ball9-t40h_q6_r7_f1.5_c672_a0.08_w0.19_d14:57_t80.wav
      Why are all the q values 4, 6, 8, 16?
      Made a few changes, and don't like the results. 
      This is a test run that did not include the 10 minutes to generate the csound wav file.
            grep -E "mod = " slide_tuning.log > save_h.txt
                  bwv245.15 mod = 15h_q3_r4_f1.25_c196 ratio_factor = 1.25 chords: 196 repeats = 4 quantization = 3
                  bwv245.17 mod = 17h_q8_r6_f0.75_c352 ratio_factor = 0.75 chords: 352 repeats = 6 quantization = 8
                  bwv245.22 mod = 22h_q3_r5_f0.75_c136 ratio_factor = 0.75 chords: 136 repeats = 5 quantization = 3
                  bwv245.26 mod = 26h_q8_r4_f0.75_c512 ratio_factor = 0.75 chords: 512 repeats = 4 quantization = 8
                  bwv245.28 mod = 28h_q4_r8_f1.5_c256  ratio_factor = 1.5  chords: 256 repeats = 8 quantization = 4
                  bwv245.3  mod = .3h_q3_r2_f1.0_c126  ratio_factor = 1.0  chords: 126 repeats = 2 quantization = 3
                  bwv245.37 mod = 37h_q3_r4_f1.0_c197  ratio_factor = 1.0  chords: 197 repeats = 4 quantization = 3
                  bwv245.40 mod = 40h_q3_r4_f1.0_c314  ratio_factor = 1.0  chords: 314 repeats = 4 quantization = 3
                  bwv245.5  mod = .5h_q3_r8_f1.25_c135 ratio_factor = 1.25 chords: 135 repeats = 8 quantization = 3
                  bwv245.11 mod = 11h_q3_r5_f1.0_c136  ratio_factor = 1.0  chords: 136 repeats = 5 quantization = 3
                  bwv245.14 mod = 14h_q10_r7_f1.0_c640 ratio_factor = 1.0  chords: 640 repeats = 7 quantization = 10

      Some concerns: why so many quantization = 3? It's a choice for all repeats values. Fixed that.
                  mod = 15h_q16_r8_f1.25_c1088  ratio_factor = 1.25 chords: 1088 repeats = 8 quantization = 16
                  mod = 17h_q16_r6_f1.0_c704    ratio_factor = 1.0  chords: 704  repeats = 6 quantization = 16
                  mod = 22h_q4_r7_f1.5_c192     ratio_factor = 1.5  chords: 192  repeats = 7 quantization = 4
                  mod = 26h_q8_r3_f1.0_c512     ratio_factor = 1.0  chords: 512  repeats = 3 quantization = 8
                  mod = 28h_q16_r4_f1.25_c1024  ratio_factor = 1.25 chords: 1024 repeats = 4 quantization = 16
                  mod = .3h_q8_r7_f1.25_c352    ratio_factor = 1.25 chords: 352  repeats = 7 quantization = 8
                  mod = 37h_q4_r8_f1.0_c272     ratio_factor = 1.0  chords: 272  repeats = 8 quantization = 4
                  mod = 40h_q3_r3_f1.0_c314     ratio_factor = 1.0  chords: 314  repeats = 3 quantization = 3
                  mod = .5h_q16_r6_f1.5_c768    ratio_factor = 1.5  chords: 768  repeats = 6 quantization = 16
                  mod = 11h_q3_r4_f0.75_c136    ratio_factor = 0.75 chords: 136  repeats = 4 quantization = 3
                  mod = 14h_q5_r2_f0.75_c311    ratio_factor = 0.75 chords: 311  repeats = 2 quantization = 5
      Why are the repeats values so low? Just coincidence, since the next one included some large repeats values. Probabalistic, not deterministic.